{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/txtai/src/python",
    "API_Calls": [
        {
            "Name": "call_Embeddings",
            "Description": "call_Embeddings",
            "Code": "\"\"\"\nBuilds a similarity index for a directory of images\n\nRequires streamlit to be installed.\n  pip install streamlit\n\"\"\"\n\nimport glob\nimport os\nimport sys\n\nimport streamlit as st\n\nfrom PIL import Image\n\nfrom txtai.embeddings import Embeddings\n\n\nclass Application:\n    \"\"\"\n    Main application\n    \"\"\"\n\n    def __init__(self, directory):\n        \"\"\"\n        Creates a new application.\n\n        Args:\n            directory: directory of images\n        \"\"\"\n\n        self.embeddings = self.build(directory)\n\n    def build(self, directory):\n        \"\"\"\n        Builds an image embeddings index.\n\n        Args:\n            directory: directory with images\n\n        Returns:\n            Embeddings index\n        \"\"\"\n\n        embeddings = Embeddings({\"method\": \"sentence-transformers\", \"path\": \"clip-ViT-B-32\"})\n        embeddings.index(self.images(directory))\n\n        # Update model to support multilingual queries\n        embeddings.config[\"path\"] = \"sentence-transformers/clip-ViT-B-32-multilingual-v1\"\n        embeddings.model = embeddings.loadvectors()\n\n        return embeddings\n\n    def images(self, directory):\n        \"\"\"\n        Generator that loops over each image in a directory.\n\n        Args:\n            directory: directory with images\n        \"\"\"\n\n        for path in glob.glob(directory + \"/*jpg\") + glob.glob(directory + \"/*png\"):\n            yield (path, Image.open(path), None)\n\n    def run(self):\n        \"\"\"\n        Runs a Streamlit application.\n        \"\"\"\n\n        st.title(\"Image search\")\n\n        st.markdown(\"This application shows how images and text can be embedded into the same space to support similarity search. \")\n        st.markdown(\n            \"[sentence-transformers](https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/image-search) \"\n            + \"recently added support for the [OpenAI CLIP model](https://github.com/openai/CLIP). This model embeds text and images into \"\n            + \"the same space, enabling image similarity search. txtai can directly utilize these models.\"\n        )\n\n        query = st.text_input(\"Search query:\")\n        if query:\n            index, _ = self.embeddings.search(query, 1)[0]\n            st.image(Image.open(index))\n\n\n@st.cache(allow_output_mutation=True)\ndef create(directory):\n    \"\"\"\n    Creates and caches a Streamlit application.\n\n    Args:\n        directory: directory of images to index\n\n    Returns:\n        Application\n    \"\"\"\n\n    return Application(directory)\n\n\nif __name__ == \"__main__\":\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n    # Create and run application\n    app = create(sys.argv[1])\n    app.run()\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/txtai/examples/images.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "Embeddings",
            "Description": "Embeddings",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/txtai/src/python/txtai/embeddings/base.py",
            "Implementation": "\"\"\"\nEmbeddings module\n\"\"\"\n\nimport json\nimport os\nimport tempfile\n\nfrom ..ann import ANNFactory\nfrom ..archive import ArchiveFactory\nfrom ..cloud import CloudFactory\nfrom ..database import DatabaseFactory\nfrom ..graph import GraphFactory\nfrom ..scoring import ScoringFactory\nfrom ..vectors import VectorsFactory\n\nfrom .index import Action, Configuration, Functions, Indexes, IndexIds, Reducer, Stream, Transform\nfrom .search import Explain, Ids, Query, Search, Terms\n\n\n# pylint: disable=C0302,R0904\nclass Embeddings:\n    \"\"\"\n    Embeddings databases are the engine that delivers semantic search. Data is transformed into embeddings vectors where similar concepts\n    will produce similar vectors. Indexes both large and small are built with these vectors. The indexes are used to find results\n    that have the same meaning, not necessarily the same keywords.\n    \"\"\"\n\n    # pylint: disable = W0231\n    def __init__(self, config=None, models=None, **kwargs):\n        \"\"\"\n        Creates a new embeddings index. Embeddings indexes are thread-safe for read operations but writes must be synchronized.\n\n        Args:\n            config: embeddings configuration\n            models: models cache, used for model sharing between embeddings\n            kwargs: additional configuration as keyword args\n        \"\"\"\n\n        # Index configuration\n        self.config = None\n\n        # Dimensionality reduction - word vectors only\n        self.reducer = None\n\n        # Dense vector model - transforms data into similarity vectors\n        self.model = None\n\n        # Approximate nearest neighbor index\n        self.ann = None\n\n        # Index ids when content is disabled\n        self.ids = None\n\n        # Document database\n        self.database = None\n\n        # Resolvable functions\n        self.functions = None\n\n        # Graph network\n        self.graph = None\n\n        # Sparse vectors\n        self.scoring = None\n\n        # Query model\n        self.query = None\n\n        # Index archive\n        self.archive = None\n\n        # Subindexes for this embeddings instance\n        self.indexes = None\n\n        # Models cache\n        self.models = models\n\n        # Merge configuration into single dictionary\n        config = {**config, **kwargs} if config and kwargs else kwargs if kwargs else config\n\n        # Set initial configuration\n        self.configure(config)\n\n    def score(self, documents):\n        \"\"\"\n        Builds a term weighting scoring index. Only used by word vectors models.\n\n        Args:\n            documents: iterable of (id, data, tags), (id, data) or data\n        \"\"\"\n\n        # Build scoring index for word vectors term weighting\n        if self.isweighted():\n            self.scoring.index(Stream(self)(documents))\n\n    def index(self, documents, reindex=False, checkpoint=None):\n        \"\"\"\n        Builds an embeddings index. This method overwrites an existing index.\n\n        Args:\n            documents: iterable of (id, data, tags), (id, data) or data\n            reindex: if this is a reindex operation in which case database creation is skipped, defaults to False\n            checkpoint: optional checkpoint directory, enables indexing restart\n        \"\"\"\n\n        # Initialize index\n        self.initindex(reindex)\n\n        # Create transform and stream\n        transform = Transform(self, Action.REINDEX if reindex else Action.INDEX, checkpoint)\n        stream = Stream(self, Action.REINDEX if reindex else Action.INDEX)\n\n        with tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".npy\") as buffer:\n            # Load documents into database and transform to vectors\n            ids, dimensions, embeddings = transform(stream(documents), buffer)\n            if embeddings is not None:\n                # Build LSA model (if enabled). Remove principal components from embeddings.\n                if self.config.get(\"pca\"):\n                    self.reducer = Reducer(embeddings, self.config[\"pca\"])\n                    self.reducer(embeddings)\n\n                # Save index dimensions\n                self.config[\"dimensions\"] = dimensions\n\n                # Create approximate nearest neighbor index\n                self.ann = self.createann()\n\n                # Add embeddings to the index\n                self.ann.index(embeddings)\n\n            # Save indexids-ids mapping for indexes with no database, except when this is a reindex\n            if ids and not reindex and not self.database:\n                self.ids = self.createids(ids)\n\n        # Index scoring, if necessary\n        # This must occur before graph index in order to be available to the graph\n        if self.issparse():\n            self.scoring.index()\n\n        # Index subindexes, if necessary\n        if self.indexes:\n            self.indexes.index()\n\n        # Index graph, if necessary\n        if self.graph:\n            self.graph.index(Search(self, indexonly=True), Ids(self), self.batchsimilarity)\n\n    def search(self, query, limit=None, weights=None, index=None, parameters=None, graph=False):\n        \"\"\"\n        Finds documents most similar to the input query. This method runs an index search, index + database search\n        or a graph search, depending on the embeddings configuration and query.\n\n        Args:\n            query: input query\n            limit: maximum results\n            weights: hybrid score weights, if applicable\n            index: index name, if applicable\n            parameters: dict of named parameters to bind to placeholders\n            graph: return graph results if True\n\n        Returns:\n            list of (id, score) for index search\n            list of dict for an index + database search\n            graph when graph is set to True\n        \"\"\"\n\n        results = self.batchsearch([query], limit, weights, index, [parameters], graph)\n        return results[0] if results else results\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}