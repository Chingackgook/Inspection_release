{
    "Project_Root": "/mnt/autor_name/Inspection/Demo/DemoAIProject/",
    "API_Calls": [
        {
            "Name": "ExternalCallDemo",
            "Description": "External Call Demo - Demonstrates how to use AI agent in other projects",
            "Code": "from ai_agent import AIAgent\n\nclass ExternalCallDemo:\n    \"\"\"External Call Demo Class - Demonstrates how to use AI agent in external projects\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize external call example\"\"\"\n        self.ai_agent = None\n        self.setup_agent()\n    \n    def setup_agent(self):\n        \"\"\"Setup AI agent\"\"\"\n        # Here you can read API key from environment variables or config file\n        try:\n            self.ai_agent = AIAgent()\n            print(\"âœ… AI agent setup successful\")\n        except Exception as e:\n            print(f\"âŒ AI agent setup failed: {e}\")\n    \n    def simple_chat_example(self):\n        \"\"\"Simple chat example\"\"\"\n        print(\"\\n=== Simple Chat Example ===\")\n        \n        if not self.ai_agent:\n            print(\"Simulated conversation: Hello! I am an AI assistant.\")\n            return\n        \n        questions = [\n            \"Who are you?\",\n            \"Please explain what machine learning is\",\n            \"Summarize the development prospects of artificial intelligence in one sentence\"\n        ]\n        \n        for question in questions:\n            print(f\"\\nðŸ“ Question: {question}\")\n            result = self.ai_agent.chat(question)\n            \n            if result[\"success\"]:\n                print(f\"ðŸ¤– Answer: {result['reply']}\")\n                print(f\"ðŸ“Š Tokens used: {result.get('tokens_used', {})}\")\n            else:\n                print(f\"âŒ Error: {result['error']}\")\n    \n    def batch_processing_example(self):\n        \"\"\"Batch processing example\"\"\"\n        print(\"\\n=== Batch Processing Example ===\")\n        \n        tasks = [\n            {\"type\": \"translate\", \"content\": \"Hello, how are you?\", \"instruction\": \"Translate to Chinese\"},\n            {\"type\": \"summarize\", \"content\": \"Artificial intelligence technology is developing rapidly, with breakthroughs in deep learning, natural language processing and other technologies.\", \"instruction\": \"Summarize in one sentence\"},\n            {\"type\": \"creative\", \"content\": \"Spring\", \"instruction\": \"Write a short poem about spring\"}\n        ]\n        \n        for i, task in enumerate(tasks, 1):\n            print(f\"\\nTask {i}: {task['type']}\")\n            print(f\"Content: {task['content']}\")\n            \n            if not self.ai_agent:\n                print(f\"Simulated result: Processed '{task['content']}'\")\n                continue\n            \n            prompt = f\"{task['instruction']}: {task['content']}\"\n            result = self.ai_agent.chat(prompt)\n            \n            if result[\"success\"]:\n                print(f\"Result: {result['reply']}\")\n            else:\n                print(f\"Error: {result['error']}\")\n    \n    def advanced_usage_example(self):\n        \"\"\"Advanced usage example\"\"\"\n        print(\"\\n=== Advanced Usage Example ===\")\n        \n        if not self.ai_agent:\n            print(\"Simulated advanced features demo\")\n            return\n        \n        # 1. Using different temperature parameters\n        print(\"\\n1. Creative writing (high temperature):\")\n        creative_result = self.ai_agent.chat(\n            \"Write the beginning of a short story about robots\",\n            temperature=0.9\n        )\n        if creative_result[\"success\"]:\n            print(creative_result[\"reply\"])\n        \n        # 2. Using system prompt\n        print(\"\\n2. Professional translation (system prompt):\")\n        translation_result = self.ai_agent.chat(\n            \"Artificial intelligence is transforming our world.\",\n            system_prompt=\"You are a professional English-Chinese translation expert, please provide accurate and natural translations.\"\n        )\n        if translation_result[\"success\"]:\n            print(translation_result[\"reply\"])\n        \n        # 3. Text analysis\n        print(\"\\n3. Sentiment analysis:\")\n        sentiment_result = self.ai_agent.analyze_text(\n            \"Today's meeting was very successful, the team worked well together!\",\n            analysis_type=\"sentiment\"\n        )\n        if sentiment_result[\"success\"]:\n            print(sentiment_result[\"reply\"])\n    \n",
            "Path": "/mnt/autor_name/Inspection/Demo/DemoAIProject/external_call_demo.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "AIAgent",
            "Description": "Intelligent AI agent class for interacting with GPT API",
            "Path": "/mnt/autor_name/Inspection/Demo/DemoAIProject/ai_agent.py",
            "Implementation": "\"\"\"\nAI Agent Class - Intelligent agent for calling GPT API\n\"\"\"\nimport requests\nfrom typing import Optional, Dict, Any\nimport os\n\nclass AIAgent:\n    \"\"\"Intelligent AI agent class for interacting with GPT API\"\"\"\n    \n    def __init__(self, model = None):\n        \"\"\"\n        Initialize AI agent\n        \n        Args:\n            api_key: OpenAI API key\n            base_url: API base URL\n            model: Model name to use\n        \"\"\"\n        api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n        base_url = os.getenv(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n        if model is None:\n            model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n        \n        if api_key == \"your-api-key-here\":\n            raise ValueError(\"Please set OPENAI_API_KEY environment variable or provide API key\")\n\n        print(f\"Using model: {model}\")\n        print(f\"API Base URL: {base_url}\")\n        print(f\"API Key: {api_key}\")\n\n        self.api_key = api_key\n        self.base_url = base_url\n        self.model = model\n        self.headers = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n    \n    def chat(self, message: str, system_prompt: Optional[str] = None, temperature: float = 0.7) -> Dict[str, Any]:\n        \"\"\"\n        Chat with AI\n        \n        Args:\n            message: User message\n            system_prompt: System prompt (optional)\n            temperature: Temperature parameter to control randomness of response\n            \n        Returns:\n            Dictionary containing AI reply and metadata\n        \"\"\"\n        try:\n            # Build message list\n            messages = []\n            if system_prompt:\n                messages.append({\"role\": \"system\", \"content\": system_prompt})\n            messages.append({\"role\": \"user\", \"content\": message})\n            \n            # Build request data\n            payload = {\n                \"model\": self.model,\n                \"messages\": messages,\n                \"temperature\": temperature,\n                \"max_tokens\": 1000\n            }\n            \n            # Send request\n            url = f\"{self.base_url}/chat/completions\"\n            response = requests.post(url, headers=self.headers, json=payload, timeout=30)\n            \n            if response.status_code == 200:\n                result = response.json()\n                ai_reply = result['choices'][0]['message']['content']\n                \n                return {\n                    \"success\": True,\n                    \"reply\": ai_reply,\n                    \"tokens_used\": result.get('usage', {}),\n                    \"model\": self.model\n                }\n            else:\n                error_msg = f\"API request failed: {response.status_code} - {response.text}\"\n                return {\n                    \"success\": False,\n                    \"error\": error_msg,\n                    \"reply\": None\n                }\n                \n        except requests.exceptions.Timeout:\n            error_msg = \"Request timeout\"\n            return {\"success\": False, \"error\": error_msg, \"reply\": None}\n        \n        except requests.exceptions.RequestException as e:\n            error_msg = f\"Network request error: {str(e)}\"\n            return {\"success\": False, \"error\": error_msg, \"reply\": None}\n        \n        except Exception as e:\n            error_msg = f\"Unknown error: {str(e)}\"\n            return {\"success\": False, \"error\": error_msg, \"reply\": None}\n    \n    def generate_text(self, prompt: str) -> Dict[str, Any]:\n        \"\"\"\n        Generate text\n        \n        Args:\n            prompt: Prompt text\n            \n        Returns:\n            Generated text and metadata\n        \"\"\"\n        return self.chat(prompt, temperature=0.8)\n    \n    def analyze_text(self, text: str, analysis_type: str = \"general\") -> Dict[str, Any]:\n        \"\"\"\n        Analyze text\n        \n        Args:\n            text: Text to analyze\n            analysis_type: Analysis type (general, sentiment, summary, etc.)\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        system_prompts = {\n            \"general\": \"You are a text analysis expert, please provide a comprehensive analysis of the following text.\",\n            \"sentiment\": \"You are a sentiment analysis expert, please analyze the emotional tendency of the following text.\",\n            \"summary\": \"You are a text summarization expert, please generate a concise summary for the following text.\"\n        }\n        \n        system_prompt = system_prompts.get(analysis_type, system_prompts[\"general\"])\n        return self.chat(text, system_prompt=system_prompt)\n    \n    def set_model(self, model: str):\n        \"\"\"Set the model to use\"\"\"\n        self.model = model\n    \n    def get_model_info(self) -> Dict[str, str]:\n        \"\"\"Get current model information\"\"\"\n        return {\n            \"current_model\": self.model,\n            \"base_url\": self.base_url\n        }\n",
            "Examples": [
                "\n\n"
            ]
        }
    ]
}