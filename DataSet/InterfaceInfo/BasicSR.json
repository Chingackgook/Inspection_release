{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/BasicSR",
    "API_Calls": [
        {
            "Name": "call_BasicVSR",
            "Description": "call BasicVSR",
            "Code": "import argparse\nimport cv2\nimport glob\nimport os\nimport shutil\nimport torch\n\nfrom basicsr.archs.basicvsr_arch import BasicVSR\nfrom basicsr.data.data_util import read_img_seq\nfrom basicsr.utils.img_util import tensor2img\n\n\ndef inference(imgs, imgnames, model, save_path):\n    with torch.no_grad():\n        outputs = model(imgs)\n    # save imgs\n    outputs = outputs.squeeze()\n    outputs = list(outputs)\n    for output, imgname in zip(outputs, imgnames):\n        output = tensor2img(output)\n        cv2.imwrite(os.path.join(save_path, f'{imgname}_BasicVSR.png'), output)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--model_path', type=str, default='experiments/pretrained_models/BasicVSR_REDS4.pth')\n    parser.add_argument(\n        '--input_path', type=str, default='datasets/REDS4/sharp_bicubic/000', help='input test image folder')\n    parser.add_argument('--save_path', type=str, default='results/BasicVSR', help='save image path')\n    parser.add_argument('--interval', type=int, default=15, help='interval size')\n    args = parser.parse_args()\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # set up model\n    model = BasicVSR(num_feat=64, num_block=30)\n    model.load_state_dict(torch.load(args.model_path)['params'], strict=True)\n    model.eval()\n    model = model.to(device)\n\n    os.makedirs(args.save_path, exist_ok=True)\n\n    # extract images from video format files\n    input_path = args.input_path\n    use_ffmpeg = False\n    if not os.path.isdir(input_path):\n        use_ffmpeg = True\n        video_name = os.path.splitext(os.path.split(args.input_path)[-1])[0]\n        input_path = os.path.join('./BasicVSR_tmp', video_name)\n        os.makedirs(os.path.join('./BasicVSR_tmp', video_name), exist_ok=True)\n        os.system(f'ffmpeg -i {args.input_path} -qscale:v 1 -qmin 1 -qmax 1 -vsync 0  {input_path} /frame%08d.png')\n\n    # load data and inference\n    imgs_list = sorted(glob.glob(os.path.join(input_path, '*')))\n    num_imgs = len(imgs_list)\n    if len(imgs_list) <= args.interval:  # too many images may cause CUDA out of memory\n        imgs, imgnames = read_img_seq(imgs_list, return_imgname=True)\n        imgs = imgs.unsqueeze(0).to(device)\n        inference(imgs, imgnames, model, args.save_path)\n    else:\n        for idx in range(0, num_imgs, args.interval):\n            interval = min(args.interval, num_imgs - idx)\n            imgs, imgnames = read_img_seq(imgs_list[idx:idx + interval], return_imgname=True)\n            imgs = imgs.unsqueeze(0).to(device)\n            inference(imgs, imgnames, model, args.save_path)\n\n    # delete ffmpeg output images\n    if use_ffmpeg:\n        shutil.rmtree(input_path)\n\n\nif __name__ == '__main__':\n    main()\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/BasicSR/inference/inference_basicvsr.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "BasicVSR",
            "Description": "BasicVSR impl",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/BasicSR/basicsr/archs/basicvsr_arch.py",
            "Implementation": "import torch\nfrom torch import nn as nn\nfrom torch.nn import functional as F\n\nfrom basicsr.utils.registry import ARCH_REGISTRY\nfrom .arch_util import ResidualBlockNoBN, flow_warp, make_layer\nfrom .edvr_arch import PCDAlignment, TSAFusion\nfrom .spynet_arch import SpyNet\n\n\n@ARCH_REGISTRY.register()\nclass BasicVSR(nn.Module):\n    \"\"\"A recurrent network for video SR. Now only x4 is supported.\n\n    Args:\n        num_feat (int): Number of channels. Default: 64.\n        num_block (int): Number of residual blocks for each branch. Default: 15\n        spynet_path (str): Path to the pretrained weights of SPyNet. Default: None.\n    \"\"\"\n\n    def __init__(self, num_feat=64, num_block=15, spynet_path=None):\n        super().__init__()\n        self.num_feat = num_feat\n\n        # alignment\n        self.spynet = SpyNet(spynet_path)\n\n        # propagation\n        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)\n        self.forward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)\n\n        # reconstruction\n        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)\n        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)\n        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)\n        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)\n        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)\n\n        self.pixel_shuffle = nn.PixelShuffle(2)\n\n        # activation functions\n        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n\n    def get_flow(self, x):\n        b, n, c, h, w = x.size()\n\n        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)\n        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)\n\n        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)\n        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)\n\n        return flows_forward, flows_backward\n\n    def forward(self, x):\n        \"\"\"Forward function of BasicVSR.\n\n        Args:\n            x: Input frames with shape (b, n, c, h, w). n is the temporal dimension / number of frames.\n        \"\"\"\n        flows_forward, flows_backward = self.get_flow(x)\n        b, n, _, h, w = x.size()\n\n        # backward branch\n        out_l = []\n        feat_prop = x.new_zeros(b, self.num_feat, h, w)\n        for i in range(n - 1, -1, -1):\n            x_i = x[:, i, :, :, :]\n            if i < n - 1:\n                flow = flows_backward[:, i, :, :, :]\n                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))\n            feat_prop = torch.cat([x_i, feat_prop], dim=1)\n            feat_prop = self.backward_trunk(feat_prop)\n            out_l.insert(0, feat_prop)\n\n        # forward branch\n        feat_prop = torch.zeros_like(feat_prop)\n        for i in range(0, n):\n            x_i = x[:, i, :, :, :]\n            if i > 0:\n                flow = flows_forward[:, i - 1, :, :, :]\n                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))\n\n            feat_prop = torch.cat([x_i, feat_prop], dim=1)\n            feat_prop = self.forward_trunk(feat_prop)\n\n            # upsample\n            out = torch.cat([out_l[i], feat_prop], dim=1)\n            out = self.lrelu(self.fusion(out))\n            out = self.lrelu(self.pixel_shuffle(self.upconv1(out)))\n            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))\n            out = self.lrelu(self.conv_hr(out))\n            out = self.conv_last(out)\n            base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)\n            out += base\n            out_l[i] = out\n\n        return torch.stack(out_l, dim=1)\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}