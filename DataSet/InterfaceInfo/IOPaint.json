{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/IOPaint",
    "API_Calls": [
        {
            "Name": "call_branchprocessing",
            "Description": "call batch_processing",
            "Code": "if __name__ == '__main__':\n    gan = CycleGAN()\n    gan.train(epochs=200, batch_size=1, sample_interval=200)\nimport webbrowser\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\nfrom typing import Optional\n\nimport typer\nfrom fastapi import FastAPI\nfrom loguru import logger\nfrom typer import Option\nfrom typer_config import use_json_config\n\nfrom iopaint.const import *\nfrom iopaint.runtime import setup_model_dir, dump_environment_info, check_device\nfrom iopaint.schema import InteractiveSegModel, Device, RealESRGANModel, RemoveBGModel\n\ntyper_app = typer.Typer(pretty_exceptions_show_locals=False, add_completion=False)\n\n@typer_app.command(help=\"Batch processing images\")\ndef run(\n    model: str = Option(\"lama\"),\n    device: Device = Option(Device.cuda),\n    image: Path = Option(..., help=\"Image folders or file path\"),\n    mask: Path = Option(\n        ...,\n        help=\"Mask folders or file path. \"\n        \"If it is a directory, the mask images in the directory should have the same name as the original image.\"\n        \"If it is a file, all images will use this mask.\"\n        \"Mask will automatically resize to the same size as the original image.\",\n    ),\n    output: Path = Option(..., help=\"Output directory or file path\"),\n    config: Path = Option(\n        None, help=\"Config file path. You can use dump command to create a base config.\"\n    ),\n    concat: bool = Option(\n        False, help=\"Concat original image, mask and output images into one image\"\n    ),\n    model_dir: Path = Option(\n        DEFAULT_MODEL_DIR,\n        help=MODEL_DIR_HELP,\n        file_okay=False,\n        callback=setup_model_dir,\n    ),\n):\n    from iopaint.download import cli_download_model, scan_models\n\n    scanned_models = scan_models()\n    if model not in [it.name for it in scanned_models]:\n        logger.info(f\"{model} not found in {model_dir}, try to downloading\")\n        cli_download_model(model)\n\n    from iopaint.batch_processing import batch_inpaint\n\n    batch_inpaint(model, device, image, mask, output, config, concat)\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/IOPaint/iopaint/cli.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "batch_inpaint",
            "Description": "batch_inpaint impl",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/IOPaint/iopaint/batch_processing.py",
            "Implementation": "import json\nfrom pathlib import Path\nfrom typing import Dict, Optional\n\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom loguru import logger\nfrom rich.console import Console\nfrom rich.progress import (\n    Progress,\n    SpinnerColumn,\n    TimeElapsedColumn,\n    MofNCompleteColumn,\n    TextColumn,\n    BarColumn,\n    TaskProgressColumn,\n)\n\nfrom iopaint.helper import pil_to_bytes\nfrom iopaint.model.utils import torch_gc\nfrom iopaint.model_manager import ModelManager\nfrom iopaint.schema import InpaintRequest\n\n\ndef glob_images(path: Path) -> Dict[str, Path]:\n    # png/jpg/jpeg\n    if path.is_file():\n        return {path.stem: path}\n    elif path.is_dir():\n        res = {}\n        for it in path.glob(\"*.*\"):\n            if it.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]:\n                res[it.stem] = it\n        return res\n\n\ndef batch_inpaint(\n    model: str,\n    device,\n    image: Path,\n    mask: Path,\n    output: Path,\n    config: Optional[Path] = None,\n    concat: bool = False,\n):\n    if image.is_dir() and output.is_file():\n        logger.error(\n            \"invalid --output: when image is a directory, output should be a directory\"\n        )\n        exit(-1)\n    output.mkdir(parents=True, exist_ok=True)\n\n    image_paths = glob_images(image)\n    mask_paths = glob_images(mask)\n    if len(image_paths) == 0:\n        logger.error(\"invalid --image: empty image folder\")\n        exit(-1)\n    if len(mask_paths) == 0:\n        logger.error(\"invalid --mask: empty mask folder\")\n        exit(-1)\n\n    if config is None:\n        inpaint_request = InpaintRequest()\n        logger.info(f\"Using default config: {inpaint_request}\")\n    else:\n        with open(config, \"r\", encoding=\"utf-8\") as f:\n            inpaint_request = InpaintRequest(**json.load(f))\n        logger.info(f\"Using config: {inpaint_request}\")\n\n    model_manager = ModelManager(name=model, device=device)\n    first_mask = list(mask_paths.values())[0]\n\n    console = Console()\n\n    with Progress(\n        SpinnerColumn(),\n        TextColumn(\"[progress.description]{task.description}\"),\n        BarColumn(),\n        TaskProgressColumn(),\n        MofNCompleteColumn(),\n        TimeElapsedColumn(),\n        console=console,\n        transient=False,\n    ) as progress:\n        task = progress.add_task(\"Batch processing...\", total=len(image_paths))\n        for stem, image_p in image_paths.items():\n            if stem not in mask_paths and mask.is_dir():\n                progress.log(f\"mask for {image_p} not found\")\n                progress.update(task, advance=1)\n                continue\n            mask_p = mask_paths.get(stem, first_mask)\n\n            infos = Image.open(image_p).info\n\n            img = np.array(Image.open(image_p).convert(\"RGB\"))\n            mask_img = np.array(Image.open(mask_p).convert(\"L\"))\n\n            if mask_img.shape[:2] != img.shape[:2]:\n                progress.log(\n                    f\"resize mask {mask_p.name} to image {image_p.name} size: {img.shape[:2]}\"\n                )\n                mask_img = cv2.resize(\n                    mask_img,\n                    (img.shape[1], img.shape[0]),\n                    interpolation=cv2.INTER_NEAREST,\n                )\n            mask_img[mask_img >= 127] = 255\n            mask_img[mask_img < 127] = 0\n\n            # bgr\n            inpaint_result = model_manager(img, mask_img, inpaint_request)\n            inpaint_result = cv2.cvtColor(inpaint_result, cv2.COLOR_BGR2RGB)\n            if concat:\n                mask_img = cv2.cvtColor(mask_img, cv2.COLOR_GRAY2RGB)\n                inpaint_result = cv2.hconcat([img, mask_img, inpaint_result])\n\n            img_bytes = pil_to_bytes(Image.fromarray(inpaint_result), \"png\", 100, infos)\n            save_p = output / f\"{stem}.png\"\n            with open(save_p, \"wb\") as fw:\n                fw.write(img_bytes)\n\n            progress.update(task, advance=1)\n            torch_gc()\n            pid = psutil.Process().pid\n            memory_info = psutil.Process(pid).memory_info()\n            memory_in_mb = memory_info.rss / (1024 * 1024)\n            print(f\"原图大小：{img.shape},当前进程的内存占用：{memory_in_mb}MB\")\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}