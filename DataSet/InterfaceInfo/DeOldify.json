{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/DeOldify",
    "API_Calls": [
        {
            "Name": "get_visualized_image",
            "Description": "get_image_colorizer函数调用ModelImageVisualizer类以获取处理后的图像的信息。",
            "Code": "import os\nos.environ['CUDA_VISIBLE_DEVICES']='1'\nos.environ['OMP_NUM_THREADS']='1'\nimport statistics\nfrom fastai import *\nfrom deoldify.visualize import *\nfrom deoldify.visualize import ModelImageVisualizer\nimport cv2\nfrom fid.fid_score import *\nfrom fid.inception import *\nimport imageio\nplt.style.use('dark_background')\ntorch.backends.cudnn.benchmark=True\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.functional\")\nwarnings.filterwarnings(\"ignore\", category=UserWarning, message='.*?retrieve source code for container of type.*?')\n#NOTE:  Data should come from here:  'https://datasets.figure-eight.com/figure_eight_datasets/open-images/test_challenge.zip'\n#NOTE:  Minimum recommmended number of samples is 10K.  Source:  https://github.com/bioinf-jku/TTUR\n\npath = Path('data/ColorBenchmark')\npath_hr = path/'source'\npath_lr = path/'bandw'\npath_results = Path('./result_images/ColorBenchmarkFID/artistic')\npath_rendered = path_results/'rendered'\n\n#path = Path('data/DeOldifyColor')\n#path_hr = path\n#path_lr = path/'bandw'\n#path_results = Path('./result_images/ColorBenchmark/edge')\n#path_rendered = path_results/'rendered'\n\n#num_images = 2048\n#num_images = 15000\nnum_images = 50000\nrender_factor=35\nfid_batch_size = 4\neval_size=299\ndef get_image_colorizer(\n    root_folder: Path = Path('./'), render_factor: int = 35, artistic: bool = True\n) -> ModelImageVisualizer:\n    if artistic:\n        return get_artistic_image_colorizer(root_folder=root_folder, render_factor=render_factor)\n    else:\n        return get_stable_image_colorizer(root_folder=root_folder, render_factor=render_factor)\ndef inception_model(dims:int):\n    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n    model = InceptionV3([block_idx])\n    model.cuda()\n    return model\ndef create_before_images(fn,i):\n    dest = path_lr/fn.relative_to(path_hr)\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    img = PIL.Image.open(fn).convert('LA').convert('RGB')\n    img.save(dest)  \ndef render_images(colorizer, source_dir:Path, filtered_dir:Path, target_dir:Path, render_factor:int, num_images:int)->[(Path, Path, Path)]:\n    results = []\n    bandw_list = ImageList.from_folder(path_lr)\n    bandw_list = bandw_list[:num_images]\n\n    if len(bandw_list.items) == 0: return results\n\n    results = []\n    img_iterator = progress_bar(bandw_list.items)\n\n    for bandw_path in img_iterator:\n        target_path = target_dir/bandw_path.relative_to(source_dir)\n\n        try:\n            result_image = colorizer.get_transformed_image(path=bandw_path, render_factor=render_factor)\n            result_path = Path(str(path_results) + '/' + bandw_path.parent.name + '/' + bandw_path.name)\n            if not result_path.parent.exists():\n                result_path.parent.mkdir(parents=True, exist_ok=True)\n            result_image.save(result_path)\n            results.append((result_path, bandw_path, target_path))\n        except Exception as err:\n            print('Failed to render image.  Skipping.  Details: {0}'.format(err))\n    \n    return results \ndef calculate_fid_score(render_results, bs:int, eval_size:int):\n    dims = 2048\n    cuda = True\n    model = inception_model(dims=dims)\n    rendered_paths = []\n    target_paths = []\n    \n    for render_result in render_results:\n        rendered_path, _, target_path = render_result\n        rendered_paths.append(str(rendered_path))\n        target_paths.append(str(target_path))\n        \n    rendered_m, rendered_s = calculate_activation_statistics(files=rendered_paths, model=model, batch_size=bs, dims=dims, cuda=cuda)\n    target_m, target_s = calculate_activation_statistics(files=target_paths, model=model, batch_size=bs, dims=dims, cuda=cuda)\n    fid_score = calculate_frechet_distance(rendered_m, rendered_s, target_m, target_s)\n    del model\n    return fid_score\nif not path_lr.exists():\n    il = ImageList.from_folder(path_hr)\n    parallel(create_before_images, il.items)\npath_results.parent.mkdir(parents=True, exist_ok=True)\ncolorizer = get_image_colorizer(artistic=True)\nrender_results = render_images(colorizer=colorizer, source_dir=path_lr, target_dir=path_hr, filtered_dir=path_results, render_factor=render_factor, num_images=num_images)\nfid_score = calculate_fid_score(render_results, bs=fid_batch_size, eval_size=eval_size)\nprint('FID Score: ' + str(fid_score))",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/DeOldify/ColorFIDBenchipynbmarkArtistic."
        }
    ],
    "API_Implementations": [
        {
            "Name": "class_ModelImageVisualizer",
            "Description": "ModelImageVisualizer 类提供了一套完整的图像处理、可视化和保存的功能，可用于对图像进行上色等处理，并将处理结果可视化和保存。",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/DeOldify/deoldify/visualize.py",
            "Implementation": "from fastai.core import *\nfrom fastai.vision import *\nfrom matplotlib.axes import Axes\nfrom .filters import IFilter, MasterFilter, ColorizerFilter\nfrom .generators import gen_inference_deep, gen_inference_wide\nfrom PIL import Image\nimport ffmpeg\nimport yt_dlp as youtube_dl\nimport gc\nimport requests\nfrom io import BytesIO\nimport base64\nfrom IPython import display as ipythondisplay\nfrom IPython.display import HTML\nfrom IPython.display import Image as ipythonimage\nimport cv2\nimport logging\n\n# adapted from https://www.pyimagesearch.com/2016/04/25/watermarking-images-with-opencv-and-python/\ndef get_watermarked(pil_image: Image) -> Image:\n    try:\n        image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n        (h, w) = image.shape[:2]\n        image = np.dstack([image, np.ones((h, w), dtype=\"uint8\") * 255])\n        pct = 0.05\n        full_watermark = cv2.imread(\n            './resource_images/watermark.png', cv2.IMREAD_UNCHANGED\n        )\n        (fwH, fwW) = full_watermark.shape[:2]\n        wH = int(pct * h)\n        wW = int((pct * h / fwH) * fwW)\n        watermark = cv2.resize(full_watermark, (wH, wW), interpolation=cv2.INTER_AREA)\n        overlay = np.zeros((h, w, 4), dtype=\"uint8\")\n        (wH, wW) = watermark.shape[:2]\n        overlay[h - wH - 10 : h - 10, 10 : 10 + wW] = watermark\n        # blend the two images together using transparent overlays\n        output = image.copy()\n        cv2.addWeighted(overlay, 0.5, output, 1.0, 0, output)\n        rgb_image = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n        final_image = Image.fromarray(rgb_image)\n        return final_image\n    except:\n        # Don't want this to crash everything, so let's just not watermark the image for now.\n        return pil_image\n\n\nclass ModelImageVisualizer:\n    def __init__(self, filter: IFilter, results_dir: str = None):\n        self.filter = filter\n        self.results_dir = None if results_dir is None else Path(results_dir)\n        self.results_dir.mkdir(parents=True, exist_ok=True)\n\n    def _clean_mem(self):\n        torch.cuda.empty_cache()\n        # gc.collect()\n\n    def _open_pil_image(self, path: Path) -> Image:\n        return PIL.Image.open(path).convert('RGB')\n\n    def _get_image_from_url(self, url: str) -> Image:\n        response = requests.get(url, timeout=30, headers={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'})\n        img = PIL.Image.open(BytesIO(response.content)).convert('RGB')\n        return img\n\n    def plot_transformed_image_from_url(\n        self,\n        url: str,\n        path: str = 'test_images/image.png',\n        results_dir:Path = None,\n        figsize: Tuple[int, int] = (20, 20),\n        render_factor: int = None,\n        \n        display_render_factor: bool = False,\n        compare: bool = False,\n        post_process: bool = True,\n        watermarked: bool = True,\n    ) -> Path:\n        img = self._get_image_from_url(url)\n        img.save(path)\n        return self.plot_transformed_image(\n            path=path,\n            results_dir=results_dir,\n            figsize=figsize,\n            render_factor=render_factor,\n            display_render_factor=display_render_factor,\n            compare=compare,\n            post_process = post_process,\n            watermarked=watermarked,\n        )\n\n    def plot_transformed_image(\n        self,\n        path: str,\n        results_dir:Path = None,\n        figsize: Tuple[int, int] = (20, 20),\n        render_factor: int = None,\n        display_render_factor: bool = False,\n        compare: bool = False,\n        post_process: bool = True,\n        watermarked: bool = True,\n    ) -> Path:\n        path = Path(path)\n        if results_dir is None:\n            results_dir = Path(self.results_dir)\n        result = self.get_transformed_image(\n            path, render_factor, post_process=post_process,watermarked=watermarked\n        )\n        orig = self._open_pil_image(path)\n        if compare:\n            self._plot_comparison(\n                figsize, render_factor, display_render_factor, orig, result\n            )\n        else:\n            self._plot_solo(figsize, render_factor, display_render_factor, result)\n\n        orig.close()\n        result_path = self._save_result_image(path, result, results_dir=results_dir)\n        result.close()\n        return result_path\n\n    def _plot_comparison(\n        self,\n        figsize: Tuple[int, int],\n        render_factor: int,\n        display_render_factor: bool,\n        orig: Image,\n        result: Image,\n    ):\n        fig, axes = plt.subplots(1, 2, figsize=figsize)\n        self._plot_image(\n            orig,\n            axes=axes[0],\n            figsize=figsize,\n            render_factor=render_factor,\n            display_render_factor=False,\n        )\n        self._plot_image(\n            result,\n            axes=axes[1],\n            figsize=figsize,\n            render_factor=render_factor,\n            display_render_factor=display_render_factor,\n        )\n\n    def _plot_solo(\n        self,\n        figsize: Tuple[int, int],\n        render_factor: int,\n        display_render_factor: bool,\n        result: Image,\n    ):\n        fig, axes = plt.subplots(1, 1, figsize=figsize)\n        self._plot_image(\n            result,\n            axes=axes,\n            figsize=figsize,\n            render_factor=render_factor,\n            display_render_factor=display_render_factor,\n        )\n\n    def _save_result_image(self, source_path: Path, image: Image, results_dir = None) -> Path:\n        if results_dir is None:\n            results_dir = Path(self.results_dir)\n        result_path = results_dir / source_path.name\n        image.save(result_path)\n        return result_path\n\n    def get_transformed_image(\n        self, path: Path, render_factor: int = None, post_process: bool = True,\n        watermarked: bool = True,\n    ) -> Image:\n        self._clean_mem()\n        orig_image = self._open_pil_image(path)\n        filtered_image = self.filter.filter(\n            orig_image, orig_image, render_factor=render_factor,post_process=post_process\n        )\n\n        if watermarked:\n            return get_watermarked(filtered_image)\n\n        return filtered_image\n\n    def _plot_image(\n        self,\n        image: Image,\n        render_factor: int,\n        axes: Axes = None,\n        figsize=(20, 20),\n        display_render_factor = False,\n    ):\n        if axes is None:\n            _, axes = plt.subplots(figsize=figsize)\n        axes.imshow(np.asarray(image) / 255)\n        axes.axis('off')\n        if render_factor is not None and display_render_factor:\n            plt.text(\n                10,\n                10,\n                'render_factor: ' + str(render_factor),\n                color='white',\n                backgroundcolor='black',\n            )\n\n    def _get_num_rows_columns(self, num_images: int, max_columns: int) -> Tuple[int, int]:\n        columns = min(num_images, max_columns)\n        rows = num_images // columns\n        rows = rows if rows * columns == num_images else rows + 1\n        return rows, columns\n",
            "Examples": [
                "import unittest\nimport os\nfrom deoldify.filters import ColorizerFilter\nfrom deoldify.visualize import ModelImageVisualizer\nfrom fastai.vision.image import open_image\nfrom PIL import Image as PilImage\nfrom fastai.basic_train import Learner\nfrom fastai.vision import imagenet_stats, DataBunch, ImageList\nfrom fastai.torch_core import Path\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\n\n# 创建一个更接近 DeOldify 期望的模型结构\nclass DeOldifyModel(nn.Module):\n    def __init__(self):\n        super(DeOldifyModel, self).__init__()\n        # 定义一个简化的模型结构，包含编码器和解码器部分\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.Sigmoid()  # 确保输出在 [0,1] 范围内\n        )\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\nclass TestImageGeneration(unittest.TestCase):\n    def setUp(self):\n        # 创建一个简单的 DataBunch 对象\n        path = Path('test_images')\n        data = (ImageList.from_folder(path)\n                .split_by_rand_pct()\n                .label_from_folder()\n                .databunch())\n\n        # 使用更接近 DeOldify 的模型结构\n        model = DeOldifyModel()\n\n        # 创建 Learner 对象\n        learn = Learner(data, model)\n\n        # 创建滤镜实例，使用 ColorizerFilter 替代 BaseFilter\n        filter = ColorizerFilter(learn, stats=imagenet_stats)\n\n        # 创建可视化器实例\n        self.visualizer = ModelImageVisualizer(filter, results_dir='results')\n\n        # 测试图像路径\n        self.test_image_path = 'test_images/test.jpg'\n\n    def test_image_generation(self):\n        if os.path.exists(self.test_image_path):\n            # 打开测试图像\n            orig_image = open_image(self.test_image_path)\n            \n            # 转换为 PIL 图像\n            pil_orig_image = PilImage.fromarray((orig_image.data * 255).permute(1, 2, 0).numpy().astype('uint8'))\n\n            # 调用模型处理方法\n            try:\n                result_image = self.visualizer.filter._model_process(pil_orig_image, sz=256)\n                self.assertIsNotNone(result_image)\n\n                # 保存处理后的图像\n                result_path = os.path.join('results', 'test_result.jpg')\n                result_image.save(result_path)\n                self.assertTrue(os.path.exists(result_path))\n            except Exception as e:\n                self.fail(f\"图像生成过程中出现错误: {e}\")\n        else:\n            print(f\"测试图像 {self.test_image_path} 不存在，请检查路径。\")\n\n\nif __name__ == '__main__':\n    unittest.main()\n\n"
            ]
        }
    ]
}