{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/LaTeX-OCR",
    "API_Calls": [
        {
            "Name": "call_Latex",
            "Description": "call LateX",
            "Code": "# Adapted from https://github.com/kingyiusuen/image-to-latex/blob/main/api/app.py\n\nfrom http import HTTPStatus\nfrom fastapi import FastAPI, File, UploadFile, Form\nfrom PIL import Image\nfrom io import BytesIO\nfrom pix2tex.cli import LatexOCR\n\nmodel = None\napp = FastAPI(title='pix2tex API')\n\n\ndef read_imagefile(file) -> Image.Image:\n    image = Image.open(BytesIO(file))\n    return image\n\n\n@app.on_event('startup')\nasync def load_model():\n    global model\n    if model is None:\n        model = LatexOCR()\n\n\n@app.get('/')\ndef root():\n    '''Health check.'''\n    response = {\n        'message': HTTPStatus.OK.phrase,\n        'status-code': HTTPStatus.OK,\n        'data': {},\n    }\n    return response\n\n\n@app.post('/predict/')\nasync def predict(file: UploadFile = File(...)) -> str:\n    \"\"\"Predict the Latex code from an image file.\n\n    Args:\n        file (UploadFile, optional): Image to predict. Defaults to File(...).\n\n    Returns:\n        str: Latex prediction\n    \"\"\"\n    global model\n    image = Image.open(file.file)\n    return model(image)\n\n\n@app.post('/bytes/')\nasync def predict_from_bytes(file: bytes = File(...)) -> str:  # , size: str = Form(...)\n    \"\"\"Predict the Latex code from a byte array\n\n    Args:\n        file (bytes, optional): Image as byte array. Defaults to File(...).\n\n    Returns:\n        str: Latex prediction\n    \"\"\"\n    global model\n    #size = tuple(int(a) for a in size.split(','))\n    image = Image.open(BytesIO(file))\n    return model(image, resize=False)\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/LaTeX-OCR/pix2tex/api/app.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "LatexOCR",
            "Description": "LatexOCR",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/LaTeX-OCR/pix2tex/cli.py",
            "Implementation": "from pix2tex.dataset.transforms import test_transform\nimport pandas.io.clipboard as clipboard\nfrom PIL import ImageGrab\nfrom PIL import Image\nimport os\nfrom pathlib import Path\nimport sys\nfrom typing import List, Optional, Tuple\nimport atexit\nfrom contextlib import suppress\nimport logging\nimport yaml\nimport re\n\nwith suppress(ImportError, AttributeError):\n    import readline\n\nimport numpy as np\nimport torch\nfrom torch._appdirs import user_data_dir\nfrom munch import Munch\nfrom transformers import PreTrainedTokenizerFast\nfrom timm.models.resnetv2 import ResNetV2\nfrom timm.models.layers import StdConv2dSame\n\nfrom pix2tex.dataset.latex2png import tex2pil\nfrom pix2tex.models import get_model\nfrom pix2tex.utils import *\nfrom pix2tex.model.checkpoints.get_latest_checkpoint import download_checkpoints\n\nclass LatexOCR:\n    '''Get a prediction of an image in the easiest way'''\n\n    image_resizer = None\n    last_pic = None\n\n    @in_model_path()\n    def __init__(self, arguments=None):\n        \"\"\"Initialize a LatexOCR model\n\n        Args:\n            arguments (Union[Namespace, Munch], optional): Special model parameters. Defaults to None.\n        \"\"\"\n        if arguments is None:\n            arguments = Munch({'config': 'settings/config.yaml', 'checkpoint': 'checkpoints/weights.pth', 'no_cuda': True, 'no_resize': False})\n        logging.getLogger().setLevel(logging.FATAL)\n        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n        with open(arguments.config, 'r') as f:\n            params = yaml.load(f, Loader=yaml.FullLoader)\n        self.args = parse_args(Munch(params))\n        self.args.update(**vars(arguments))\n        self.args.wandb = False\n        self.args.device = 'cuda' if torch.cuda.is_available() and not self.args.no_cuda else 'cpu'\n        if not os.path.exists(self.args.checkpoint):\n            download_checkpoints()\n        self.model = get_model(self.args)\n        self.model.load_state_dict(torch.load(self.args.checkpoint, map_location=self.args.device))\n        self.model.eval()\n\n        if 'image_resizer.pth' in os.listdir(os.path.dirname(self.args.checkpoint)) and not arguments.no_resize:\n            self.image_resizer = ResNetV2(layers=[2, 3, 3], num_classes=max(self.args.max_dimensions)//32, global_pool='avg', in_chans=1, drop_rate=.05,\n                                          preact=True, stem_type='same', conv_layer=StdConv2dSame).to(self.args.device)\n            self.image_resizer.load_state_dict(torch.load(os.path.join(os.path.dirname(self.args.checkpoint), 'image_resizer.pth'), map_location=self.args.device))\n            self.image_resizer.eval()\n        self.tokenizer = PreTrainedTokenizerFast(tokenizer_file=self.args.tokenizer)\n\n    @in_model_path()\n    def __call__(self, img=None, resize=True) -> str:\n        \"\"\"Get a prediction from an image\n\n        Args:\n            img (Image, optional): Image to predict. Defaults to None.\n            resize (bool, optional): Whether to call the resize model. Defaults to True.\n\n        Returns:\n            str: predicted Latex code\n        \"\"\"\n        if type(img) is bool:\n            img = None\n        if img is None:\n            if self.last_pic is None:\n                return ''\n            else:\n                print('\\nLast image is: ', end='')\n                img = self.last_pic.copy()\n        else:\n            self.last_pic = img.copy()\n        img = minmax_size(pad(img), self.args.max_dimensions, self.args.min_dimensions)\n        if (self.image_resizer is not None and not self.args.no_resize) and resize:\n            with torch.no_grad():\n                input_image = img.convert('RGB').copy()\n                r, w, h = 1, input_image.size[0], input_image.size[1]\n                for _ in range(10):\n                    h = int(h * r)  # height to resize\n                    img = pad(minmax_size(input_image.resize((w, h), Image.Resampling.BILINEAR if r > 1 else Image.Resampling.LANCZOS), self.args.max_dimensions, self.args.min_dimensions))\n                    t = test_transform(image=np.array(img.convert('RGB')))['image'][:1].unsqueeze(0)\n                    w = (self.image_resizer(t.to(self.args.device)).argmax(-1).item()+1)*32\n                    logging.info(r, img.size, (w, int(input_image.size[1]*r)))\n                    if (w == img.size[0]):\n                        break\n                    r = w/img.size[0]\n        else:\n            img = np.array(pad(img).convert('RGB'))\n            t = test_transform(image=img)['image'][:1].unsqueeze(0)\n        im = t.to(self.args.device)\n\n        dec = self.model.generate(im.to(self.args.device), temperature=self.args.get('temperature', .25))\n        pred = post_process(token2str(dec, self.tokenizer)[0])\n        try:\n            clipboard.copy(pred)\n        except:\n            pass\n        return pred",
            "Examples": [
                "\n"
            ]
        }
    ]
}