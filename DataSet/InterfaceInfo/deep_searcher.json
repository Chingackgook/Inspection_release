{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/deep-searcher",
    "API_Calls": [
        {
            "Name": "call_query",
            "Description": "call_query",
            "Code": "import argparse\nimport logging\nimport sys\nimport warnings\n\nfrom deepsearcher.configuration import Configuration, init_config\nfrom deepsearcher.offline_loading import load_from_local_files, load_from_website\nfrom deepsearcher.online_query import query\nfrom deepsearcher.utils import log\n\nhttpx_logger = logging.getLogger(\"httpx\")  # disable openai's logger output\nhttpx_logger.setLevel(logging.WARNING)\n\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)  # disable warning output\n\n\ndef main():\n    \"\"\"\n    Main entry point for the DeepSearcher CLI.\n\n    This function parses command line arguments and executes the appropriate action\n    based on the subcommand provided (query or load). It handles the deprecated\n    command line format and provides helpful error messages.\n\n    Returns:\n        None\n    \"\"\"\n    if \"--query\" in sys.argv or \"--load\" in sys.argv:\n        print(\"\\033[91m[Deprecated]\\033[0m The use of '--query' and '--load' is deprecated.\")\n        print(\"Please use:\")\n        print(\"  deepsearcher query <your_query> --max_iter 3\")\n        print(\n            \"  deepsearcher load <your_local_path_or_url> --collection_name <your_collection_name> --collection_desc <your_collection_description>\"\n        )\n        sys.exit(1)\n\n    config = Configuration()  # Customize your config here\n    init_config(config=config)\n\n    parser = argparse.ArgumentParser(prog=\"deepsearcher\", description=\"Deep Searcher.\")\n    subparsers = parser.add_subparsers(dest=\"subcommand\", title=\"subcommands\")\n\n    ## Arguments of query\n    query_parser = subparsers.add_parser(\"query\", help=\"Query a question or search topic.\")\n    query_parser.add_argument(\"query\", type=str, default=\"\", help=\"query question or search topic.\")\n    query_parser.add_argument(\n        \"--max_iter\",\n        type=int,\n        default=3,\n        help=\"Max iterations of reflection. Default is 3.\",\n    )\n\n    ## Arguments of loading\n    load_parser = subparsers.add_parser(\n        \"load\", help=\"Load knowledge from local files or from URLs.\"\n    )\n    load_parser.add_argument(\n        \"load_path\",\n        type=str,\n        nargs=\"+\",  # 1 or more files or urls\n        help=\"Load knowledge from local files or from URLs.\",\n    )\n    load_parser.add_argument(\n        \"--batch_size\",\n        type=int,\n        default=256,\n        help=\"Batch size for loading knowledge.\",\n    )\n    load_parser.add_argument(\n        \"--collection_name\",\n        type=str,\n        default=None,\n        help=\"Destination collection name of loaded knowledge.\",\n    )\n    load_parser.add_argument(\n        \"--collection_desc\",\n        type=str,\n        default=None,\n        help=\"Description of the collection.\",\n    )\n    load_parser.add_argument(\n        \"--force_new_collection\",\n        type=bool,\n        default=False,\n        help=\"If you want to drop origin collection and create a new collection on every load, set to True\",\n    )\n\n    args = parser.parse_args()\n    if args.subcommand == \"query\":\n        final_answer, refs, consumed_tokens = query(args.query, max_iter=args.max_iter)\n        log.color_print(\"\\n==== FINAL ANSWER====\\n\")\n        log.color_print(final_answer)\n        log.color_print(\"\\n### References\\n\")\n        for i, ref in enumerate(refs):\n            log.color_print(f\"{i + 1}. {ref.text[:60]}â€¦ {ref.reference}\")\n    elif args.subcommand == \"load\":\n        urls = [url for url in args.load_path if url.startswith(\"http\")]\n        local_files = [file for file in args.load_path if not file.startswith(\"http\")]\n        kwargs = {}\n        if args.collection_name:\n            kwargs[\"collection_name\"] = args.collection_name\n        if args.collection_desc:\n            kwargs[\"collection_description\"] = args.collection_desc\n        if args.force_new_collection:\n            kwargs[\"force_new_collection\"] = args.force_new_collection\n        if args.batch_size:\n            kwargs[\"batch_size\"] = args.batch_size\n        if len(urls) > 0:\n            load_from_website(urls, **kwargs)\n        if len(local_files) > 0:\n            load_from_local_files(local_files, **kwargs)\n    else:\n        print(\"Please provide a query or a load argument.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/deep-searcher/deepsearcher/cli.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "query",
            "Description": "query impl",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/deep-searcher/deepsearcher/online_query.py",
            "Implementation": "from typing import List, Tuple\n\n# from deepsearcher.configuration import vector_db, embedding_model, llm\nfrom deepsearcher import configuration\nfrom deepsearcher.vector_db.base import RetrievalResult\n\n\ndef query(original_query: str, max_iter: int = 3) -> Tuple[str, List[RetrievalResult], int]:\n    \"\"\"\n    Query the knowledge base with a question and get an answer.\n\n    This function uses the default searcher to query the knowledge base and generate\n    an answer based on the retrieved information.\n\n    Args:\n        original_query: The question or query to search for.\n        max_iter: Maximum number of iterations for the search process.\n\n    Returns:\n        A tuple containing:\n            - The generated answer as a string\n            - A list of retrieval results that were used to generate the answer\n            - The number of tokens consumed during the process\n    \"\"\"\n    default_searcher = configuration.default_searcher\n    return default_searcher.query(original_query, max_iter=max_iter)\n\n\ndef retrieve(\n    original_query: str, max_iter: int = 3\n) -> Tuple[List[RetrievalResult], List[str], int]:\n    \"\"\"\n    Retrieve relevant information from the knowledge base without generating an answer.\n\n    This function uses the default searcher to retrieve information from the knowledge base\n    that is relevant to the query.\n\n    Args:\n        original_query: The question or query to search for.\n        max_iter: Maximum number of iterations for the search process.\n\n    Returns:\n        A tuple containing:\n            - A list of retrieval results\n            - An empty list (placeholder for future use)\n            - The number of tokens consumed during the process\n    \"\"\"\n    default_searcher = configuration.default_searcher\n    retrieved_results, consume_tokens, metadata = default_searcher.retrieve(\n        original_query, max_iter=max_iter\n    )\n    return retrieved_results, [], consume_tokens\n\n\ndef naive_retrieve(query: str, collection: str = None, top_k=10) -> List[RetrievalResult]:\n    \"\"\"\n    Perform a simple retrieval from the knowledge base using the naive RAG approach.\n\n    This function uses the naive RAG agent to retrieve information from the knowledge base\n    without any advanced techniques like iterative refinement.\n\n    Args:\n        query: The question or query to search for.\n        collection: The name of the collection to search in. If None, searches in all collections.\n        top_k: The maximum number of results to return.\n\n    Returns:\n        A list of retrieval results.\n    \"\"\"\n    naive_rag = configuration.naive_rag\n    all_retrieved_results, consume_tokens, _ = naive_rag.retrieve(query)\n    return all_retrieved_results\n\n\ndef naive_rag_query(\n    query: str, collection: str = None, top_k=10\n) -> Tuple[str, List[RetrievalResult]]:\n    \"\"\"\n    Query the knowledge base using the naive RAG approach and get an answer.\n\n    This function uses the naive RAG agent to query the knowledge base and generate\n    an answer based on the retrieved information, without any advanced techniques.\n\n    Args:\n        query: The question or query to search for.\n        collection: The name of the collection to search in. If None, searches in all collections.\n        top_k: The maximum number of results to consider.\n\n    Returns:\n        A tuple containing:\n            - The generated answer as a string\n            - A list of retrieval results that were used to generate the answer\n    \"\"\"\n    naive_rag = configuration.naive_rag\n    answer, retrieved_results, consume_tokens = naive_rag.query(query)\n    return answer, retrieved_results\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}