{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/autokeras",
    "API_Calls": [
        {
            "Name": "call_TextClassifier",
            "Description": "call_TextClassifier",
            "Code": "\"\"\"\nSearch for a good model for the\n[IMDB](\nhttps://keras.io/datasets/#imdb-movie-reviews-sentiment-classification) dataset.\n\"\"\"\n\nimport keras\nimport numpy as np\n\nimport autokeras as ak\n\n\ndef imdb_raw():\n    max_features = 20000\n    index_offset = 3  # word index offset\n\n    (x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n        num_words=max_features, index_from=index_offset\n    )\n    x_train = x_train[:2]\n    y_train = y_train.reshape(-1, 1)[:2]\n    x_test = x_test[:1]\n    y_test = y_test.reshape(-1, 1)[:1]\n\n    word_to_id = keras.datasets.imdb.get_word_index()\n    word_to_id = {k: (v + index_offset) for k, v in word_to_id.items()}\n    word_to_id[\"<PAD>\"] = 0\n    word_to_id[\"<START>\"] = 1\n    word_to_id[\"<UNK>\"] = 2\n\n    id_to_word = {value: key for key, value in word_to_id.items()}\n    x_train = list(\n        map(lambda sentence: \" \".join(id_to_word[i] for i in sentence), x_train)\n    )\n    x_test = list(\n        map(lambda sentence: \" \".join(id_to_word[i] for i in sentence), x_test)\n    )\n    x_train = np.array(x_train, dtype=str)\n    x_test = np.array(x_test, dtype=str)\n    return (x_train, y_train), (x_test, y_test)\n\n\n# Prepare the data.\n(x_train, y_train), (x_test, y_test) = imdb_raw()\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_train[0][:50])  # <START> this film was just brilliant casting <UNK>\n\n# Initialize the TextClassifier\nclf = ak.TextClassifier(max_trials=3)\n# Search for the best model.\nclf.fit(x_train, y_train, epochs=1, batch_size=1)\n# Evaluate on the testing data.\nprint(\"Accuracy: {accuracy}\".format(accuracy=clf.evaluate(x_test, y_test)))\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/autokeras/examples/imdb.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "TextClassifier",
            "Description": "TextClassifier impl",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/autokeras/autokeras/tasks/text.py",
            "Implementation": "from pathlib import Path\nfrom typing import Optional\nfrom typing import Type\nfrom typing import Union\n\nfrom autokeras import auto_model\nfrom autokeras import blocks\nfrom autokeras import nodes as input_module\nfrom autokeras.engine import tuner\nfrom autokeras.tuners import greedy\nfrom autokeras.tuners import task_specific\nfrom autokeras.utils import types\n\nclass AutoModel(object):\n    def __init__(\n        self,\n        inputs: Union[Input, List[Input]],\n        outputs: Union[head_module.Head, node_module.Node, list],\n        project_name: str = \"auto_model\",\n        max_trials: int = 100,\n        directory: Union[str, Path, None] = None,\n        objective: str = \"val_loss\",\n        tuner: Union[str, Type[tuner.AutoTuner]] = \"greedy\",\n        overwrite: bool = False,\n        seed: Optional[int] = None,\n        max_model_size: Optional[int] = None,\n        **kwargs\n    ):\n        self.inputs = tree.flatten(inputs)\n        self.outputs = tree.flatten(outputs)\n        self.seed = seed\n        if seed:\n            np.random.seed(seed)\n            tf.random.set_seed(seed)\n        # TODO: Support passing a tuner instance.\n        # Initialize the hyper_graph.\n        graph = self._build_graph()\n        if isinstance(tuner, str):\n            tuner = get_tuner_class(tuner)\n        self.tuner = tuner(\n            hypermodel=graph,\n            overwrite=overwrite,\n            objective=objective,\n            max_trials=max_trials,\n            directory=directory,\n            seed=self.seed,\n            project_name=project_name,\n            max_model_size=max_model_size,\n            **kwargs\n        )\n        self.overwrite = overwrite\n        self._heads = [output_node.in_blocks[0] for output_node in self.outputs]\n    def predict(self, x, batch_size=32, verbose=1, **kwargs):\n        \"\"\"Predict the output for a given testing data.\n\n        # Arguments\n            x: Any allowed types according to the input node. Testing data.\n            batch_size: Number of samples per batch.\n                If unspecified, batch_size will default to 32.\n            verbose: Verbosity mode. 0 = silent, 1 = progress bar.\n                Controls the verbosity of\n                [keras.Model.predict](https://tensorflow.org/api_docs/python/tf/keras/Model#predict)\n            **kwargs: Any arguments supported by keras.Model.predict.\n\n        # Returns\n            A list of numpy.ndarray objects or a single numpy.ndarray.\n            The predicted results.\n        \"\"\"\n        if isinstance(x, tf.data.Dataset) and self._has_y(x):\n            x = x.map(lambda x, y: x)\n        self._check_data_format((x, None), predict=True)\n        dataset = self._adapt(x, self.inputs, batch_size)\n        pipeline = self.tuner.get_best_pipeline()\n        model = self.tuner.get_best_model()\n        dataset = pipeline.transform_x(dataset)\n        dataset = tf.data.Dataset.zip((dataset, dataset))\n        y = model.predict(dataset, **kwargs)\n        y = utils.predict_with_adaptive_batch_size(\n            model=model,\n            batch_size=batch_size,\n            x=dataset,\n            verbose=verbose,\n            **kwargs\n        )\n        return pipeline.postprocess(y)\n\n    def evaluate(self, x, y=None, batch_size=32, verbose=1, **kwargs):\n        \"\"\"Evaluate the best model for the given data.\n\n        # Arguments\n            x: Any allowed types according to the input node. Testing data.\n            y: Any allowed types according to the head. Testing targets.\n                Defaults to None.\n            batch_size: Number of samples per batch.\n                If unspecified, batch_size will default to 32.\n            verbose: Verbosity mode. 0 = silent, 1 = progress bar.\n                Controls the verbosity of\n                [keras.Model.evaluate](http://tensorflow.org/api_docs/python/tf/keras/Model#evaluate)\n            **kwargs: Any arguments supported by keras.Model.evaluate.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs and/or\n            metrics). The attribute model.metrics_names will give you the\n            display labels for the scalar outputs.\n        \"\"\"\n        self._check_data_format((x, y))\n        if isinstance(x, tf.data.Dataset):\n            dataset = x\n            x = dataset.map(lambda x, y: x)\n            y = dataset.map(lambda x, y: y)\n        x = self._adapt(x, self.inputs, batch_size)\n        y = self._adapt(y, self._heads, batch_size)\n        dataset = tf.data.Dataset.zip((x, y))\n        pipeline = self.tuner.get_best_pipeline()\n        dataset = pipeline.transform(dataset)\n        model = self.tuner.get_best_model()\n        return utils.evaluate_with_adaptive_batch_size(\n            model=model,\n            batch_size=batch_size,\n            x=dataset,\n            verbose=verbose,\n            **kwargs\n        )\n\n\nclass SupervisedTextPipeline(auto_model.AutoModel):\n    def __init__(self, outputs, **kwargs):\n        super().__init__(\n            inputs=input_module.TextInput(), outputs=outputs, **kwargs\n        )\n\nclass TextClassifier(SupervisedTextPipeline):\n    \"\"\"AutoKeras text classification class.\n\n    # Arguments\n        num_classes: Int. Defaults to None. If None, it will be inferred from\n            the data.\n        multi_label: Boolean. Defaults to False.\n        loss: A Keras loss function. Defaults to use 'binary_crossentropy' or\n            'categorical_crossentropy' based on the number of classes.\n        metrics: A list of Keras metrics. Defaults to use 'accuracy'.\n        project_name: String. The name of the AutoModel.\n            Defaults to 'text_classifier'.\n        max_trials: Int. The maximum number of different Keras Models to try.\n            The search may finish before reaching the max_trials. Defaults to\n            100.\n        directory: String. The path to a directory for storing the search\n            outputs. Defaults to None, which would create a folder with the\n            name of the AutoModel in the current directory.\n        objective: String. Name of model metric to minimize\n            or maximize, e.g. 'val_accuracy'. Defaults to 'val_loss'.\n        tuner: String or subclass of AutoTuner. If string, it should be one of\n            'greedy', 'bayesian', 'hyperband' or 'random'. It can also be a\n            subclass of AutoTuner. If left unspecified, it uses a task specific\n            tuner, which first evaluates the most commonly used models for the\n            task before exploring other models.\n        overwrite: Boolean. Defaults to `False`. If `False`, reloads an existing\n            project of the same name if one is found. Otherwise, overwrites the\n            project.\n        seed: Int. Random seed.\n        max_model_size: Int. Maximum number of scalars in the parameters of a\n            model. Models larger than this are rejected.\n        **kwargs: Any arguments supported by AutoModel.\n    \"\"\"\n\n    def __init__(\n        self,\n        num_classes: Optional[int] = None,\n        multi_label: bool = False,\n        loss: types.LossType = None,\n        metrics: Optional[types.MetricsType] = None,\n        project_name: str = \"text_classifier\",\n        max_trials: int = 100,\n        directory: Union[str, Path, None] = None,\n        objective: str = \"val_loss\",\n        tuner: Union[str, Type[tuner.AutoTuner]] = None,\n        overwrite: bool = False,\n        seed: Optional[int] = None,\n        max_model_size: Optional[int] = None,\n        **kwargs\n    ):\n        if tuner is None:\n            tuner = task_specific.TextClassifierTuner\n        super().__init__(\n            outputs=blocks.ClassificationHead(\n                num_classes=num_classes,\n                multi_label=multi_label,\n                loss=loss,\n                metrics=metrics,\n            ),\n            max_trials=max_trials,\n            directory=directory,\n            project_name=project_name,\n            objective=objective,\n            tuner=tuner,\n            overwrite=overwrite,\n            seed=seed,\n            max_model_size=max_model_size,\n            **kwargs\n        )\n\n    def fit(\n        self,\n        x=None,\n        y=None,\n        epochs=None,\n        callbacks=None,\n        validation_split=0.2,\n        validation_data=None,\n        **kwargs\n    ):\n        \"\"\"Search for the best model and hyperparameters for the AutoModel.\n\n        It will search for the best model based on the performances on\n        validation data.\n\n        # Arguments\n            x: numpy.ndarray or tensorflow.Dataset. Training data x. The input\n                data should be numpy.ndarray or tf.data.Dataset. The data should\n                be one dimensional. Each element in the data should be a string\n                which is a full sentence.\n            y: numpy.ndarray or tensorflow.Dataset. Training data y. It can be\n                raw labels, one-hot encoded if more than two classes, or binary\n                encoded for binary classification.\n            epochs: Int. The number of epochs to train each model during the\n                search. If unspecified, by default we train for a maximum of\n                1000 epochs, but we stop training if the validation loss stops\n                improving for 10 epochs (unless you specified an EarlyStopping\n                callback as part of the callbacks argument, in which case the\n                EarlyStopping callback you specified will determine early\n                stopping).\n            callbacks: List of Keras callbacks to apply during training and\n                validation.\n            validation_split: Float between 0 and 1. Defaults to 0.2. Fraction\n                of the training data to be used as validation data. The model\n                will set apart this fraction of the training data, will not\n                train on it, and will evaluate the loss and any model metrics on\n                this data at the end of each epoch. The validation data is\n                selected from the last samples in the `x` and `y` data provided,\n                before shuffling. This argument is not supported when `x` is a\n                dataset. The best model found would be fit on the entire\n                dataset including the validation data.\n            validation_data: Data on which to evaluate the loss and any model\n                metrics at the end of each epoch. The model will not be trained\n                on this data. `validation_data` will override\n                `validation_split`. The type of the validation data should be\n                the same as the training data.  The best model found would be\n                fit on the training dataset without the validation data.\n            **kwargs: Any arguments supported by\n                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\n\n        # Returns\n            history: A Keras History object corresponding to the best model.\n                Its History.history attribute is a record of training\n                loss values and metrics values at successive epochs, as well as\n                validation loss values and validation metrics values (if\n                applicable).\n        \"\"\"\n        history = super().fit(\n            x=x,\n            y=y,\n            epochs=epochs,\n            callbacks=callbacks,\n            validation_split=validation_split,\n            validation_data=validation_data,\n            **kwargs\n        )\n        return history",
            "Examples": [
                "\n"
            ]
        }
    ]
}