{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/fawkes",
    "API_Calls": [
        {
            "Name": "call_Fawkes",
            "Description": "call_Fawkes",
            "Code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Date    : 2020-05-17\n# @Author  : Shawn Shan (shansixiong@cs.uchicago.edu)\n# @Link    : https://www.shawnshan.com/\n\nimport argparse\nimport glob\nimport logging\nimport os\nimport sys\n\nlogging.getLogger('tensorflow').setLevel(logging.ERROR)\nos.environ[\"KMP_AFFINITY\"] = \"noverbose\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport tensorflow as tf\n\ntf.get_logger().setLevel('ERROR')\ntf.autograph.set_verbosity(3)\n\nimport numpy as np\nfrom fawkes.differentiator import FawkesMaskGeneration\nfrom fawkes.utils import init_gpu, dump_image, reverse_process_cloaked, \\\n    Faces, filter_image_paths, load_extractor\n\nfrom fawkes.align_face import aligner\n\n\ndef generate_cloak_images(protector, image_X, target_emb=None):\n    cloaked_image_X = protector.compute(image_X, target_emb)\n    return cloaked_image_X\n\n\nIMG_SIZE = 112\nPREPROCESS = 'raw'\n\n\ndef main(*argv):\n    if not argv:\n        argv = list(sys.argv)\n\n    try:\n        import signal\n        signal.signal(signal.SIGPIPE, signal.SIG_DFL)\n    except Exception as e:\n        pass\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--directory', '-d', type=str,\n                        help='the directory that contains images to run protection', default='imgs/')\n    parser.add_argument('--gpu', '-g', type=str,\n                        help='the GPU id when using GPU for optimization', default='0')\n    parser.add_argument('--mode', '-m', type=str,\n                        help='cloak generation mode, select from min, low, mid, high. The higher the mode is, '\n                             'the more perturbation added and stronger protection',\n                        default='low')\n    parser.add_argument('--feature-extractor', type=str,\n                        help=\"name of the feature extractor used for optimization\",\n                        default=\"arcface_extractor_0\")\n    parser.add_argument('--th', help='only relevant with mode=custom, DSSIM threshold for perturbation', type=float,\n                        default=0.01)\n    parser.add_argument('--max-step', help='only relevant with mode=custom, number of steps for optimization', type=int,\n                        default=1000)\n    parser.add_argument('--sd', type=int, help='only relevant with mode=custom, penalty number, read more in the paper',\n                        default=1e6)\n    parser.add_argument('--lr', type=float, help='only relevant with mode=custom, learning rate', default=2)\n    parser.add_argument('--batch-size', help=\"number of images to run optimization together\", type=int, default=1)\n    parser.add_argument('--separate_target', help=\"whether select separate targets for each faces in the directory\",\n                        action='store_true')\n    parser.add_argument('--no-align', help=\"whether to detect and crop faces\",\n                        action='store_true')\n    parser.add_argument('--debug', help=\"turn on debug and copy/paste the stdout when reporting an issue on github\",\n                        action='store_true')\n    parser.add_argument('--format', type=str,\n                        help=\"format of the output image\",\n                        default=\"png\")\n\n    args = parser.parse_args(argv[1:])\n\n    assert args.format in ['png', 'jpg', 'jpeg']\n    if args.format == 'jpg':\n        args.format = 'jpeg'\n\n    image_paths = glob.glob(os.path.join(args.directory, \"*\"))\n    image_paths = [path for path in image_paths if \"_cloaked\" not in path.split(\"/\")[-1]]\n\n    protector = Fawkes(args.feature_extractor, args.gpu, args.batch_size, mode=args.mode)\n\n    protector.run_protection(image_paths, th=args.th, sd=args.sd, lr=args.lr,\n                             max_step=args.max_step,\n                             batch_size=args.batch_size, format=args.format,\n                             separate_target=args.separate_target, debug=args.debug, no_align=args.no_align)\n\n\nif __name__ == '__main__':\n    main(*sys.argv)",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/fawkes/fawkes/protection.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "Fawkes",
            "Description": "Fawkes",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/fawkes/fawkes/protection.py",
            "Implementation": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Date    : 2020-05-17\n# @Author  : Shawn Shan (shansixiong@cs.uchicago.edu)\n# @Link    : https://www.shawnshan.com/\n\nimport argparse\nimport glob\nimport logging\nimport os\nimport sys\n\nlogging.getLogger('tensorflow').setLevel(logging.ERROR)\nos.environ[\"KMP_AFFINITY\"] = \"noverbose\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport tensorflow as tf\n\ntf.get_logger().setLevel('ERROR')\ntf.autograph.set_verbosity(3)\n\nimport numpy as np\nfrom fawkes.differentiator import FawkesMaskGeneration\nfrom fawkes.utils import init_gpu, dump_image, reverse_process_cloaked, \\\n    Faces, filter_image_paths, load_extractor\n\nfrom fawkes.align_face import aligner\n\n\nclass Fawkes(object):\n    def __init__(self, feature_extractor, gpu, batch_size, mode=\"low\"):\n\n        self.feature_extractor = feature_extractor\n        self.gpu = gpu\n        self.batch_size = batch_size\n        self.mode = mode\n        th, max_step, lr, extractors = self.mode2param(self.mode)\n        self.th = th\n        self.lr = lr\n        self.max_step = max_step\n        if gpu is not None:\n            init_gpu(gpu)\n\n        self.aligner = aligner()\n\n        self.protector = None\n        self.protector_param = None\n        self.feature_extractors_ls = [load_extractor(name) for name in extractors]\n\n    def mode2param(self, mode):\n        if mode == 'low':\n            th = 0.004\n            max_step = 40\n            lr = 25\n            extractors = [\"extractor_2\"]\n\n        elif mode == 'mid':\n            th = 0.012\n            max_step = 75\n            lr = 20\n            extractors = [\"extractor_0\", \"extractor_2\"]\n\n        elif mode == 'high':\n            th = 0.017\n            max_step = 150\n            lr = 15\n            extractors = [\"extractor_0\", \"extractor_2\"]\n\n        else:\n            raise Exception(\"mode must be one of 'min', 'low', 'mid', 'high'\")\n        return th, max_step, lr, extractors\n\n    def run_protection(self, image_paths, th=0.04, sd=1e7, lr=10, max_step=500, batch_size=1, format='png',\n                       separate_target=True, debug=False, no_align=False, exp=\"\", maximize=True,\n                       save_last_on_failed=True):\n\n        current_param = \"-\".join([str(x) for x in [self.th, sd, self.lr, self.max_step, batch_size, format,\n                                                   separate_target, debug]])\n\n        image_paths, loaded_images = filter_image_paths(image_paths)\n\n        if not image_paths:\n            print(\"No images in the directory\")\n            return 3\n\n        faces = Faces(image_paths, loaded_images, self.aligner, verbose=1, no_align=no_align)\n        original_images = faces.cropped_faces\n\n        if len(original_images) == 0:\n            print(\"No face detected. \")\n            return 2\n        original_images = np.array(original_images)\n\n        if current_param != self.protector_param:\n            self.protector_param = current_param\n            if self.protector is not None:\n                del self.protector\n            if batch_size == -1:\n                batch_size = len(original_images)\n            self.protector = FawkesMaskGeneration(self.feature_extractors_ls,\n                                                  batch_size=batch_size,\n                                                  mimic_img=True,\n                                                  intensity_range=PREPROCESS,\n                                                  initial_const=sd,\n                                                  learning_rate=self.lr,\n                                                  max_iterations=self.max_step,\n                                                  l_threshold=self.th,\n                                                  verbose=debug,\n                                                  maximize=maximize,\n                                                  keep_final=False,\n                                                  image_shape=(IMG_SIZE, IMG_SIZE, 3),\n                                                  loss_method='features',\n                                                  tanh_process=True,\n                                                  save_last_on_failed=save_last_on_failed,\n                                                  )\n        protected_images = generate_cloak_images(self.protector, original_images)\n        faces.cloaked_cropped_faces = protected_images\n\n        final_images, images_without_face = faces.merge_faces(\n            reverse_process_cloaked(protected_images, preprocess=PREPROCESS),\n            reverse_process_cloaked(original_images, preprocess=PREPROCESS))\n\n        for i in range(len(final_images)):\n            if i in images_without_face:\n                continue\n            p_img = final_images[i]\n            path = image_paths[i]\n            file_name = \"{}_cloaked.{}\".format(\".\".join(path.split(\".\")[:-1]), format)\n            dump_image(p_img, file_name, format=format)\n\n        print(\"Done!\")\n        return 1",
            "Examples": [
                "\n"
            ]
        }
    ]
}