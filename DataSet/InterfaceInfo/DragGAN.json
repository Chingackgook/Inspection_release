{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/DragGAN",
    "API_Calls": [
        {
            "Name": "generate_images",
            "Description": "主函数直接调用generate_images函数，生成处理后的图片",
            "Code": "# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n#\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto.  Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\n\n\"\"\"Generate images using pretrained network pickle.\"\"\"\n\nimport os\nimport re\nfrom typing import List, Optional, Tuple, Union\n\nimport click\nimport dnnlib\nimport numpy as np\nimport PIL.Image\nimport torch\n\nimport legacy\n\n#----------------------------------------------------------------------------\n\ndef parse_range(s: Union[str, List]) -> List[int]:\n    '''Parse a comma separated list of numbers or ranges and return a list of ints.\n\n    Example: '1,2,5-10' returns [1, 2, 5, 6, 7]\n    '''\n    if isinstance(s, list): return s\n    ranges = []\n    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n    for p in s.split(','):\n        m = range_re.match(p)\n        if m:\n            ranges.extend(range(int(m.group(1)), int(m.group(2))+1))\n        else:\n            ranges.append(int(p))\n    return ranges\n\n#----------------------------------------------------------------------------\n\ndef parse_vec2(s: Union[str, Tuple[float, float]]) -> Tuple[float, float]:\n    '''Parse a floating point 2-vector of syntax 'a,b'.\n\n    Example:\n        '0,1' returns (0,1)\n    '''\n    if isinstance(s, tuple): return s\n    parts = s.split(',')\n    if len(parts) == 2:\n        return (float(parts[0]), float(parts[1]))\n    raise ValueError(f'cannot parse 2-vector {s}')\n\n#----------------------------------------------------------------------------\n\ndef make_transform(translate: Tuple[float,float], angle: float):\n    m = np.eye(3)\n    s = np.sin(angle/360.0*np.pi*2)\n    c = np.cos(angle/360.0*np.pi*2)\n    m[0][0] = c\n    m[0][1] = s\n    m[0][2] = translate[0]\n    m[1][0] = -s\n    m[1][1] = c\n    m[1][2] = translate[1]\n    return m\n\n#----------------------------------------------------------------------------\n\n@click.command()\n@click.option('--network', 'network_pkl', help='Network pickle filename', required=True)\n@click.option('--seeds', type=parse_range, help='List of random seeds (e.g., \\'0,1,4-6\\')', required=True)\n@click.option('--trunc', 'truncation_psi', type=float, help='Truncation psi', default=1, show_default=True)\n@click.option('--class', 'class_idx', type=int, help='Class label (unconditional if not specified)')\n@click.option('--noise-mode', help='Noise mode', type=click.Choice(['const', 'random', 'none']), default='const', show_default=True)\n@click.option('--translate', help='Translate XY-coordinate (e.g. \\'0.3,1\\')', type=parse_vec2, default='0,0', show_default=True, metavar='VEC2')\n@click.option('--rotate', help='Rotation angle in degrees', type=float, default=0, show_default=True, metavar='ANGLE')\n@click.option('--outdir', help='Where to save the output images', type=str, required=True, metavar='DIR')\ndef generate_images(\n    network_pkl: str,\n    seeds: List[int],\n    truncation_psi: float,\n    noise_mode: str,\n    outdir: str,\n    translate: Tuple[float,float],\n    rotate: float,\n    class_idx: Optional[int]\n):\n    \"\"\"Generate images using pretrained network pickle.\n\n    Examples:\n\n    \\b\n    # Generate an image using pre-trained AFHQv2 model (\"Ours\" in Figure 1, left).\n    python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\\\n        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\n\n    \\b\n    # Generate uncurated images with truncation using the MetFaces-U dataset\n    python gen_images.py --outdir=out --trunc=0.7 --seeds=600-605 \\\\\n        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-metfacesu-1024x1024.pkl\n    \"\"\"\n\n    print('Loading networks from \"%s\"...' % network_pkl)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n    dtype = torch.float32 if device.type == 'mps' else torch.float64\n    with dnnlib.util.open_url(network_pkl) as f:\n        G = legacy.load_network_pkl(f)['G_ema'].to(device, dtype=dtype) # type: ignore\n        # import pickle\n        # G = legacy.load_network_pkl(f)\n        # output = open('checkpoints/stylegan2-car-config-f-pt.pkl', 'wb')\n        # pickle.dump(G, output)\n\n    os.makedirs(outdir, exist_ok=True)\n    \n    G = G.to(torch.float32)\n\n    # Labels.\n    label = torch.zeros([1, G.c_dim], device=device)\n    if G.c_dim != 0:\n        if class_idx is None:\n            raise click.ClickException('Must specify class label with --class when using a conditional network')\n        label[:, class_idx] = 1\n    else:\n        if class_idx is not None:\n            print ('warn: --class=lbl ignored when running on an unconditional network')\n\n    # Generate images.\n    for seed_idx, seed in enumerate(seeds):\n        print('Generating image for seed %d (%d/%d) ...' % (seed, seed_idx, len(seeds)))\n        z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(device, dtype=dtype)\n\n        # Construct an inverse rotation/translation matrix and pass to the generator.  The\n        # generator expects this matrix as an inverse to avoid potentially failing numerical\n        # operations in the network.\n        if hasattr(G.synthesis, 'input'):\n            m = make_transform(translate, rotate)\n            m = np.linalg.inv(m)\n            G.synthesis.input.transform.copy_(torch.from_numpy(m))\n\n        img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n        PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png')\n\n\n#----------------------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    generate_images() # pylint: disable=no-value-for-parameter\n\n#----------------------------------------------------------------------------\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/DragGAN/gen_images.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "generate_images",
            "Description": "基于预训练的 StyleGAN 模型，通过潜在空间操作生成高质量的图像。",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/DragGAN/gen_images.py",
            "Implementation": "# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n#\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto.  Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\n\n\"\"\"Generate images using pretrained network pickle.\"\"\"\n\nimport os\nimport re\nfrom typing import List, Optional, Tuple, Union\n\nimport click\nimport dnnlib\nimport numpy as np\nimport PIL.Image\nimport torch\n\nimport legacy\n\n#----------------------------------------------------------------------------\n\ndef parse_range(s: Union[str, List]) -> List[int]:\n    '''Parse a comma separated list of numbers or ranges and return a list of ints.\n\n    Example: '1,2,5-10' returns [1, 2, 5, 6, 7]\n    '''\n    if isinstance(s, list): return s\n    ranges = []\n    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n    for p in s.split(','):\n        m = range_re.match(p)\n        if m:\n            ranges.extend(range(int(m.group(1)), int(m.group(2))+1))\n        else:\n            ranges.append(int(p))\n    return ranges\n\n#----------------------------------------------------------------------------\n\ndef parse_vec2(s: Union[str, Tuple[float, float]]) -> Tuple[float, float]:\n    '''Parse a floating point 2-vector of syntax 'a,b'.\n\n    Example:\n        '0,1' returns (0,1)\n    '''\n    if isinstance(s, tuple): return s\n    parts = s.split(',')\n    if len(parts) == 2:\n        return (float(parts[0]), float(parts[1]))\n    raise ValueError(f'cannot parse 2-vector {s}')\n\n#----------------------------------------------------------------------------\n\ndef make_transform(translate: Tuple[float,float], angle: float):\n    m = np.eye(3)\n    s = np.sin(angle/360.0*np.pi*2)\n    c = np.cos(angle/360.0*np.pi*2)\n    m[0][0] = c\n    m[0][1] = s\n    m[0][2] = translate[0]\n    m[1][0] = -s\n    m[1][1] = c\n    m[1][2] = translate[1]\n    return m\n\n#----------------------------------------------------------------------------\n\n@click.command()\n@click.option('--network', 'network_pkl', help='Network pickle filename', required=True)\n@click.option('--seeds', type=parse_range, help='List of random seeds (e.g., \\'0,1,4-6\\')', required=True)\n@click.option('--trunc', 'truncation_psi', type=float, help='Truncation psi', default=1, show_default=True)\n@click.option('--class', 'class_idx', type=int, help='Class label (unconditional if not specified)')\n@click.option('--noise-mode', help='Noise mode', type=click.Choice(['const', 'random', 'none']), default='const', show_default=True)\n@click.option('--translate', help='Translate XY-coordinate (e.g. \\'0.3,1\\')', type=parse_vec2, default='0,0', show_default=True, metavar='VEC2')\n@click.option('--rotate', help='Rotation angle in degrees', type=float, default=0, show_default=True, metavar='ANGLE')\n@click.option('--outdir', help='Where to save the output images', type=str, required=True, metavar='DIR')\ndef generate_images(\n    network_pkl: str,\n    seeds: List[int],\n    truncation_psi: float,\n    noise_mode: str,\n    outdir: str,\n    translate: Tuple[float,float],\n    rotate: float,\n    class_idx: Optional[int]\n):\n    \"\"\"Generate images using pretrained network pickle.\n\n    Examples:\n\n    \\b\n    # Generate an image using pre-trained AFHQv2 model (\"Ours\" in Figure 1, left).\n    python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\\\n        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\n\n    \\b\n    # Generate uncurated images with truncation using the MetFaces-U dataset\n    python gen_images.py --outdir=out --trunc=0.7 --seeds=600-605 \\\\\n        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-metfacesu-1024x1024.pkl\n    \"\"\"\n\n    print('Loading networks from \"%s\"...' % network_pkl)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n    dtype = torch.float32 if device.type == 'mps' else torch.float64\n    with dnnlib.util.open_url(network_pkl) as f:\n        G = legacy.load_network_pkl(f)['G_ema'].to(device, dtype=dtype) # type: ignore\n        # import pickle\n        # G = legacy.load_network_pkl(f)\n        # output = open('checkpoints/stylegan2-car-config-f-pt.pkl', 'wb')\n        # pickle.dump(G, output)\n\n    os.makedirs(outdir, exist_ok=True)\n    \n    G = G.to(torch.float32)\n\n    # Labels.\n    label = torch.zeros([1, G.c_dim], device=device)\n    if G.c_dim != 0:\n        if class_idx is None:\n            raise click.ClickException('Must specify class label with --class when using a conditional network')\n        label[:, class_idx] = 1\n    else:\n        if class_idx is not None:\n            print ('warn: --class=lbl ignored when running on an unconditional network')\n\n    # Generate images.\n    for seed_idx, seed in enumerate(seeds):\n        print('Generating image for seed %d (%d/%d) ...' % (seed, seed_idx, len(seeds)))\n        z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(device, dtype=dtype)\n\n        # Construct an inverse rotation/translation matrix and pass to the generator.  The\n        # generator expects this matrix as an inverse to avoid potentially failing numerical\n        # operations in the network.\n        if hasattr(G.synthesis, 'input'):\n            m = make_transform(translate, rotate)\n            m = np.linalg.inv(m)\n            G.synthesis.input.transform.copy_(torch.from_numpy(m))\n\n        img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n        PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png')\n\n\n#----------------------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    generate_images() # pylint: disable=no-value-for-parameter\n\n#----------------------------------------------------------------------------\n",
            "Example": [
                "#export TORCH_CUDA_ARCH_LIST=\"8.9;8.9;8.9;8.9\"\n\nimport os\nimport sys\nimport torch\nimport numpy as np\n\n# 将项目根目录添加到系统路径\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom gen_images import generate_images\n\ndef test_generate_images():\n    try:\n        # 测试参数\n        network_pkl = \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\"\n        seeds = [0, 1]\n        truncation_psi = 1\n        noise_mode = 'const'\n        outdir = \"test_output\"\n        translate = (0, 0)\n        rotate = 0\n        class_idx = None\n\n        # 确保目录存在\n        os.makedirs(outdir, exist_ok=True)\n\n        # 手动设置默认数据类型为Float (32位)\n        torch.set_default_dtype(torch.float32)\n        \n        # 调用 generate_images 函数进行测试\n        generate_images.callback(network_pkl=network_pkl, seeds=seeds, truncation_psi=truncation_psi,\n                                 noise_mode=noise_mode, outdir=outdir, translate=translate,\n                                 rotate=rotate, class_idx=class_idx)\n\n        # 检查输出文件\n        output_files = [f for f in os.listdir(outdir) if f.endswith('.png')]\n        if len(output_files) >= len(seeds):\n            print(f\"Test passed! Generated {len(output_files)} images.\")\n        else:\n            print(f\"Test failed! Expected {len(seeds)} images, but found {len(output_files)}.\")\n            \n    except Exception as e:\n        print(f\"Test failed: {e}\")\n\nif __name__ == \"__main__\":\n    test_generate_images()\n"
            ]
        }
    ]
}