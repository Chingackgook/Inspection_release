{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/backgroundremover",
    "API_Calls": [
        {
            "Name": "call_remove",
            "Description": "call removebg",
            "Code": "import argparse\nimport os\nfrom distutils.util import strtobool\nfrom .. import utilities\nfrom ..bg import remove\n\n\ndef main():\n    model_choices = [\"u2net\", \"u2net_human_seg\", \"u2netp\"]\n\n    ap = argparse.ArgumentParser()\n\n    ap.add_argument(\n        \"-m\",\n        \"--model\",\n        default=\"u2net\",\n        type=str,\n        choices=model_choices,\n        help=\"The model name, u2net, u2netp, u2net_human_seg\",\n    )\n\n    ap.add_argument(\n        \"-a\",\n        \"--alpha-matting\",\n        nargs=\"?\",\n        const=True,\n        default=False,\n        type=lambda x: bool(strtobool(x)),\n        help=\"When true use alpha matting cutout.\",\n    )\n\n    ap.add_argument(\n        \"-af\",\n        \"--alpha-matting-foreground-threshold\",\n        default=240,\n        type=int,\n        help=\"The trimap foreground threshold.\",\n    )\n\n    ap.add_argument(\n        \"-ab\",\n        \"--alpha-matting-background-threshold\",\n        default=10,\n        type=int,\n        help=\"The trimap background threshold.\",\n    )\n\n    ap.add_argument(\n        \"-ae\",\n        \"--alpha-matting-erode-size\",\n        default=10,\n        type=int,\n        help=\"Size of element used for the erosion.\",\n    )\n\n    ap.add_argument(\n        \"-az\",\n        \"--alpha-matting-base-size\",\n        default=1000,\n        type=int,\n        help=\"The image base size.\",\n    )\n    ap.add_argument(\n        \"-wn\",\n        \"--workernodes\",\n        default=1,\n        type=int,\n        help=\"Number of parallel workers\"\n    )\n\n    ap.add_argument(\n        \"-gb\",\n        \"--gpubatchsize\",\n        default=2,\n        type=int,\n        help=\"GPU batchsize\"\n    )\n\n    ap.add_argument(\n        \"-fr\",\n        \"--framerate\",\n        default=-1,\n        type=int,\n        help=\"Override the frame rate\"\n    )\n\n    ap.add_argument(\n        \"-fl\",\n        \"--framelimit\",\n        default=-1,\n        type=int,\n        help=\"Limit the number of frames to process for quick testing.\",\n    )\n    ap.add_argument(\n        \"-mk\",\n        \"--mattekey\",\n        nargs=\"?\",\n        const=True,\n        default=False,\n        type=lambda x: bool(strtobool(x)),\n        help=\"Output the Matte key file\",\n    )\n    ap.add_argument(\n        \"-tv\",\n        \"--transparentvideo\",\n        nargs=\"?\",\n        const=True,\n        default=False,\n        type=lambda x: bool(strtobool(x)),\n        help=\"Output transparent video format mov\",\n    )\n\n    ap.add_argument(\n        \"-tov\",\n        \"--transparentvideoovervideo\",\n        nargs=\"?\",\n        const=True,\n        default=False,\n        type=lambda x: bool(strtobool(x)),\n        help=\"Overlay transparent video over another video\",\n    )\n    ap.add_argument(\n        \"-toi\",\n        \"--transparentvideooverimage\",\n        nargs=\"?\",\n        const=True,\n        default=False,\n        type=lambda x: bool(strtobool(x)),\n        help=\"Overlay transparent video over another image\",\n    )\n    ap.add_argument(\n        \"-tg\",\n        \"--transparentgif\",\n        nargs=\"?\",\n        const=True,\n        default=False,\n        type=lambda x: bool(strtobool(x)),\n        help=\"Make transparent gif from video\",\n    )\n    ap.add_argument(\n        \"-tgwb\",\n        \"--transparentgifwithbackground\",\n        nargs=\"?\",\n        const=True,\n        default=False,\n        type=lambda x: bool(strtobool(x)),\n        help=\"Make transparent background overlay a background image\",\n    )\n\n    ap.add_argument(\n        \"-i\",\n        \"--input\",\n        nargs=\"?\",\n        default=\"-\",\n        type=argparse.FileType(\"rb\"),\n        help=\"Path to the input video or image.\",\n    )\n\n    ap.add_argument(\n        \"-bi\",\n        \"--backgroundimage\",\n        nargs=\"?\",\n        default=\"-\",\n        type=argparse.FileType(\"rb\"),\n        help=\"Path to background image.\",\n    )\n\n    ap.add_argument(\n        \"-bv\",\n        \"--backgroundvideo\",\n        nargs=\"?\",\n        default=\"-\",\n        type=argparse.FileType(\"rb\"),\n        help=\"Path to background video.\",\n    )\n\n    ap.add_argument(\n        \"-o\",\n        \"--output\",\n        nargs=\"?\",\n        default=\"-\",\n        type=argparse.FileType(\"wb\"),\n        help=\"Path to the output\",\n    )\n\n    ap.add_argument(\n        \"-if\",\n        \"--input-folder\",\n        type=str,\n        help=\"Path to a folder containing input videos or images.\",\n    )\n\n    ap.add_argument(\n        \"-of\",\n        \"--output-folder\",\n        type=str,\n        help=\"Path to the output folder for processed files.\",\n    )\n\n    args = ap.parse_args()\n\n    def is_video_file(filename):\n        return filename.lower().endswith((\".mp4\", \".mov\", \".webm\", \".ogg\", \".gif\"))\n\n    def is_image_file(filename):\n        return filename.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n\n    if args.input_folder:\n        input_folder = os.path.abspath(args.input_folder)\n        output_folder = os.path.abspath(args.output_folder or input_folder)\n        os.makedirs(output_folder, exist_ok=True)\n\n        files = [f for f in os.listdir(input_folder) if is_video_file(f) or is_image_file(f)]\n\n        for f in files:\n            input_path = os.path.join(input_folder, f)\n            output_path = os.path.join(output_folder, f\"output_{f}\")\n\n            if is_video_file(f):\n                if args.mattekey:\n                    utilities.matte_key(output_path, input_path,\n                                        worker_nodes=args.workernodes,\n                                        gpu_batchsize=args.gpubatchsize,\n                                        model_name=args.model,\n                                        frame_limit=args.framelimit,\n                                        framerate=args.framerate)\n                elif args.transparentvideo:\n                    utilities.transparentvideo(output_path, input_path,\n                                               worker_nodes=args.workernodes,\n                                               gpu_batchsize=args.gpubatchsize,\n                                               model_name=args.model,\n                                               frame_limit=args.framelimit,\n                                               framerate=args.framerate)\n                elif args.transparentvideoovervideo:\n                    utilities.transparentvideoovervideo(output_path, os.path.abspath(args.backgroundvideo.name),\n                                                        input_path,\n                                                        worker_nodes=args.workernodes,\n                                                        gpu_batchsize=args.gpubatchsize,\n                                                        model_name=args.model,\n                                                        frame_limit=args.framelimit,\n                                                        framerate=args.framerate)\n                elif args.transparentvideooverimage:\n                    utilities.transparentvideooverimage(output_path, os.path.abspath(args.backgroundimage.name),\n                                                        input_path,\n                                                        worker_nodes=args.workernodes,\n                                                        gpu_batchsize=args.gpubatchsize,\n                                                        model_name=args.model,\n                                                        frame_limit=args.framelimit,\n                                                        framerate=args.framerate)\n                elif args.transparentgif:\n                    utilities.transparentgif(output_path, input_path,\n                                             worker_nodes=args.workernodes,\n                                             gpu_batchsize=args.gpubatchsize,\n                                             model_name=args.model,\n                                             frame_limit=args.framelimit,\n                                             framerate=args.framerate)\n                elif args.transparentgifwithbackground:\n                    utilities.transparentgifwithbackground(output_path, os.path.abspath(args.backgroundimage.name), input_path,\n                                                           worker_nodes=args.workernodes,\n                                                           gpu_batchsize=args.gpubatchsize,\n                                                           model_name=args.model,\n                                                           frame_limit=args.framelimit,\n                                                           framerate=args.framerate)\n            elif is_image_file(f):\n                with open(input_path, \"rb\") as i, open(output_path, \"wb\") as o:\n                    r = lambda i: i.buffer.read() if hasattr(i, \"buffer\") else i.read()\n                    w = lambda o, data: o.buffer.write(data) if hasattr(o, \"buffer\") else o.write(data)\n                    w(\n                        o,\n                        remove(\n                            r(i),\n                            model_name=args.model,\n                            alpha_matting=args.alpha_matting,\n                            alpha_matting_foreground_threshold=args.alpha_matting_foreground_threshold,\n                            alpha_matting_background_threshold=args.alpha_matting_background_threshold,\n                            alpha_matting_erode_structure_size=args.alpha_matting_erode_size,\n                            alpha_matting_base_size=args.alpha_matting_base_size,\n                        ),\n                    )\n        return\n\n    ext = os.path.splitext(args.input.name)[1].lower()\n\n    if ext in [\".mp4\", \".mov\", \".webm\", \".ogg\", \".gif\"]:\n        if args.mattekey:\n            utilities.matte_key(os.path.abspath(args.output.name), os.path.abspath(args.input.name),\n                                worker_nodes=args.workernodes,\n                                gpu_batchsize=args.gpubatchsize,\n                                model_name=args.model,\n                                frame_limit=args.framelimit,\n                                framerate=args.framerate)\n        elif args.transparentvideo:\n            utilities.transparentvideo(os.path.abspath(args.output.name), os.path.abspath(args.input.name),\n                                       worker_nodes=args.workernodes,\n                                       gpu_batchsize=args.gpubatchsize,\n                                       model_name=args.model,\n                                       frame_limit=args.framelimit,\n                                       framerate=args.framerate)\n        elif args.transparentvideoovervideo:\n            utilities.transparentvideoovervideo(os.path.abspath(args.output.name), os.path.abspath(args.backgroundvideo.name),\n                                                os.path.abspath(args.input.name),\n                                                worker_nodes=args.workernodes,\n                                                gpu_batchsize=args.gpubatchsize,\n                                                model_name=args.model,\n                                                frame_limit=args.framelimit,\n                                                framerate=args.framerate)\n        elif args.transparentvideooverimage:\n            utilities.transparentvideooverimage(os.path.abspath(args.output.name), os.path.abspath(args.backgroundimage.name),\n                                                os.path.abspath(args.input.name),\n                                                worker_nodes=args.workernodes,\n                                                gpu_batchsize=args.gpubatchsize,\n                                                model_name=args.model,\n                                                frame_limit=args.framelimit,\n                                                framerate=args.framerate)\n        elif args.transparentgif:\n            utilities.transparentgif(os.path.abspath(args.output.name), os.path.abspath(args.input.name),\n                                     worker_nodes=args.workernodes,\n                                     gpu_batchsize=args.gpubatchsize,\n                                     model_name=args.model,\n                                     frame_limit=args.framelimit,\n                                     framerate=args.framerate)\n        elif args.transparentgifwithbackground:\n            utilities.transparentgifwithbackground(os.path.abspath(args.output.name), os.path.abspath(args.backgroundimage.name), os.path.abspath(args.input.name),\n                                                   worker_nodes=args.workernodes,\n                                                   gpu_batchsize=args.gpubatchsize,\n                                                   model_name=args.model,\n                                                   frame_limit=args.framelimit,\n                                                   framerate=args.framerate)\n\n    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n        r = lambda i: i.buffer.read() if hasattr(i, \"buffer\") else i.read()\n        w = lambda o, data: o.buffer.write(data) if hasattr(o, \"buffer\") else o.write(data)\n        w(\n            args.output,\n            remove(\n                r(args.input),\n                model_name=args.model,\n                alpha_matting=args.alpha_matting,\n                alpha_matting_foreground_threshold=args.alpha_matting_foreground_threshold,\n                alpha_matting_background_threshold=args.alpha_matting_background_threshold,\n                alpha_matting_erode_structure_size=args.alpha_matting_erode_size,\n                alpha_matting_base_size=args.alpha_matting_base_size,\n            ),\n        )\n    else:\n        print(f\"âŒ Unsupported file type: {ext}\")\n        exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/backgroundremover/backgroundremover/cmd/cli.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "removebg",
            "Description": "removebg",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/backgroundremover/backgroundremover/bg.py",
            "Implementation": "import io\nimport os\nimport typing\nfrom PIL import Image\nfrom pymatting.alpha.estimate_alpha_cf import estimate_alpha_cf\nfrom pymatting.foreground.estimate_foreground_ml import estimate_foreground_ml\nfrom pymatting.util.util import stack_images\nfrom scipy.ndimage.morphology import binary_erosion\nfrom moviepy import VideoFileClip\nimport numpy as np\nimport torch\nimport torch.nn.functional\nimport torch.nn.functional\nfrom hsh.library.hash import Hasher\nfrom .u2net import detect, u2net\nfrom . import github\n\n# closes https://github.com/nadermx/backgroundremover/issues/18\n# closes https://github.com/nadermx/backgroundremover/issues/112\ntry:\n    if torch.cuda.is_available():\n        DEVICE = torch.device('cuda:0')\n    elif torch.backends.mps.is_available():\n        DEVICE = torch.device('mps')\n    else:\n        DEVICE = torch.device('cpu')\nexcept Exception as e:\n    print(f\"Using CPU.  Setting Cuda or MPS failed: {e}\")\n    DEVICE = torch.device('cpu')\n\nclass Net(torch.nn.Module):\n    def __init__(self, model_name):\n        super(Net, self).__init__()\n        hasher = Hasher()\n        model = {\n            'u2netp': (u2net.U2NETP,\n                       'e4f636406ca4e2af789941e7f139ee2e',\n                       '1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy',\n                       'U2NET_PATH'),\n            'u2net': (u2net.U2NET,\n                      '09fb4e49b7f785c9f855baf94916840a',\n                      '1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ',\n                      'U2NET_PATH'),\n            'u2net_human_seg': (u2net.U2NET,\n                                '347c3d51b01528e5c6c071e3cff1cb55',\n                                '1-Yg0cxgrNhHP-016FPdp902BR-kSsA4P',\n                                'U2NET_PATH')\n        }[model_name]\n\n        if model_name == \"u2netp\":\n            net = u2net.U2NETP(3, 1)\n            path = os.environ.get(\n                \"U2NETP_PATH\",\n                os.path.expanduser(os.path.join(\"~\", \".u2net\", model_name + \".pth\")),\n            )\n            if (\n                not os.path.exists(path)\n            ):\n                github.download_files_from_github(\n                    path, model_name\n                )\n\n        elif model_name == \"u2net\":\n            net = u2net.U2NET(3, 1)\n            path = os.environ.get(\n                \"U2NET_PATH\",\n                os.path.expanduser(os.path.join(\"~\", \".u2net\", model_name + \".pth\")),\n            )\n            if (\n                not os.path.exists(path)\n                #or hasher.md5(path) != \"09fb4e49b7f785c9f855baf94916840a\"\n            ):\n                github.download_files_from_github(\n                    path, model_name\n                )\n\n        elif model_name == \"u2net_human_seg\":\n            net = u2net.U2NET(3, 1)\n            path = os.environ.get(\n                \"U2NET_PATH\",\n                os.path.expanduser(os.path.join(\"~\", \".u2net\", model_name + \".pth\")),\n            )\n            if (\n                not os.path.exists(path)\n                #or hasher.md5(path) != \"347c3d51b01528e5c6c071e3cff1cb55\"\n            ):\n                github.download_files_from_github(\n                    path, model_name\n                )\n        else:\n            print(\"Choose between u2net, u2net_human_seg or u2netp\", file=sys.stderr)\n\n        net.load_state_dict(torch.load(path, map_location=torch.device(DEVICE)))\n        net.to(device=DEVICE, dtype=torch.float32, non_blocking=True)\n        net.eval()\n        self.net = net\n\n    def forward(self, block_input: torch.Tensor):\n        image_data = block_input.permute(0, 3, 1, 2)\n        original_shape = image_data.shape[2:]\n        image_data = torch.nn.functional.interpolate(image_data, (320, 320), mode='bilinear')\n        image_data = (image_data / 255 - 0.485) / 0.229\n        out = self.net(image_data)[0][:, 0:1]\n        ma = torch.max(out)\n        mi = torch.min(out)\n        out = (out - mi) / (ma - mi) * 255\n        out = torch.nn.functional.interpolate(out, original_shape, mode='bilinear')\n        out = out[:, 0]\n        out = out.to(dtype=torch.uint8, device=torch.device('cpu'), non_blocking=True).detach()\n        return out\n\n\ndef alpha_matting_cutout(\n    img,\n    mask,\n    foreground_threshold,\n    background_threshold,\n    erode_structure_size,\n    base_size,\n):\n    size = img.size\n\n    img.thumbnail((base_size, base_size), Image.LANCZOS)\n    mask = mask.resize(img.size, Image.LANCZOS)\n\n    img = np.asarray(img)\n    mask = np.asarray(mask)\n\n    # guess likely foreground/background\n    is_foreground = mask > foreground_threshold\n    is_background = mask < background_threshold\n\n    # erode foreground/background\n    structure = None\n    if erode_structure_size > 0:\n        structure = np.ones((erode_structure_size, erode_structure_size), dtype=np.int64)\n\n    is_foreground = binary_erosion(is_foreground, structure=structure)\n    is_background = binary_erosion(is_background, structure=structure, border_value=1)\n\n    # build trimap\n    # 0   = background\n    # 128 = unknown\n    # 255 = foreground\n    trimap = np.full(mask.shape, dtype=np.uint8, fill_value=128)\n    trimap[is_foreground] = 255\n    trimap[is_background] = 0\n\n    # build the cutout image\n    img_normalized = img / 255.0\n    trimap_normalized = trimap / 255.0\n\n    alpha = estimate_alpha_cf(img_normalized, trimap_normalized)\n    foreground = estimate_foreground_ml(img_normalized, alpha)\n    cutout = stack_images(foreground, alpha)\n\n    cutout = np.clip(cutout * 255, 0, 255).astype(np.uint8)\n    cutout = Image.fromarray(cutout)\n    cutout = cutout.resize(size, Image.LANCZOS)\n\n    return cutout\n\n\ndef naive_cutout(img, mask):\n    empty = Image.new(\"RGBA\", (img.size), 0)\n    cutout = Image.composite(img, empty, mask.resize(img.size, Image.LANCZOS))\n    return cutout\n\n\ndef get_model(model_name):\n    if model_name == \"u2netp\":\n        return detect.load_model(model_name=\"u2netp\")\n    if model_name == \"u2net_human_seg\":\n        return detect.load_model(model_name=\"u2net_human_seg\")\n    else:\n        return detect.load_model(model_name=\"u2net\")\n\n\ndef remove(\n    data,\n    model_name=\"u2net\",\n    alpha_matting=False,\n    alpha_matting_foreground_threshold=240,\n    alpha_matting_background_threshold=10,\n    alpha_matting_erode_structure_size=10,\n    alpha_matting_base_size=1000,\n):\n    model = get_model(model_name)\n\n    if isinstance(data, np.ndarray):\n        img = Image.fromarray(data).convert(\"RGB\")\n    else:\n        try:\n            img = Image.open(io.BytesIO(data)).convert(\"RGB\")\n        except Exception as e:\n            raise ValueError(f\"Invalid image input to `remove()`: {e}\")\n\n    mask = detect.predict(model, np.array(img)).convert(\"L\")\n\n    if alpha_matting:\n        cutout = alpha_matting_cutout(\n            img,\n            mask,\n            alpha_matting_foreground_threshold,\n            alpha_matting_background_threshold,\n            alpha_matting_erode_structure_size,\n            alpha_matting_base_size,\n        )\n    else:\n        cutout = naive_cutout(img, mask)\n\n    bio = io.BytesIO()\n    cutout.save(bio, \"PNG\")\n\n    return bio.getbuffer()\n\n\ndef iter_frames(path):\n    return VideoFileClip(path).resized(height=320).iter_frames(dtype=\"uint8\")\n\n\n@torch.no_grad()\ndef remove_many(image_data: typing.List[np.array], net: Net):\n    image_data = np.stack(image_data)\n    image_data = torch.as_tensor(image_data, dtype=torch.float32, device=DEVICE)\n    return net(image_data).numpy()\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}