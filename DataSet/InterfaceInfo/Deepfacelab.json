{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/DeepFaceLab",
    "API_Calls": [
        {
            "Name": "clitools",
            "Description": "call_of_some_apis they from main.py ,we delete some of the APIs that we are not interested in",
            "Code": "if __name__ == \"__main__\":\n    # Fix for linux\n    import multiprocessing\n    multiprocessing.set_start_method(\"spawn\")\n\n    from core.leras import nn\n    nn.initialize_main_env()\n    import os\n    import sys\n    import time\n    import argparse\n\n    from core import pathex\n    from core import osex\n    from pathlib import Path\n    from core.interact import interact as io\n\n    if sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] < 6):\n        raise Exception(\"This program requires at least Python 3.6\")\n\n    class fixPathAction(argparse.Action):\n        def __call__(self, parser, namespace, values, option_string=None):\n            setattr(namespace, self.dest, os.path.abspath(os.path.expanduser(values)))\n\n    exit_code = 0\n    \n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n\n    facesettool_parser = subparsers.add_parser( \"facesettool\", help=\"Faceset tools.\").add_subparsers()\n\n    def process_faceset_enhancer(arguments):\n        osex.set_process_lowest_prio()\n        from mainscripts import FacesetEnhancer\n        FacesetEnhancer.process_folder ( Path(arguments.input_dir),\n                                         cpu_only=arguments.cpu_only,\n                                         force_gpu_idxs=arguments.force_gpu_idxs\n                                       )\n\n    p = facesettool_parser.add_parser (\"enhance\", help=\"Enhance details in DFL faceset.\")\n    p.add_argument('--input-dir', required=True, action=fixPathAction, dest=\"input_dir\", help=\"Input directory of aligned faces.\")\n    p.add_argument('--cpu-only', action=\"store_true\", dest=\"cpu_only\", default=False, help=\"Process on CPU.\")\n    p.add_argument('--force-gpu-idxs', dest=\"force_gpu_idxs\", default=None, help=\"Force to choose GPU indexes separated by comma.\")\n\n    p.set_defaults(func=process_faceset_enhancer)\n    \n    videoed_parser = subparsers.add_parser( \"videoed\", help=\"Video processing.\").add_subparsers()\n\n    def process_videoed_extract_video(arguments):\n        osex.set_process_lowest_prio()\n        from mainscripts import VideoEd\n        VideoEd.extract_video (arguments.input_file, arguments.output_dir, arguments.output_ext, arguments.fps)\n    p = videoed_parser.add_parser( \"extract-video\", help=\"Extract images from video file.\")\n    p.add_argument('--input-file', required=True, action=fixPathAction, dest=\"input_file\", help=\"Input file to be processed. Specify .*-extension to find first file.\")\n    p.add_argument('--output-dir', required=True, action=fixPathAction, dest=\"output_dir\", help=\"Output directory. This is where the extracted images will be stored.\")\n    p.add_argument('--output-ext', dest=\"output_ext\", default=None, help=\"Image format (extension) of output files.\")\n    p.add_argument('--fps', type=int, dest=\"fps\", default=None, help=\"How many frames of every second of the video will be extracted. 0 - full fps.\")\n    p.set_defaults(func=process_videoed_extract_video)\n\n    def process_videoed_cut_video(arguments):\n        osex.set_process_lowest_prio()\n        from mainscripts import VideoEd\n        VideoEd.cut_video (arguments.input_file,\n                           arguments.from_time,\n                           arguments.to_time,\n                           arguments.audio_track_id,\n                           arguments.bitrate)\n    p = videoed_parser.add_parser( \"cut-video\", help=\"Cut video file.\")\n    p.add_argument('--input-file', required=True, action=fixPathAction, dest=\"input_file\", help=\"Input file to be processed. Specify .*-extension to find first file.\")\n    p.add_argument('--from-time', dest=\"from_time\", default=None, help=\"From time, for example 00:00:00.000\")\n    p.add_argument('--to-time', dest=\"to_time\", default=None, help=\"To time, for example 00:00:00.000\")\n    p.add_argument('--audio-track-id', type=int, dest=\"audio_track_id\", default=None, help=\"Specify audio track id.\")\n    p.add_argument('--bitrate', type=int, dest=\"bitrate\", default=None, help=\"Bitrate of output file in Megabits.\")\n    p.set_defaults(func=process_videoed_cut_video)\n\n    def process_videoed_denoise_image_sequence(arguments):\n        osex.set_process_lowest_prio()\n        from mainscripts import VideoEd\n        VideoEd.denoise_image_sequence (arguments.input_dir, arguments.factor)\n    p = videoed_parser.add_parser( \"denoise-image-sequence\", help=\"Denoise sequence of images, keeping sharp edges. Helps to remove pixel shake from the predicted face.\")\n    p.add_argument('--input-dir', required=True, action=fixPathAction, dest=\"input_dir\", help=\"Input directory to be processed.\")\n    p.add_argument('--factor', type=int, dest=\"factor\", default=None, help=\"Denoise factor (1-20).\")\n    p.set_defaults(func=process_videoed_denoise_image_sequence)\n\n    def process_videoed_video_from_sequence(arguments):\n        osex.set_process_lowest_prio()\n        from mainscripts import VideoEd\n        VideoEd.video_from_sequence (input_dir      = arguments.input_dir,\n                                     output_file    = arguments.output_file,\n                                     reference_file = arguments.reference_file,\n                                     ext      = arguments.ext,\n                                     fps      = arguments.fps,\n                                     bitrate  = arguments.bitrate,\n                                     include_audio = arguments.include_audio,\n                                     lossless = arguments.lossless)\n\n    p = videoed_parser.add_parser( \"video-from-sequence\", help=\"Make video from image sequence.\")\n    p.add_argument('--input-dir', required=True, action=fixPathAction, dest=\"input_dir\", help=\"Input file to be processed. Specify .*-extension to find first file.\")\n    p.add_argument('--output-file', required=True, action=fixPathAction, dest=\"output_file\", help=\"Input file to be processed. Specify .*-extension to find first file.\")\n    p.add_argument('--reference-file', action=fixPathAction, dest=\"reference_file\", help=\"Reference file used to determine proper FPS and transfer audio from it. Specify .*-extension to find first file.\")\n    p.add_argument('--ext', dest=\"ext\", default='png', help=\"Image format (extension) of input files.\")\n    p.add_argument('--fps', type=int, dest=\"fps\", default=None, help=\"FPS of output file. Overwritten by reference-file.\")\n    p.add_argument('--bitrate', type=int, dest=\"bitrate\", default=None, help=\"Bitrate of output file in Megabits.\")\n    p.add_argument('--include-audio', action=\"store_true\", dest=\"include_audio\", default=False, help=\"Include audio from reference file.\")\n    p.add_argument('--lossless', action=\"store_true\", dest=\"lossless\", default=False, help=\"PNG codec.\")\n\n    p.set_defaults(func=process_videoed_video_from_sequence)\n\n\n\n    def bad_args(arguments):\n        parser.print_help()\n        exit(0)\n    parser.set_defaults(func=bad_args)\n\n    arguments = parser.parse_args()\n    arguments.func(arguments)\n\n    if exit_code == 0:\n        print (\"Done.\")\n        \n    exit(exit_code)\n    \n'''\nimport code\ncode.interact(local=dict(globals(), **locals()))\n'''\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/DeepFaceLab/main.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "process_folder",
            "Description": "FacesetEnhancer.process_folder implements",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/DeepFaceLab/mainscripts/FacesetEnhancer.py",
            "Implementation": "import multiprocessing\nimport shutil\n\nfrom DFLIMG import *\nfrom core.interact import interact as io\nfrom core.joblib import Subprocessor\nfrom core.leras import nn\nfrom core import pathex\nfrom core.cv2ex import *\n\ndef process_folder ( dirpath, cpu_only=False, force_gpu_idxs=None ):\n    device_config = nn.DeviceConfig.GPUIndexes( force_gpu_idxs or nn.ask_choose_device_idxs(suggest_all_gpu=True) ) \\\n                    if not cpu_only else nn.DeviceConfig.CPU()\n\n    output_dirpath = dirpath.parent / (dirpath.name + '_enhanced')\n    output_dirpath.mkdir (exist_ok=True, parents=True)\n\n    dirpath_parts = '/'.join( dirpath.parts[-2:])\n    output_dirpath_parts = '/'.join( output_dirpath.parts[-2:] )\n    io.log_info (f\"Enhancing faceset in {dirpath_parts}\")\n    io.log_info ( f\"Processing to {output_dirpath_parts}\")\n\n    output_images_paths = pathex.get_image_paths(output_dirpath)\n    if len(output_images_paths) > 0:\n        for filename in output_images_paths:\n            Path(filename).unlink()\n\n    image_paths = [Path(x) for x in pathex.get_image_paths( dirpath )]\n    result = FacesetEnhancerSubprocessor ( image_paths, output_dirpath, device_config=device_config).run()\n\n    is_merge = io.input_bool (f\"\\r\\nMerge {output_dirpath_parts} to {dirpath_parts} ?\", True)\n    if is_merge:\n        io.log_info (f\"Copying processed files to {dirpath_parts}\")\n\n        for (filepath, output_filepath) in result:\n            try:\n                shutil.copy (output_filepath, filepath)\n            except:\n                pass\n\n        io.log_info (f\"Removing {output_dirpath_parts}\")\n        shutil.rmtree(output_dirpath)",
            "Examples": [
                "\n"
            ]
        },
        {
            "Name": "video_processors",
            "Description": "some video processor",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/DeepFaceLab/mainscripts/VideoEd.py",
            "Implementation": "import subprocess\nimport numpy as np\nimport ffmpeg\nfrom pathlib import Path\nfrom core import pathex\nfrom core.interact import interact as io\n\ndef extract_video(input_file, output_dir, output_ext=None, fps=None):\n    input_file_path = Path(input_file)\n    output_path = Path(output_dir)\n\n    if not output_path.exists():\n        output_path.mkdir(exist_ok=True)\n\n\n    if input_file_path.suffix == '.*':\n        input_file_path = pathex.get_first_file_by_stem (input_file_path.parent, input_file_path.stem)\n    else:\n        if not input_file_path.exists():\n            input_file_path = None\n\n    if input_file_path is None:\n        io.log_err(\"input_file not found.\")\n        return\n\n    if fps is None:\n        fps = io.input_int (\"Enter FPS\", 0, help_message=\"How many frames of every second of the video will be extracted. 0 - full fps\")\n\n    if output_ext is None:\n        output_ext = io.input_str (\"Output image format\", \"png\", [\"png\",\"jpg\"], help_message=\"png is lossless, but extraction is x10 slower for HDD, requires x10 more disk space than jpg.\")\n\n    for filename in pathex.get_image_paths (output_path, ['.'+output_ext]):\n        Path(filename).unlink()\n\n    job = ffmpeg.input(str(input_file_path))\n\n    kwargs = {'pix_fmt': 'rgb24'}\n    if fps != 0:\n        kwargs.update ({'r':str(fps)})\n\n    if output_ext == 'jpg':\n        kwargs.update ({'q:v':'2'}) #highest quality for jpg\n\n    job = job.output( str (output_path / ('%5d.'+output_ext)), **kwargs )\n\n    try:\n        job = job.run()\n    except:\n        io.log_err (\"ffmpeg fail, job commandline:\" + str(job.compile()) )\n\ndef cut_video ( input_file, from_time=None, to_time=None, audio_track_id=None, bitrate=None):\n    input_file_path = Path(input_file)\n    if input_file_path is None:\n        io.log_err(\"input_file not found.\")\n        return\n\n    output_file_path = input_file_path.parent / (input_file_path.stem + \"_cut\" + input_file_path.suffix)\n\n    if from_time is None:\n        from_time = io.input_str (\"From time\", \"00:00:00.000\")\n\n    if to_time is None:\n        to_time = io.input_str (\"To time\", \"00:00:00.000\")\n\n    if audio_track_id is None:\n        audio_track_id = io.input_int (\"Specify audio track id.\", 0)\n\n    if bitrate is None:\n        bitrate = max (1, io.input_int (\"Bitrate of output file in MB/s\", 25) )\n\n    kwargs = {\"c:v\": \"libx264\",\n              \"b:v\": \"%dM\" %(bitrate),\n              \"pix_fmt\": \"yuv420p\",\n             }\n\n    job = ffmpeg.input(str(input_file_path), ss=from_time, to=to_time)\n\n    job_v = job['v:0']\n    job_a = job['a:' + str(audio_track_id) + '?' ]\n\n    job = ffmpeg.output(job_v, job_a, str(output_file_path), **kwargs).overwrite_output()\n\n    try:\n        job = job.run()\n    except:\n        io.log_err (\"ffmpeg fail, job commandline:\" + str(job.compile()) )\n\ndef denoise_image_sequence( input_dir, ext=None, factor=None ):\n    input_path = Path(input_dir)\n\n    if not input_path.exists():\n        io.log_err(\"input_dir not found.\")\n        return\n\n    image_paths = [ Path(filepath) for filepath in pathex.get_image_paths(input_path) ]\n\n    # Check extension of all images\n    image_paths_suffix = None\n    for filepath in image_paths:\n        if image_paths_suffix is None:\n            image_paths_suffix = filepath.suffix\n        else:\n            if filepath.suffix != image_paths_suffix:\n                io.log_err(f\"All images in {input_path.name} should be with the same extension.\")\n                return\n\n    if factor is None:\n        factor = np.clip ( io.input_int (\"Denoise factor?\", 7, add_info=\"1-20\"), 1, 20 )\n\n    # Rename to temporary filenames\n    for i,filepath in io.progress_bar_generator( enumerate(image_paths), \"Renaming\", leave=False):\n        src = filepath\n        dst = filepath.parent / ( f'{i+1:06}_{filepath.name}' )\n        try:\n            src.rename (dst)\n        except:\n            io.log_error ('fail to rename %s' % (src.name) )\n            return\n\n    # Rename to sequental filenames\n    for i,filepath in io.progress_bar_generator( enumerate(image_paths), \"Renaming\", leave=False):\n\n        src = filepath.parent / ( f'{i+1:06}_{filepath.name}' )\n        dst = filepath.parent / ( f'{i+1:06}{filepath.suffix}' )\n        try:\n            src.rename (dst)\n        except:\n            io.log_error ('fail to rename %s' % (src.name) )\n            return\n\n    # Process image sequence in ffmpeg\n    kwargs = {}\n    if image_paths_suffix == '.jpg':\n        kwargs.update ({'q:v':'2'})\n\n    job = ( ffmpeg\n            .input(str ( input_path / ('%6d'+image_paths_suffix) ) )\n            .filter(\"hqdn3d\", factor, factor, 5,5)\n            .output(str ( input_path / ('%6d'+image_paths_suffix) ), **kwargs )\n           )\n\n    try:\n        job = job.run()\n    except:\n        io.log_err (\"ffmpeg fail, job commandline:\" + str(job.compile()) )\n\n    # Rename to temporary filenames\n    for i,filepath in io.progress_bar_generator( enumerate(image_paths), \"Renaming\", leave=False):\n        src = filepath.parent / ( f'{i+1:06}{filepath.suffix}' )\n        dst = filepath.parent / ( f'{i+1:06}_{filepath.name}' )\n        try:\n            src.rename (dst)\n        except:\n            io.log_error ('fail to rename %s' % (src.name) )\n            return\n\n    # Rename to initial filenames\n    for i,filepath in io.progress_bar_generator( enumerate(image_paths), \"Renaming\", leave=False):\n        src = filepath.parent / ( f'{i+1:06}_{filepath.name}' )\n        dst = filepath\n\n        try:\n            src.rename (dst)\n        except:\n            io.log_error ('fail to rename %s' % (src.name) )\n            return\n\ndef video_from_sequence( input_dir, output_file, reference_file=None, ext=None, fps=None, bitrate=None, include_audio=False, lossless=None ):\n    input_path = Path(input_dir)\n    output_file_path = Path(output_file)\n    reference_file_path = Path(reference_file) if reference_file is not None else None\n\n    if not input_path.exists():\n        io.log_err(\"input_dir not found.\")\n        return\n\n    if not output_file_path.parent.exists():\n        output_file_path.parent.mkdir(parents=True, exist_ok=True)\n        return\n\n    out_ext = output_file_path.suffix\n\n    if ext is None:\n        ext = io.input_str (\"Input image format (extension)\", \"png\")\n\n    if lossless is None:\n        lossless = io.input_bool (\"Use lossless codec\", False)\n\n    video_id = None\n    audio_id = None\n    ref_in_a = None\n    if reference_file_path is not None:\n        if reference_file_path.suffix == '.*':\n            reference_file_path = pathex.get_first_file_by_stem (reference_file_path.parent, reference_file_path.stem)\n        else:\n            if not reference_file_path.exists():\n                reference_file_path = None\n\n        if reference_file_path is None:\n            io.log_err(\"reference_file not found.\")\n            return\n\n        #probing reference file\n        probe = ffmpeg.probe (str(reference_file_path))\n\n        #getting first video and audio streams id with fps\n        for stream in probe['streams']:\n            if video_id is None and stream['codec_type'] == 'video':\n                video_id = stream['index']\n                fps = stream['r_frame_rate']\n\n            if audio_id is None and stream['codec_type'] == 'audio':\n                audio_id = stream['index']\n\n        if audio_id is not None:\n            #has audio track\n            ref_in_a = ffmpeg.input (str(reference_file_path))[str(audio_id)]\n\n    if fps is None:\n        #if fps not specified and not overwritten by reference-file\n        fps = max (1, io.input_int (\"Enter FPS\", 25) )\n\n    if not lossless and bitrate is None:\n        bitrate = max (1, io.input_int (\"Bitrate of output file in MB/s\", 16) )\n\n    input_image_paths = pathex.get_image_paths(input_path)\n\n    i_in = ffmpeg.input('pipe:', format='image2pipe', r=fps)\n\n    output_args = [i_in]\n\n    if include_audio and ref_in_a is not None:\n        output_args += [ref_in_a]\n\n    output_args += [str (output_file_path)]\n\n    output_kwargs = {}\n\n    if lossless:\n        output_kwargs.update ({\"c:v\": \"libx264\",\n                               \"crf\": \"0\",\n                               \"pix_fmt\": \"yuv420p\",\n                              })\n    else:\n        output_kwargs.update ({\"c:v\": \"libx264\",\n                               \"b:v\": \"%dM\" %(bitrate),\n                               \"pix_fmt\": \"yuv420p\",\n                              })\n\n    if include_audio and ref_in_a is not None:\n        output_kwargs.update ({\"c:a\": \"aac\",\n                               \"b:a\": \"192k\",\n                               \"ar\" : \"48000\",\n                               \"strict\": \"experimental\"\n                               })\n\n    job = ( ffmpeg.output(*output_args, **output_kwargs).overwrite_output() )\n\n    try:\n        job_run = job.run_async(pipe_stdin=True)\n\n        for image_path in input_image_paths:\n            with open (image_path, \"rb\") as f:\n                image_bytes = f.read()\n                job_run.stdin.write (image_bytes)\n\n        job_run.stdin.close()\n        job_run.wait()\n    except:\n        io.log_err (\"ffmpeg fail, job commandline:\" + str(job.compile()) )\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}