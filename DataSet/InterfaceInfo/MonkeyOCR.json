{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/MonkeyOCR",
    "API_Calls": [
        {
            "Name": "call_parse",
            "Description": "call_parse",
            "Code": "#!/usr/bin/env python3\n# Copyright (c) Opendatalab. All rights reserved.\nimport os\nimport time\nimport argparse\nimport sys\nimport torch.distributed as dist\nfrom magic_pdf.utils.load_image import pdf_to_images\n\nfrom magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader\nfrom magic_pdf.data.dataset import PymuDocDataset, ImageDataset, MultiFileDataset\nfrom magic_pdf.model.doc_analyze_by_custom_model_llm import doc_analyze_llm\nfrom magic_pdf.model.custom_model import MonkeyOCR\n\nTASK_INSTRUCTIONS = {\n    'text': 'Please output the text content from the image.',\n    'formula': 'Please write out the expression of the formula in the image using LaTeX format.',\n    'table': 'This is the image of a table. Please output the table in html format.'\n}\n\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"PDF Document Parsing Tool\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nUsage examples:\n  # Single file processing\n  python parse.py input.pdf                           # Parse single PDF file\n  python parse.py input.pdf -o ./output               # Parse with custom output dir\n  python parse.py input.pdf -s                        # Parse PDF with page splitting\n  python parse.py image.jpg                           # Parse single image file\n  \n  # Single task recognition\n  python parse.py image.jpg -t text                   # Text recognition from image\n  python parse.py image.jpg -t formula                # Formula recognition from image\n  python parse.py image.jpg -t table                  # Table recognition from image\n  python parse.py document.pdf -t text                # Text recognition from all PDF pages\n  \n  # Folder processing (all files individually)\n  python parse.py /path/to/folder                     # Parse all files in folder\n  python parse.py /path/to/folder -s                  # Parse with page splitting\n  python parse.py /path/to/folder -t text             # Single task recognition for all files\n  \n  # Multi-file grouping (batch processing by page count)\n  python parse.py /path/to/folder -g 5                # Group files with max 5 total pages\n  python parse.py /path/to/folder -g 10 -s            # Group files with page splitting\n  python parse.py /path/to/folder -g 8 -t text        # Group files for single task recognition\n  \n  # Advanced configurations\n  python parse.py input.pdf -c model_configs.yaml     # Custom model configuration\n  python parse.py /path/to/folder -g 15 -s -o ./out   # Group files, split pages, custom output\n  python parse.py input.pdf --pred-abandon            # Enable predicting abandon elements\n        \"\"\"\n    )\n    \n    parser.add_argument(\n        \"input_path\",\n        help=\"Input PDF/image file path or folder path\"\n    )\n    \n    parser.add_argument(\n        \"-o\", \"--output\",\n        default=\"./output\",\n        help=\"Output directory (default: ./output)\"\n    )\n    \n    parser.add_argument(\n        \"-c\", \"--config\",\n        default=\"model_configs.yaml\",\n        help=\"Configuration file path (default: model_configs.yaml)\"\n    )\n    \n    parser.add_argument(\n        \"-t\", \"--task\",\n        choices=['text', 'formula', 'table'],\n        help=\"Single task recognition type (text/formula/table). Supports both image and PDF files.\"\n    )\n\n    parser.add_argument(\n        \"-s\", \"--split_pages\",\n        action='store_true',\n        help=\"Split the output of PDF pages into separate ones (default: False)\"\n    )\n    \n    parser.add_argument(\n        \"-g\", \"--group-size\",\n        type=int,\n        help=\"Maximum total page count per group when processing folders (applies to all file types)\"\n    )\n\n    parser.add_argument(\n        \"--pred-abandon\",\n        action='store_true',\n        help=\"Enable predicting abandon elements like footer and header (default: False)\"\n    )\n    \n    args = parser.parse_args()\n    \n    MonkeyOCR_model = None\n    \n    try:\n        # Check if input path is a directory or file\n        if os.path.isdir(args.input_path):\n            # Process folder\n            result_dir = parse_folder(\n                folder_path = args.input_path,\n                output_dir = args.output,\n                config_path = args.config,\n                task = args.task,\n                split_pages = args.split_pages,\n                group_size = args.group_size,\n                pred_abandon = args.pred_abandon\n            )\n            \n            if args.task:\n                if args.group_size:\n                    print(f\"\\n✅ Folder processing with single task ({args.task}) recognition and image grouping (size: {args.group_size}) completed! Results saved in: {result_dir}\")\n                else:\n                    print(f\"\\n✅ Folder processing with single task ({args.task}) recognition completed! Results saved in: {result_dir}\")\n            else:\n                if args.group_size:\n                    print(f\"\\n✅ Folder processing with image grouping (size: {args.group_size}) completed! Results saved in: {result_dir}\")\n                else:\n                    print(f\"\\n✅ Folder processing completed! Results saved in: {result_dir}\")\n        elif os.path.isfile(args.input_path):\n            # Process single file - initialize model for single file processing\n            print(\"Loading model...\")\n            MonkeyOCR_model = MonkeyOCR(args.config)\n            \n            if args.task:\n                result_dir = single_task_recognition(\n                    input_file = args.input_path,\n                    output_dir = args.output,\n                    MonkeyOCR_model = MonkeyOCR_model,\n                    task = args.task\n                )\n                print(f\"\\n✅ Single task ({args.task}) recognition completed! Results saved in: {result_dir}\")\n            else:\n                result_dir = parse_file(\n                    input_file = args.input_path,\n                    output_dir = args.output,\n                    MonkeyOCR_model = MonkeyOCR_model,\n                    split_pages = args.split_pages,\n                    pred_abandon = args.pred_abandon\n                )\n                print(f\"\\n✅ Parsing completed! Results saved in: {result_dir}\")\n        else:\n            raise FileNotFoundError(f\"Input path does not exist: {args.input_path}\")\n            \n    except Exception as e:\n        print(f\"\\n❌ Processing failed: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n    finally:\n        # Clean up resources\n        try:\n            if MonkeyOCR_model is not None:\n                # Clean up model resources if needed\n                if hasattr(MonkeyOCR_model, 'chat_model') and hasattr(MonkeyOCR_model.chat_model, 'close'):\n                    MonkeyOCR_model.chat_model.close()\n                    \n            # Give time for async tasks to complete before exiting\n            time.sleep(1.0)\n            \n            if dist.is_initialized():\n                dist.destroy_process_group()\n                \n        except Exception as cleanup_error:\n            print(f\"Warning: Error during final cleanup: {cleanup_error}\")\n\n\nif __name__ == \"__main__\":\n    main()",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/MonkeyOCR/parse.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "parse_folder",
            "Description": "parse_folder",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/MonkeyOCR/parse.py",
            "Implementation": "def parse_folder(folder_path, output_dir, config_path, task=None, split_pages=False, group_size=None, pred_abandon=False):\n    \"\"\"\n    Parse all PDF and image files in a folder\n    \n    Args:\n        folder_path: Input folder path\n        output_dir: Output directory\n        config_path: Configuration file path\n        task: Optional task type for single task recognition\n        group_size: Number of files to group together by total page count (None means process individually)\n    \"\"\"\n    print(f\"Starting to parse folder: {folder_path}\")\n    \n    # Record start time for total processing time\n    total_start_time = time.time()\n    \n    # Check if folder exists\n    if not os.path.exists(folder_path):\n        raise FileNotFoundError(f\"Folder does not exist: {folder_path}\")\n    \n    if not os.path.isdir(folder_path):\n        raise ValueError(f\"Path is not a directory: {folder_path}\")\n    \n    # Find all supported files\n    supported_extensions = {'.pdf', '.jpg', '.jpeg', '.png'}\n    all_files = []\n    \n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            file_ext = os.path.splitext(file)[1].lower()\n            if file_ext in supported_extensions:\n                all_files.append(file_path)\n    \n    all_files.sort()\n    \n    # Initialize model once for all files\n    print(\"Loading model...\")\n    MonkeyOCR_model = MonkeyOCR(config_path)\n    \n    successful_files = []\n    failed_files = []\n    \n    if group_size and group_size > 1:\n        # Group files by total page count\n        print(f\"Found {len(all_files)} files to process in groups with max {group_size} total pages\")\n        \n        file_groups = create_file_groups_by_page_count(all_files, group_size)\n        print(f\"Created {len(file_groups)} file groups\")\n        \n        for i, file_group in enumerate(file_groups, 1):\n            print(f\"\\n{'='*60}\")\n            print(f\"Processing file group {i}/{len(file_groups)} (contains {len(file_group)} files)\")\n            for file_path in file_group:\n                print(f\"  - {os.path.basename(file_path)}\")\n            print(f\"{'='*60}\")\n            \n            try:\n                if task:\n                    result_dir = single_task_recognition_multi_file_group(file_group, output_dir, MonkeyOCR_model, task, folder_path)\n                else:\n                    result_dir = parse_multi_file_group(file_group, output_dir, MonkeyOCR_model, folder_path, split_pages, pred_abandon)\n\n                successful_files.extend(file_group)\n                print(f\"✅ Successfully processed file group {i}\")\n                \n            except Exception as e:\n                failed_files.extend([(path, str(e)) for path in file_group])\n                print(f\"❌ Failed to process file group {i}: {str(e)}\")\n    else:\n        # Process files individually\n        print(f\"Found {len(all_files)} files to process individually:\")\n        for file_path in all_files:\n            print(f\"  - {file_path}\")\n        \n        for i, file_path in enumerate(all_files, 1):\n            print(f\"\\n{'='*60}\")\n            print(f\"Processing file {i}/{len(all_files)}: {os.path.basename(file_path)}\")\n            print(f\"{'='*60}\")\n            \n            try:\n                if task:\n                    result_dir = single_task_recognition(file_path, output_dir, MonkeyOCR_model, task)\n                else:\n                    result_dir = parse_file(file_path, output_dir, MonkeyOCR_model, pred_abandon=pred_abandon)\n                \n                successful_files.append(file_path)\n                print(f\"✅ Successfully processed: {os.path.basename(file_path)}\")\n                \n            except Exception as e:\n                failed_files.append((file_path, str(e)))\n                print(f\"❌ Failed to process {os.path.basename(file_path)}: {str(e)}\")\n    \n    if not all_files:\n        print(\"No supported files found in the folder.\")\n        return\n    \n    # Calculate total processing time\n    total_processing_time = time.time() - total_start_time\n    \n    # Summary\n    total_files = len(all_files)\n    print(f\"\\n{'='*60}\")\n    print(\"PROCESSING SUMMARY\")\n    print(f\"{'='*60}\")\n    print(f\"Total files: {total_files}\")\n    print(f\"Successful: {len(successful_files)}\")\n    print(f\"Failed: {len(failed_files)}\")\n    print(f\"Total processing time: {total_processing_time:.2f}s\")\n    \n    if failed_files:\n        print(\"\\nFailed files:\")\n        for file_path, error in failed_files:\n            print(f\"  - {os.path.basename(file_path)}: {error}\")\n    \n    return output_dir",
            "Examples": [
                "\n"
            ]
        },
        {
            "Name": "parse_file",
            "Description": "parse_file",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/MonkeyOCR/parse.py",
            "Implementation": "def single_task_recognition(input_file, output_dir, MonkeyOCR_model, task):\n    \"\"\"\n    Single task recognition for specific content type\n    \n    Args:\n        input_file: Input file path\n        output_dir: Output directory\n        MonkeyOCR_model: Pre-initialized model instance\n        task: Task type ('text', 'formula', 'table')\n    \"\"\"\n    print(f\"Starting single task recognition: {task}\")\n    print(f\"Processing file: {input_file}\")\n    \n    # Check if input file exists\n    if not os.path.exists(input_file):\n        raise FileNotFoundError(f\"Input file does not exist: {input_file}\")\n    \n    # Get filename\n    name_without_suff = '.'.join(os.path.basename(input_file).split(\".\")[:-1])\n    \n    # Prepare output directory\n    local_md_dir = os.path.join(output_dir, name_without_suff)\n    os.makedirs(local_md_dir, exist_ok=True)\n    \n    print(f\"Output dir: {local_md_dir}\")\n    md_writer = FileBasedDataWriter(local_md_dir)\n    \n    # Get task instruction\n    instruction = TASK_INSTRUCTIONS.get(task, TASK_INSTRUCTIONS['text'])\n    \n    # Check file type and prepare images\n    file_extension = input_file.split(\".\")[-1].lower()\n    images = []\n    \n    if file_extension == 'pdf':\n        print(\"⚠️  WARNING: PDF input detected for single task recognition.\")\n        print(\"⚠️  WARNING: Converting all PDF pages to images for processing.\")\n        print(\"⚠️  WARNING: This may take longer and use more resources than image input.\")\n        print(\"⚠️  WARNING: Consider using individual images for better performance.\")\n        \n        try:\n            # Convert PDF pages to PIL images directly\n            print(\"Converting PDF pages to images...\")\n            images = pdf_to_images(input_file)\n            print(f\"Converted {len(images)} pages to images\")\n            \n        except Exception as e:\n            raise RuntimeError(f\"Failed to convert PDF to images: {str(e)}\")\n            \n    elif file_extension in ['jpg', 'jpeg', 'png']:\n        # Load single image\n        from PIL import Image\n        images = [Image.open(input_file)]\n    else:\n        raise ValueError(f\"Single task recognition supports PDF and image files, got: {file_extension}\")\n    \n    # Start recognition\n    print(f\"Performing {task} recognition on {len(images)} image(s)...\")\n    start_time = time.time()\n    \n    try:\n        # Prepare instructions for all images\n        instructions = [instruction] * len(images)\n        \n        # Use chat model for single task recognition with PIL images directly\n        responses = MonkeyOCR_model.chat_model.batch_inference(images, instructions)\n        \n        recognition_time = time.time() - start_time\n        print(f\"Recognition time: {recognition_time:.2f}s\")\n        \n        # Combine results\n        combined_result = responses[0]\n        for i, response in enumerate(responses):\n            if i > 0:\n                combined_result = combined_result + \"\\n\\n\" + response\n        \n        # Save result\n        result_filename = f\"{name_without_suff}_{task}_result.md\"\n        md_writer.write(result_filename, combined_result.encode('utf-8'))\n        \n        print(f\"Single task recognition completed!\")\n        print(f\"Task: {task}\")\n        print(f\"Processed {len(images)} image(s)\")\n        print(f\"Result saved to: {os.path.join(local_md_dir, result_filename)}\")\n        \n        # Clean up resources\n        try:\n            # Give some time for async tasks to complete\n            time.sleep(0.5)\n            \n            # Close images if they were opened\n            for img in images:\n                if hasattr(img, 'close'):\n                    img.close()\n                    \n        except Exception as cleanup_error:\n            print(f\"Warning: Error during cleanup: {cleanup_error}\")\n        \n        return local_md_dir\n        \n    except Exception as e:\n        raise RuntimeError(f\"Single task recognition failed: {str(e)}\")\n\n\ndef parse_file(input_file, output_dir, MonkeyOCR_model, split_pages=False, pred_abandon=False):\n    \"\"\"\n    Parse PDF or image and save results\n    \n    Args:\n        input_file: Input PDF or image file path\n        output_dir: Output directory\n        MonkeyOCR_model: Pre-initialized model instance\n        split_pages: Whether to split result by pages\n    \"\"\"\n    print(f\"Starting to parse file: {input_file}\")\n    \n    # Check if input file exists\n    if not os.path.exists(input_file):\n        raise FileNotFoundError(f\"Input file does not exist: {input_file}\")\n    \n    # Get filename\n    name_without_suff = '.'.join(os.path.basename(input_file).split(\".\")[:-1])\n    \n    # Prepare output directory\n    local_image_dir = os.path.join(output_dir, name_without_suff, \"images\")\n    local_md_dir = os.path.join(output_dir, name_without_suff)\n    image_dir = os.path.basename(local_image_dir)\n    os.makedirs(local_image_dir, exist_ok=True)\n    os.makedirs(local_md_dir, exist_ok=True)\n    \n    print(f\"Output dir: {local_md_dir}\")\n    image_writer = FileBasedDataWriter(local_image_dir)\n    md_writer = FileBasedDataWriter(local_md_dir)\n    \n    # Read file content\n    reader = FileBasedDataReader()\n    file_bytes = reader.read(input_file)\n    \n    # Create dataset instance\n    file_extension = input_file.split(\".\")[-1].lower()\n    if file_extension == \"pdf\":\n        ds = PymuDocDataset(file_bytes)\n    else:\n        ds = ImageDataset(file_bytes)\n    \n    # Start inference\n    print(\"Performing document parsing...\")\n    start_time = time.time()\n    \n    infer_result = ds.apply(doc_analyze_llm, MonkeyOCR_model=MonkeyOCR_model, split_pages=split_pages, pred_abandon=pred_abandon)\n    \n    # Check if infer_result is a list type\n    if isinstance(infer_result, list):\n        print(f\"Processing {len(infer_result)} pages separately...\")\n        \n        # Process each page result separately\n        for page_idx, page_infer_result in enumerate(infer_result):\n            page_dir_name = f\"page_{page_idx}\"\n            page_local_image_dir = os.path.join(output_dir, name_without_suff, page_dir_name, \"images\")\n            page_local_md_dir = os.path.join(output_dir, name_without_suff, page_dir_name)\n            page_image_dir = os.path.basename(page_local_image_dir)\n            \n            # Create page-specific directories\n            os.makedirs(page_local_image_dir, exist_ok=True)\n            os.makedirs(page_local_md_dir, exist_ok=True)\n            \n            # Create page-specific writers\n            page_image_writer = FileBasedDataWriter(page_local_image_dir)\n            page_md_writer = FileBasedDataWriter(page_local_md_dir)\n            \n            print(f\"Processing page {page_idx} - Output dir: {page_local_md_dir}\")\n            \n            # Pipeline processing for this page\n            page_pipe_result = page_infer_result.pipe_ocr_mode(page_image_writer, MonkeyOCR_model=MonkeyOCR_model)\n            \n            # Save page-specific results\n            page_infer_result.draw_model(os.path.join(page_local_md_dir, f\"{name_without_suff}_page_{page_idx}_model.pdf\"))\n            page_pipe_result.draw_layout(os.path.join(page_local_md_dir, f\"{name_without_suff}_page_{page_idx}_layout.pdf\"))\n            page_pipe_result.draw_span(os.path.join(page_local_md_dir, f\"{name_without_suff}_page_{page_idx}_spans.pdf\"))\n            page_pipe_result.dump_md(page_md_writer, f\"{name_without_suff}_page_{page_idx}.md\", page_image_dir)\n            page_pipe_result.dump_content_list(page_md_writer, f\"{name_without_suff}_page_{page_idx}_content_list.json\", page_image_dir)\n            page_pipe_result.dump_middle_json(page_md_writer, f'{name_without_suff}_page_{page_idx}_middle.json')\n        \n        print(f\"All {len(infer_result)} pages processed and saved in separate subdirectories\")\n    else:\n        print(\"Processing as single result...\")\n        \n        # Pipeline processing for single result\n        pipe_result = infer_result.pipe_ocr_mode(image_writer, MonkeyOCR_model=MonkeyOCR_model)\n        \n        # Save single result (original logic)\n        infer_result.draw_model(os.path.join(local_md_dir, f\"{name_without_suff}_model.pdf\"))\n        \n        pipe_result.draw_layout(os.path.join(local_md_dir, f\"{name_without_suff}_layout.pdf\"))\n\n        pipe_result.draw_span(os.path.join(local_md_dir, f\"{name_without_suff}_spans.pdf\"))\n\n        pipe_result.dump_md(md_writer, f\"{name_without_suff}.md\", image_dir)\n        \n        pipe_result.dump_content_list(md_writer, f\"{name_without_suff}_content_list.json\", image_dir)\n\n        pipe_result.dump_middle_json(md_writer, f'{name_without_suff}_middle.json')\n\n    parsing_time = time.time() - start_time\n    print(f\"Parsing and saving time: {parsing_time:.2f}s\")\n    \n    print(\"Results saved to \", local_md_dir)\n    return local_md_dir",
            "Examples": [
                "\n"
            ]
        }
    ]
}