{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/roop",
    "API_Calls": [
        {
            "Name": "cli_call_predict_image_predict_video",
            "Description": "call predict_video and predict_image to get predictions for video and image files respectively.",
            "Code": "#!/usr/bin/env python3\n\nimport os\nimport sys\n# single thread doubles cuda performance - needs to be set before torch import\nif any(arg.startswith('--execution-provider') for arg in sys.argv):\n    os.environ['OMP_NUM_THREADS'] = '1'\n# reduce tensorflow log level\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport warnings\nfrom typing import List\nimport platform\nimport signal\nimport shutil\nimport argparse\nimport onnxruntime\nimport tensorflow\nimport roop.globals\nimport roop.metadata\nimport roop.ui as ui\nfrom roop.predictor import predict_image, predict_video\nfrom roop.processors.frame.core import get_frame_processors_modules\nfrom roop.utilities import has_image_extension, is_image, is_video, detect_fps, create_video, extract_frames, get_temp_frame_paths, restore_audio, create_temp, move_temp, clean_temp, normalize_output_path\n\nwarnings.filterwarnings('ignore', category=FutureWarning, module='insightface')\nwarnings.filterwarnings('ignore', category=UserWarning, module='torchvision')\n\n\ndef parse_args() -> None:\n    signal.signal(signal.SIGINT, lambda signal_number, frame: destroy())\n    program = argparse.ArgumentParser(formatter_class=lambda prog: argparse.HelpFormatter(prog, max_help_position=100))\n    program.add_argument('-s', '--source', help='select an source image', dest='source_path')\n    program.add_argument('-t', '--target', help='select an target image or video', dest='target_path')\n    program.add_argument('-o', '--output', help='select output file or directory', dest='output_path')\n    program.add_argument('--frame-processor', help='frame processors (choices: face_swapper, face_enhancer, ...)', dest='frame_processor', default=['face_swapper'], nargs='+')\n    program.add_argument('--keep-fps', help='keep target fps', dest='keep_fps', action='store_true')\n    program.add_argument('--keep-frames', help='keep temporary frames', dest='keep_frames', action='store_true')\n    program.add_argument('--skip-audio', help='skip target audio', dest='skip_audio', action='store_true')\n    program.add_argument('--many-faces', help='process every face', dest='many_faces', action='store_true')\n    program.add_argument('--reference-face-position', help='position of the reference face', dest='reference_face_position', type=int, default=0)\n    program.add_argument('--reference-frame-number', help='number of the reference frame', dest='reference_frame_number', type=int, default=0)\n    program.add_argument('--similar-face-distance', help='face distance used for recognition', dest='similar_face_distance', type=float, default=0.85)\n    program.add_argument('--temp-frame-format', help='image format used for frame extraction', dest='temp_frame_format', default='png', choices=['jpg', 'png'])\n    program.add_argument('--temp-frame-quality', help='image quality used for frame extraction', dest='temp_frame_quality', type=int, default=0, choices=range(101), metavar='[0-100]')\n    program.add_argument('--output-video-encoder', help='encoder used for the output video', dest='output_video_encoder', default='libx264', choices=['libx264', 'libx265', 'libvpx-vp9', 'h264_nvenc', 'hevc_nvenc'])\n    program.add_argument('--output-video-quality', help='quality used for the output video', dest='output_video_quality', type=int, default=35, choices=range(101), metavar='[0-100]')\n    program.add_argument('--max-memory', help='maximum amount of RAM in GB', dest='max_memory', type=int)\n    program.add_argument('--execution-provider', help='available execution provider (choices: cpu, ...)', dest='execution_provider', default=['cpu'], choices=suggest_execution_providers(), nargs='+')\n    program.add_argument('--execution-threads', help='number of execution threads', dest='execution_threads', type=int, default=suggest_execution_threads())\n    program.add_argument('-v', '--version', action='version', version=f'{roop.metadata.name} {roop.metadata.version}')\n\n    args = program.parse_args()\n\n    roop.globals.source_path = args.source_path\n    roop.globals.target_path = args.target_path\n    roop.globals.output_path = normalize_output_path(roop.globals.source_path, roop.globals.target_path, args.output_path)\n    roop.globals.headless = roop.globals.source_path is not None and roop.globals.target_path is not None and roop.globals.output_path is not None\n    roop.globals.frame_processors = args.frame_processor\n    roop.globals.keep_fps = args.keep_fps\n    roop.globals.keep_frames = args.keep_frames\n    roop.globals.skip_audio = args.skip_audio\n    roop.globals.many_faces = args.many_faces\n    roop.globals.reference_face_position = args.reference_face_position\n    roop.globals.reference_frame_number = args.reference_frame_number\n    roop.globals.similar_face_distance = args.similar_face_distance\n    roop.globals.temp_frame_format = args.temp_frame_format\n    roop.globals.temp_frame_quality = args.temp_frame_quality\n    roop.globals.output_video_encoder = args.output_video_encoder\n    roop.globals.output_video_quality = args.output_video_quality\n    roop.globals.max_memory = args.max_memory\n    roop.globals.execution_providers = decode_execution_providers(args.execution_provider)\n    roop.globals.execution_threads = args.execution_threads\n\n\ndef encode_execution_providers(execution_providers: List[str]) -> List[str]:\n    return [execution_provider.replace('ExecutionProvider', '').lower() for execution_provider in execution_providers]\n\n\ndef decode_execution_providers(execution_providers: List[str]) -> List[str]:\n    return [provider for provider, encoded_execution_provider in zip(onnxruntime.get_available_providers(), encode_execution_providers(onnxruntime.get_available_providers()))\n            if any(execution_provider in encoded_execution_provider for execution_provider in execution_providers)]\n\n\ndef suggest_execution_providers() -> List[str]:\n    return encode_execution_providers(onnxruntime.get_available_providers())\n\n\ndef suggest_execution_threads() -> int:\n    if 'CUDAExecutionProvider' in onnxruntime.get_available_providers():\n        return 8\n    return 1\n\n\ndef limit_resources() -> None:\n    # prevent tensorflow memory leak\n    gpus = tensorflow.config.experimental.list_physical_devices('GPU')\n    for gpu in gpus:\n        tensorflow.config.experimental.set_virtual_device_configuration(gpu, [\n            tensorflow.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)\n        ])\n    # limit memory usage\n    if roop.globals.max_memory:\n        memory = roop.globals.max_memory * 1024 ** 3\n        if platform.system().lower() == 'darwin':\n            memory = roop.globals.max_memory * 1024 ** 6\n        if platform.system().lower() == 'windows':\n            import ctypes\n            kernel32 = ctypes.windll.kernel32  # type: ignore[attr-defined]\n            kernel32.SetProcessWorkingSetSize(-1, ctypes.c_size_t(memory), ctypes.c_size_t(memory))\n        else:\n            import resource\n            resource.setrlimit(resource.RLIMIT_DATA, (memory, memory))\n\n\ndef pre_check() -> bool:\n    if sys.version_info < (3, 9):\n        update_status('Python version is not supported - please upgrade to 3.9 or higher.')\n        return False\n    if not shutil.which('ffmpeg'):\n        update_status('ffmpeg is not installed.')\n        return False\n    return True\n\n\ndef update_status(message: str, scope: str = 'ROOP.CORE') -> None:\n    print(f'[{scope}] {message}')\n    if not roop.globals.headless:\n        ui.update_status(message)\n\n\ndef start() -> None:\n    for frame_processor in get_frame_processors_modules(roop.globals.frame_processors):\n        if not frame_processor.pre_start():\n            return\n    # process image to image\n    if has_image_extension(roop.globals.target_path):\n        if predict_image(roop.globals.target_path):\n            destroy()\n        shutil.copy2(roop.globals.target_path, roop.globals.output_path)\n        # process frame\n        for frame_processor in get_frame_processors_modules(roop.globals.frame_processors):\n            update_status('Progressing...', frame_processor.NAME)\n            frame_processor.process_image(roop.globals.source_path, roop.globals.output_path, roop.globals.output_path)\n            frame_processor.post_process()\n        # validate image\n        if is_image(roop.globals.target_path):\n            update_status('Processing to image succeed!')\n        else:\n            update_status('Processing to image failed!')\n        return\n    # process image to videos\n    if predict_video(roop.globals.target_path):\n        destroy()\n    update_status('Creating temporary resources...')\n    create_temp(roop.globals.target_path)\n    # extract frames\n    if roop.globals.keep_fps:\n        fps = detect_fps(roop.globals.target_path)\n        update_status(f'Extracting frames with {fps} FPS...')\n        extract_frames(roop.globals.target_path, fps)\n    else:\n        update_status('Extracting frames with 30 FPS...')\n        extract_frames(roop.globals.target_path)\n    # process frame\n    temp_frame_paths = get_temp_frame_paths(roop.globals.target_path)\n    if temp_frame_paths:\n        for frame_processor in get_frame_processors_modules(roop.globals.frame_processors):\n            update_status('Progressing...', frame_processor.NAME)\n            frame_processor.process_video(roop.globals.source_path, temp_frame_paths)\n            frame_processor.post_process()\n    else:\n        update_status('Frames not found...')\n        return\n    # create video\n    if roop.globals.keep_fps:\n        fps = detect_fps(roop.globals.target_path)\n        update_status(f'Creating video with {fps} FPS...')\n        create_video(roop.globals.target_path, fps)\n    else:\n        update_status('Creating video with 30 FPS...')\n        create_video(roop.globals.target_path)\n    # handle audio\n    if roop.globals.skip_audio:\n        move_temp(roop.globals.target_path, roop.globals.output_path)\n        update_status('Skipping audio...')\n    else:\n        if roop.globals.keep_fps:\n            update_status('Restoring audio...')\n        else:\n            update_status('Restoring audio might cause issues as fps are not kept...')\n        restore_audio(roop.globals.target_path, roop.globals.output_path)\n    # clean temp\n    update_status('Cleaning temporary resources...')\n    clean_temp(roop.globals.target_path)\n    # validate video\n    if is_video(roop.globals.target_path):\n        update_status('Processing to video succeed!')\n    else:\n        update_status('Processing to video failed!')\n\n\ndef destroy() -> None:\n    if roop.globals.target_path:\n        clean_temp(roop.globals.target_path)\n    sys.exit()\n\n\ndef run() -> None:\n    parse_args()\n    if not pre_check():\n        return\n    for frame_processor in get_frame_processors_modules(roop.globals.frame_processors):\n        if not frame_processor.pre_check():\n            return\n    limit_resources()\n    if roop.globals.headless:\n        start()\n    else:\n        window = ui.init(start, destroy)\n        window.mainloop()\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/roop/roop/core.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "predict_image_predict_video",
            "Description": "predict_image_predict_video implements",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/roop/roop/predictor.py",
            "Implementation": "import threading\nimport numpy\nimport opennsfw2\nfrom PIL import Image\nfrom keras import Model\n\nfrom roop.typing import Frame\n\nPREDICTOR = None\nTHREAD_LOCK = threading.Lock()\nMAX_PROBABILITY = 0.85\n\n\ndef get_predictor() -> Model:\n    global PREDICTOR\n\n    with THREAD_LOCK:\n        if PREDICTOR is None:\n            PREDICTOR = opennsfw2.make_open_nsfw_model()\n    return PREDICTOR\n\n\ndef clear_predictor() -> None:\n    global PREDICTOR\n\n    PREDICTOR = None\n\n\ndef predict_frame(target_frame: Frame) -> bool:\n    image = Image.fromarray(target_frame)\n    image = opennsfw2.preprocess_image(image, opennsfw2.Preprocessing.YAHOO)\n    views = numpy.expand_dims(image, axis=0)\n    _, probability = get_predictor().predict(views)[0]\n    return probability > MAX_PROBABILITY\n\n\ndef predict_image(target_path: str) -> bool:\n    return opennsfw2.predict_image(target_path) > MAX_PROBABILITY\n\n\ndef predict_video(target_path: str) -> bool:\n    _, probabilities = opennsfw2.predict_video_frames(video_path=target_path, frame_interval=100)\n    return any(probability > MAX_PROBABILITY for probability in probabilities)\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}