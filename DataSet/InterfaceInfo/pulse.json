{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/pulse",
    "API_Calls": [
        {
            "Name": "call_PULSE",
            "Description": "call PULSE",
            "Code": "from PULSE import PULSE\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import DataParallel\nfrom pathlib import Path\nfrom PIL import Image\nimport torchvision\nfrom math import log10, ceil\nimport argparse\nimport torch\n\nclass Images(Dataset):\n    def __init__(self, root_dir, duplicates):\n        self.root_path = Path(root_dir)\n        self.image_list = list(self.root_path.glob(\"*.png\"))\n        self.duplicates = duplicates # Number of times to duplicate the image in the dataset to produce multiple HR images\n\n    def __len__(self):\n        return self.duplicates*len(self.image_list)\n\n    def __getitem__(self, idx):\n        img_path = self.image_list[idx//self.duplicates]\n        image = torchvision.transforms.ToTensor()(Image.open(img_path))\n        if(self.duplicates == 1):\n            return image,img_path.stem\n        else:\n            return image,img_path.stem+f\"_{(idx % self.duplicates)+1}\"\n\nparser = argparse.ArgumentParser(description='PULSE')\n\n#I/O arguments\nparser.add_argument('-input_dir', type=str, default='input', help='input data directory')\nparser.add_argument('-output_dir', type=str, default='runs', help='output data directory')\nparser.add_argument('-cache_dir', type=str, default='cache', help='cache directory for model weights')\nparser.add_argument('-duplicates', type=int, default=1, help='How many HR images to produce for every image in the input directory')\nparser.add_argument('-batch_size', type=int, default=1, help='Batch size to use during optimization')\n\n#PULSE arguments\nparser.add_argument('-seed', type=int, help='manual seed to use')\nparser.add_argument('-loss_str', type=str, default=\"100*L2+0.05*GEOCROSS\", help='Loss function to use')\nparser.add_argument('-eps', type=float, default=2e-3, help='Target for downscaling loss (L2)')\nparser.add_argument('-noise_type', type=str, default='trainable', help='zero, fixed, or trainable')\nparser.add_argument('-num_trainable_noise_layers', type=int, default=5, help='Number of noise layers to optimize')\nparser.add_argument('-tile_latent', action='store_true', help='Whether to forcibly tile the same latent 18 times')\nparser.add_argument('-bad_noise_layers', type=str, default=\"17\", help='List of noise layers to zero out to improve image quality')\nparser.add_argument('-opt_name', type=str, default='adam', help='Optimizer to use in projected gradient descent')\nparser.add_argument('-learning_rate', type=float, default=0.4, help='Learning rate to use during optimization')\nparser.add_argument('-steps', type=int, default=100, help='Number of optimization steps')\nparser.add_argument('-lr_schedule', type=str, default='linear1cycledrop', help='fixed, linear1cycledrop, linear1cycle')\nparser.add_argument('-save_intermediate', action='store_true', help='Whether to store and save intermediate HR and LR images during optimization')\n\nkwargs = vars(parser.parse_args())\n\ndataset = Images(kwargs[\"input_dir\"], duplicates=kwargs[\"duplicates\"])\nout_path = Path(kwargs[\"output_dir\"])\nout_path.mkdir(parents=True, exist_ok=True)\n\ndataloader = DataLoader(dataset, batch_size=kwargs[\"batch_size\"])\nmodel = PULSE(cache_dir=kwargs[\"cache_dir\"])\n# model = DataParallel(model)\n\ntoPIL = torchvision.transforms.ToPILImage()\n\nfor ref_im, ref_im_name in dataloader:\n    # Move ref_im to GPU if CUDA is available\n    if torch.cuda.is_available():\n        ref_im = ref_im.cuda()\n    \n    if(kwargs[\"save_intermediate\"]):\n        padding = ceil(log10(100))\n        for i in range(kwargs[\"batch_size\"]):\n            int_path_HR = Path(out_path / ref_im_name[i] / \"HR\")\n            int_path_LR = Path(out_path / ref_im_name[i] / \"LR\")\n            int_path_HR.mkdir(parents=True, exist_ok=True)\n            int_path_LR.mkdir(parents=True, exist_ok=True)\n        for j,(HR,LR) in enumerate(model(ref_im,**kwargs)):\n            for i in range(kwargs[\"batch_size\"]):\n                toPIL(HR[i].cpu().detach().clamp(0, 1)).save(\n                    int_path_HR / f\"{ref_im_name[i]}_{j:0{padding}}.png\")\n                toPIL(LR[i].cpu().detach().clamp(0, 1)).save(\n                    int_path_LR / f\"{ref_im_name[i]}_{j:0{padding}}.png\")\n    else:\n        #out_im = model(ref_im,**kwargs)\n        for j,(HR,LR) in enumerate(model(ref_im,**kwargs)):\n            for i in range(kwargs[\"batch_size\"]):\n                toPIL(HR[i].cpu().detach().clamp(0, 1)).save(\n                    out_path / f\"{ref_im_name[i]}.png\")\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/pulse/run.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "PULSE",
            "Description": "impl PULSE",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/pulse/PULSE.py",
            "Implementation": "from stylegan import G_synthesis,G_mapping\nfrom dataclasses import dataclass\nfrom SphericalOptimizer import SphericalOptimizer\nfrom pathlib import Path\nimport numpy as np\nimport time\nimport torch\nfrom loss import LossBuilder\nfrom functools import partial\nfrom drive import open_url\n\n\nclass PULSE(torch.nn.Module):\n    def __init__(self, cache_dir, verbose=True):\n        super(PULSE, self).__init__()\n\n        self.synthesis = G_synthesis().cuda()\n        self.verbose = verbose\n\n        cache_dir = Path(cache_dir)\n        cache_dir.mkdir(parents=True, exist_ok = True)\n        if self.verbose: print(\"Loading Synthesis Network\")\n        with open_url(\"https://drive.google.com/uc?id=1TCViX1YpQyRsklTVYEJwdbmK91vklCo8\", cache_dir=cache_dir, verbose=verbose) as f:\n            self.synthesis.load_state_dict(torch.load(f))\n\n        for param in self.synthesis.parameters():\n            param.requires_grad = False\n\n        self.lrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n\n        if Path(\"gaussian_fit.pt\").exists():\n            self.gaussian_fit = torch.load(\"gaussian_fit.pt\")\n        else:\n            if self.verbose: print(\"\\tLoading Mapping Network\")\n            mapping = G_mapping().cuda()\n\n            with open_url(\"https://drive.google.com/uc?id=14R6iHGf5iuVx3DMNsACAl7eBr7Vdpd0k\", cache_dir=cache_dir, verbose=verbose) as f:\n                    mapping.load_state_dict(torch.load(f))\n\n            if self.verbose: print(\"\\tRunning Mapping Network\")\n            with torch.no_grad():\n                torch.manual_seed(0)\n                latent = torch.randn((1000000,512),dtype=torch.float32, device=\"cuda\")\n                latent_out = torch.nn.LeakyReLU(5)(mapping(latent))\n                self.gaussian_fit = {\"mean\": latent_out.mean(0), \"std\": latent_out.std(0)}\n                torch.save(self.gaussian_fit,\"gaussian_fit.pt\")\n                if self.verbose: print(\"\\tSaved \\\"gaussian_fit.pt\\\"\")\n\n    def forward(self, ref_im,\n                seed,\n                loss_str,\n                eps,\n                noise_type,\n                num_trainable_noise_layers,\n                tile_latent,\n                bad_noise_layers,\n                opt_name,\n                learning_rate,\n                steps,\n                lr_schedule,\n                save_intermediate,\n                **kwargs):\n\n        if seed:\n            torch.manual_seed(seed)\n            torch.cuda.manual_seed(seed)\n            torch.backends.cudnn.deterministic = True\n\n        batch_size = ref_im.shape[0]\n\n        # Generate latent tensor\n        if(tile_latent):\n            latent = torch.randn(\n                (batch_size, 1, 512), dtype=torch.float, requires_grad=True, device='cuda')\n        else:\n            latent = torch.randn(\n                (batch_size, 18, 512), dtype=torch.float, requires_grad=True, device='cuda')\n\n        # Generate list of noise tensors\n        noise = [] # stores all of the noise tensors\n        noise_vars = []  # stores the noise tensors that we want to optimize on\n\n        for i in range(18):\n            # dimension of the ith noise tensor\n            res = (batch_size, 1, 2**(i//2+2), 2**(i//2+2))\n\n            if(noise_type == 'zero' or i in [int(layer) for layer in bad_noise_layers.split('.')]):\n                new_noise = torch.zeros(res, dtype=torch.float, device='cuda')\n                new_noise.requires_grad = False\n            elif(noise_type == 'fixed'):\n                new_noise = torch.randn(res, dtype=torch.float, device='cuda')\n                new_noise.requires_grad = False\n            elif (noise_type == 'trainable'):\n                new_noise = torch.randn(res, dtype=torch.float, device='cuda')\n                if (i < num_trainable_noise_layers):\n                    new_noise.requires_grad = True\n                    noise_vars.append(new_noise)\n                else:\n                    new_noise.requires_grad = False\n            else:\n                raise Exception(\"unknown noise type\")\n\n            noise.append(new_noise)\n\n        var_list = [latent]+noise_vars\n\n        opt_dict = {\n            'sgd': torch.optim.SGD,\n            'adam': torch.optim.Adam,\n            'sgdm': partial(torch.optim.SGD, momentum=0.9),\n            'adamax': torch.optim.Adamax\n        }\n        opt_func = opt_dict[opt_name]\n        opt = SphericalOptimizer(opt_func, var_list, lr=learning_rate)\n\n        schedule_dict = {\n            'fixed': lambda x: 1,\n            'linear1cycle': lambda x: (9*(1-np.abs(x/steps-1/2)*2)+1)/10,\n            'linear1cycledrop': lambda x: (9*(1-np.abs(x/(0.9*steps)-1/2)*2)+1)/10 if x < 0.9*steps else 1/10 + (x-0.9*steps)/(0.1*steps)*(1/1000-1/10),\n        }\n        schedule_func = schedule_dict[lr_schedule]\n        scheduler = torch.optim.lr_scheduler.LambdaLR(opt.opt, schedule_func)\n        \n        loss_builder = LossBuilder(ref_im, loss_str, eps).cuda()\n\n        min_loss = np.inf\n        min_l2 = np.inf\n        best_summary = \"\"\n        start_t = time.time()\n        gen_im = None\n\n\n        if self.verbose: print(\"Optimizing\")\n        for j in range(steps):\n            opt.opt.zero_grad()\n\n            # Duplicate latent in case tile_latent = True\n            if (tile_latent):\n                latent_in = latent.expand(-1, 18, -1)\n            else:\n                latent_in = latent\n\n            # Apply learned linear mapping to match latent distribution to that of the mapping network\n            latent_in = self.lrelu(latent_in*self.gaussian_fit[\"std\"] + self.gaussian_fit[\"mean\"])\n\n            # Normalize image to [0,1] instead of [-1,1]\n            gen_im = (self.synthesis(latent_in, noise)+1)/2\n\n            # Calculate Losses\n            loss, loss_dict = loss_builder(latent_in, gen_im)\n            loss_dict['TOTAL'] = loss\n\n            # Save best summary for log\n            if(loss < min_loss):\n                min_loss = loss\n                best_summary = f'BEST ({j+1}) | '+' | '.join(\n                [f'{x}: {y:.4f}' for x, y in loss_dict.items()])\n                best_im = gen_im.clone()\n\n            loss_l2 = loss_dict['L2']\n\n            if(loss_l2 < min_l2):\n                min_l2 = loss_l2\n\n            # Save intermediate HR and LR images\n            if(save_intermediate):\n                yield (best_im.cpu().detach().clamp(0, 1),loss_builder.D(best_im).cpu().detach().clamp(0, 1))\n\n            loss.backward()\n            opt.step()\n            scheduler.step()\n\n        total_t = time.time()-start_t\n        current_info = f' | time: {total_t:.1f} | it/s: {(j+1)/total_t:.2f} | batchsize: {batch_size}'\n        if self.verbose: print(best_summary+current_info)\n        if(min_l2 <= eps):\n            yield (gen_im.clone().cpu().detach().clamp(0, 1),loss_builder.D(best_im).cpu().detach().clamp(0, 1))\n        else:\n            print(\"Could not find a face that downscales correctly within epsilon\")\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}