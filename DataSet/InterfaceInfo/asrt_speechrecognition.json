{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/ASRT_SpeechRecognition",
    "API_Calls": [
        {
            "Name": "call_ModelSpeech",
            "Description": "call ModelSpeech",
            "Code": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n用于通过ASRT语音识别系统预测一次语音文件的程序\n\"\"\"\n\nimport os\n\nfrom speech_model import ModelSpeech\nfrom model_zoo.speech_model.keras_backend import SpeechModel251BN\nfrom speech_features import Spectrogram\nfrom language_model3 import ModelLanguage\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nAUDIO_LENGTH = 1600\nAUDIO_FEATURE_LENGTH = 200\nCHANNELS = 1\n# 默认输出的拼音的表示大小是1428，即1427个拼音+1个空白块\nOUTPUT_SIZE = 1428\nsm251bn = SpeechModel251BN(\n    input_shape=(AUDIO_LENGTH, AUDIO_FEATURE_LENGTH, CHANNELS),\n    output_size=OUTPUT_SIZE\n)\nfeat = Spectrogram()\nms = ModelSpeech(sm251bn, feat, max_label_length=64)\n\nms.load_model('save_models/' + sm251bn.get_model_name() + '.model.h5')\nres = ms.recognize_speech_from_file('filename.wav')\nprint('*[提示] 声学模型语音识别结果：\\n', res)\n\nml = ModelLanguage('model_language')\nml.load_model()\nstr_pinyin = res\nres = ml.pinyin_to_text(str_pinyin)\nprint('语音识别最终结果：\\n', res)\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/ASRT_SpeechRecognition/predict_speech_file.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "ModelSpeech",
            "Description": "ASRT专用N-Gram语言模型",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/ASRT_SpeechRecognition/speech_model.py",
            "Implementation": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n声学模型基础功能模板定义\n\"\"\"\nimport os\nimport time\nimport random\nimport numpy as np\n\nfrom utils.ops import get_edit_distance, read_wav_data\nfrom utils.config import load_config_file, DEFAULT_CONFIG_FILENAME, load_pinyin_dict\nfrom utils.thread import threadsafe_generator\n\n\nclass ModelSpeech:\n    \"\"\"\n    语音模型类\n\n    参数：\n        speech_model: 声学模型类型 (BaseModel类) 实例对象\n        speech_features: 声学特征类型(SpeechFeatureMeta类)实例对象\n    \"\"\"\n\n    def __init__(self, speech_model, speech_features, max_label_length=64):\n        self.data_loader = None\n        self.speech_model = speech_model\n        self.trained_model, self.base_model = speech_model.get_model()\n        self.speech_features = speech_features\n        self.max_label_length = max_label_length\n\n    @threadsafe_generator\n    def _data_generator(self, batch_size, data_loader):\n        \"\"\"\n        数据生成器函数，用于Keras的generator_fit训练\n        batch_size: 一次产生的数据量\n        \"\"\"\n        labels = np.zeros((batch_size, 1), dtype=np.float64)\n        data_count = data_loader.get_data_count()\n        index = 0\n\n        while True:\n            X = np.zeros((batch_size,) + self.speech_model.input_shape, dtype=np.float64)\n            y = np.zeros((batch_size, self.max_label_length), dtype=np.int16)\n            input_length = []\n            label_length = []\n\n            for i in range(batch_size):\n                wavdata, sample_rate, data_labels = data_loader.get_data(index)\n                data_input = self.speech_features.run(wavdata, sample_rate)\n                data_input = data_input.reshape(data_input.shape[0], data_input.shape[1], 1)\n                # 必须加上模pool_size得到的值，否则会出现inf问题，然后提示No valid path found.\n                # 但是直接加又可能会出现sequence_length <= xxx 的问题，因此不能让其超过时间序列长度的最大值，比如200\n                pool_size = self.speech_model.input_shape[0] // self.speech_model.output_shape[0]\n                inlen = min(data_input.shape[0] // pool_size + data_input.shape[0] % pool_size,\n                            self.speech_model.output_shape[0])\n                input_length.append(inlen)\n\n                X[i, 0:len(data_input)] = data_input\n                y[i, 0:len(data_labels)] = data_labels\n                label_length.append([len(data_labels)])\n\n                index = (index + 1) % data_count\n\n            label_length = np.matrix(label_length)\n            input_length = np.array([input_length]).T\n\n            yield [X, y, input_length, label_length], labels\n\n    def train_model(self, optimizer, data_loader, epochs=1, save_step=1, batch_size=16, last_epoch=0, call_back=None):\n        \"\"\"\n        训练模型\n\n        参数：\n            optimizer：tensorflow.keras.optimizers 优化器实例对象\n            data_loader：数据加载器类型 (SpeechData) 实例对象\n            epochs: 迭代轮数\n            save_step: 每多少epoch保存一次模型\n            batch_size: mini batch大小\n            last_epoch: 上一次epoch的编号，可用于断点处继续训练时，epoch编号不冲突\n            call_back: keras call back函数\n        \"\"\"\n        save_filename = os.path.join('save_models', self.speech_model.get_model_name(),\n                                     self.speech_model.get_model_name())\n\n        self.trained_model.compile(loss=self.speech_model.get_loss_function(), optimizer=optimizer)\n        print('[ASRT] Compiles Model Successfully.')\n\n        yielddatas = self._data_generator(batch_size, data_loader)\n\n        data_count = data_loader.get_data_count()  # 获取数据的数量\n        # 计算每一个epoch迭代的次数\n        num_iterate = data_count // batch_size\n        iter_start = last_epoch\n        iter_end = last_epoch + epochs\n        for epoch in range(iter_start, iter_end):  # 迭代轮数\n            try:\n                epoch += 1\n                print('[ASRT Training] train epoch %d/%d .' % (epoch, iter_end))\n                data_loader.shuffle()\n                self.trained_model.fit_generator(yielddatas, num_iterate, callbacks=call_back)\n            except StopIteration:\n                print('[error] generator error. please check data format.')\n                break\n\n            if epoch % save_step == 0:\n                if not os.path.exists('save_models'):  # 判断保存模型的目录是否存在\n                    os.makedirs('save_models')  # 如果不存在，就新建一个，避免之后保存模型的时候炸掉\n                if not os.path.exists(os.path.join('save_models', self.speech_model.get_model_name())):  # 判断保存模型的目录是否存在\n                    os.makedirs(\n                        os.path.join('save_models', self.speech_model.get_model_name()))  # 如果不存在，就新建一个，避免之后保存模型的时候炸掉\n\n                self.save_model(save_filename + '_epoch' + str(epoch))\n\n        print('[ASRT Info] Model training complete. ')\n\n    def load_model(self, filename):\n        \"\"\"\n        加载模型参数\n        \"\"\"\n        self.speech_model.load_weights(filename)\n\n    def save_model(self, filename):\n        \"\"\"\n        保存模型参数\n        \"\"\"\n        self.speech_model.save_weights(filename)\n\n    def evaluate_model(self, data_loader, data_count=-1, out_report=False, show_ratio=True, show_per_step=100):\n        \"\"\"\n        评估检验模型的识别效果\n        \"\"\"\n        data_nums = data_loader.get_data_count()\n\n        if data_count <= 0 or data_count > data_nums:  # 当data_count为小于等于0或者大于测试数据量的值时，则使用全部数据来测试\n            data_count = data_nums\n\n        try:\n            ran_num = random.randint(0, data_nums - 1)  # 获取一个随机数\n            words_num = 0\n            word_error_num = 0\n\n            nowtime = time.strftime('%Y%m%d_%H%M%S', time.localtime(time.time()))\n            if out_report:\n                txt_obj = open('Test_Report_' + data_loader.dataset_type + '_' + nowtime + '.txt', 'w',\n                               encoding='UTF-8')  # 打开文件并读入\n                txt_obj.truncate((data_count + 1) * 300)  # 预先分配一定数量的磁盘空间，避免后期在硬盘中文件存储位置频繁移动，以防写入速度越来越慢\n                txt_obj.seek(0)  # 从文件首开始\n\n            txt = ''\n            i = 0\n            while i < data_count:\n                wavdata, fs, data_labels = data_loader.get_data((ran_num + i) % data_nums)  # 从随机数开始连续向后取一定数量数据\n                data_input = self.speech_features.run(wavdata, fs)\n                data_input = data_input.reshape(data_input.shape[0], data_input.shape[1], 1)\n                # 数据格式出错处理 开始\n                # 当输入的wav文件长度过长时自动跳过该文件，转而使用下一个wav文件来运行\n                if data_input.shape[0] > self.speech_model.input_shape[0]:\n                    print('*[Error]', 'wave data lenghth of num', (ran_num + i) % data_nums, 'is too long.',\n                          'this data\\'s length is', data_input.shape[0],\n                          'expect <=', self.speech_model.input_shape[0],\n                          '\\n A Exception raise when test Speech Model.')\n                    i += 1\n                    continue\n                # 数据格式出错处理 结束\n\n                pre = self.predict(data_input)\n\n                words_n = data_labels.shape[0]  # 获取每个句子的字数\n                words_num += words_n  # 把句子的总字数加上\n                edit_distance = get_edit_distance(data_labels, pre)  # 获取编辑距离\n                if edit_distance <= words_n:  # 当编辑距离小于等于句子字数时\n                    word_error_num += edit_distance  # 使用编辑距离作为错误字数\n                else:  # 否则肯定是增加了一堆乱七八糟的奇奇怪怪的字\n                    word_error_num += words_n  # 就直接加句子本来的总字数就好了\n\n                if i % show_per_step == 0 and show_ratio:\n                    print('[ASRT Info] Testing: ', i, '/', data_count)\n\n                txt = ''\n                if out_report:\n                    txt += str(i) + '\\n'\n                    txt += 'True:\\t' + str(data_labels) + '\\n'\n                    txt += 'Pred:\\t' + str(pre) + '\\n'\n                    txt += '\\n'\n                    txt_obj.write(txt)\n\n                i += 1\n\n            # print('*[测试结果] 语音识别 ' + str_dataset + ' 集语音单字错误率：', word_error_num / words_num * 100, '%')\n            print('*[ASRT Test Result] Speech Recognition ' + data_loader.dataset_type + ' set word error ratio: ',\n                  word_error_num / words_num * 100, '%')\n            if out_report:\n                txt = '*[ASRT Test Result] Speech Recognition ' + data_loader.dataset_type + ' set word error ratio: ' + str(\n                    word_error_num / words_num * 100) + ' %'\n                txt_obj.write(txt)\n                txt_obj.truncate()  # 去除文件末尾剩余未使用的空白存储字节\n                txt_obj.close()\n\n        except StopIteration:\n            print('[ASRT Error] Model testing raise a error. Please check data format.')\n\n    def predict(self, data_input):\n        \"\"\"\n        预测结果\n\n        返回语音识别后的forward结果\n        \"\"\"\n        return self.speech_model.forward(data_input)\n\n    def recognize_speech(self, wavsignal, fs):\n        \"\"\"\n        最终做语音识别用的函数，识别一个wav序列的语音\n        \"\"\"\n        # 获取输入特征\n        data_input = self.speech_features.run(wavsignal, fs)\n        data_input = np.array(data_input, dtype=np.float64)\n        # print(data_input,data_input.shape)\n        data_input = data_input.reshape(data_input.shape[0], data_input.shape[1], 1)\n        r1 = self.predict(data_input)\n        # 获取拼音列表\n        list_symbol_dic, _ = load_pinyin_dict(load_config_file(DEFAULT_CONFIG_FILENAME)['dict_filename'])\n\n        r_str = []\n        for i in r1:\n            r_str.append(list_symbol_dic[i])\n\n        return r_str\n\n    def recognize_speech_from_file(self, filename):\n        \"\"\"\n        最终做语音识别用的函数，识别指定文件名的语音\n        \"\"\"\n        wavsignal, sample_rate, _, _ = read_wav_data(filename)\n        r = self.recognize_speech(wavsignal, sample_rate)\n        return r\n\n    @property\n    def model(self):\n        \"\"\"\n        返回tf.keras model\n        \"\"\"\n        return self.trained_model\n",
            "Examples": [
                "\n"
            ]
        },
        {
            "Name": "ModelLanguage",
            "Description": "ASRT专用N-Gram语言模型",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/ASRT_SpeechRecognition/language_model3.py",
            "Implementation": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\nASRT语音识别的语言模型\n\n基于N-Gram的语言模型\n\"\"\"\n\nimport os\n\nfrom utils.ops import get_symbol_dict, get_language_model\n\n\nclass ModelLanguage:\n    \"\"\"\n    ASRT专用N-Gram语言模型\n    \"\"\"\n\n    def __init__(self, model_path: str):\n        self.model_path = model_path\n        self.dict_pinyin = dict()\n        self.model1 = dict()\n        self.model2 = dict()\n\n    def load_model(self):\n        \"\"\"\n        加载N-Gram语言模型到内存\n        \"\"\"\n        self.dict_pinyin = get_symbol_dict('dict.txt')\n        self.model1 = get_language_model(os.path.join(self.model_path, 'language_model1.txt'))\n        self.model2 = get_language_model(os.path.join(self.model_path, 'language_model2.txt'))\n        model = (self.dict_pinyin, self.model1, self.model2)\n        return model\n\n    def pinyin_to_text(self, list_pinyin: list, beam_size: int = 100) -> str:\n        \"\"\"\n        拼音转文本，一次性取得全部结果\n        \"\"\"\n        result = list()\n        tmp_result_last = list()\n        for item_pinyin in list_pinyin:\n            tmp_result = self.pinyin_stream_decode(tmp_result_last, item_pinyin, beam_size)\n            if len(tmp_result) == 0 and len(tmp_result_last) > 0:\n                result.append(tmp_result_last[0][0])\n                tmp_result = self.pinyin_stream_decode([], item_pinyin, beam_size)\n                if len(tmp_result) > 0:\n                    result.append(tmp_result[0][0])\n                tmp_result = []\n            tmp_result_last = tmp_result\n\n        if len(tmp_result_last) > 0:\n            result.append(tmp_result_last[0][0])\n\n        return ''.join(result)\n\n    def pinyin_stream_decode(self, temple_result: list,\n                             item_pinyin: str,\n                             beam_size: int = 100) -> list:\n        \"\"\"\n        拼音流式解码，逐字转换，每次返回中间结果\n        \"\"\"\n        # 如果这个拼音不在汉语拼音字典里的话，直接返回空列表，不做decode\n        if item_pinyin not in self.dict_pinyin:\n            return []\n\n        # 获取拼音下属的字的列表，cur_words包含了该拼音对应的所有的字\n        cur_words = self.dict_pinyin[item_pinyin]\n        # 第一个字做初始处理\n        if len(temple_result) == 0:\n            lst_result = list()\n            for word in cur_words:\n                # 添加该字到可能的句子列表，设置初始概率为1.0\n                lst_result.append([word, 1.0])\n            return lst_result\n\n        # 开始处理已经至少有一个字的中间结果情况\n        new_result = list()\n        for sequence in temple_result:\n            for cur_word in cur_words:\n                # 得到2-gram的汉字子序列\n                tuple2_word = sequence[0][-1] + cur_word\n                if tuple2_word not in self.model2:\n                    # 如果2-gram子序列不存在\n                    continue\n                # 计算状态转移概率\n                prob_origin = sequence[1]  # 原始概率\n                count_two_word = float(self.model2[tuple2_word])  # 二字频数\n                count_one_word = float(self.model1[tuple2_word[-2]])  # 单字频数\n                cur_probility = prob_origin * count_two_word / count_one_word\n                new_result.append([sequence[0] + cur_word, cur_probility])\n\n        new_result = sorted(new_result, key=lambda x: x[1], reverse=True)\n        if len(new_result) > beam_size:\n            return new_result[0:beam_size]\n        return new_result\n\n\nif __name__ == '__main__':\n    ml = ModelLanguage('model_language')\n    ml.load_model()\n\n    _str_pinyin = ['zhe4', 'zhen1', 'shi4', 'ji2', 'hao3', 'de5']\n    _RESULT = ml.pinyin_to_text(_str_pinyin)\n    print('语音转文字结果:\\n', _RESULT)\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}