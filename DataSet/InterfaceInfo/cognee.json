{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/cognee",
    "API_Calls": [
        {
            "Name": "simple_example_search",
            "Description": "simple_example_search",
            "Code": "import asyncio\nimport cognee\nfrom cognee.shared.logging_utils import setup_logging, ERROR\nfrom cognee.api.v1.search import SearchType\n\n# Prerequisites:\n# 1. Copy `.env.template` and rename it to `.env`.\n# 2. Add your OpenAI API key to the `.env` file in the `LLM_API_KEY` field:\n#    LLM_API_KEY = \"your_key_here\"\n\n\nasync def main():\n    # Create a clean slate for cognee -- reset data and system state\n    print(\"Resetting cognee data...\")\n    await cognee.prune.prune_data()\n    await cognee.prune.prune_system(metadata=True)\n    print(\"Data reset complete.\\n\")\n\n    # cognee knowledge graph will be created based on this text\n    text = \"\"\"\n    Natural language processing (NLP) is an interdisciplinary\n    subfield of computer science and information retrieval.\n    \"\"\"\n\n    print(\"Adding text to cognee:\")\n    print(text.strip())\n    # Add the text, and make it available for cognify\n    await cognee.add(text)\n    print(\"Text added successfully.\\n\")\n\n    print(\"Running cognify to create knowledge graph...\\n\")\n    print(\"Cognify process steps:\")\n    print(\"1. Classifying the document: Determining the type and category of the input text.\")\n    print(\n        \"2. Checking permissions: Ensuring the user has the necessary rights to process the text.\"\n    )\n    print(\n        \"3. Extracting text chunks: Breaking down the text into sentences or phrases for analysis.\"\n    )\n    print(\"4. Adding data points: Storing the extracted chunks for processing.\")\n    print(\n        \"5. Generating knowledge graph: Extracting entities and relationships to form a knowledge graph.\"\n    )\n    print(\"6. Summarizing text: Creating concise summaries of the content for quick insights.\\n\")\n\n    # Use LLMs and cognee to create knowledge graph\n    await cognee.cognify()\n    print(\"Cognify process complete.\\n\")\n\n    query_text = \"Tell me about NLP\"\n    print(f\"Searching cognee for insights with query: '{query_text}'\")\n    # Query cognee for insights on the added text\n    search_results = await cognee.search(query_type=SearchType.INSIGHTS, query_text=query_text)\n\n    print(\"Search results:\")\n    # Display results\n    for result_text in search_results:\n        print(result_text)\n\n    # Example output:\n    # ({'id': UUID('bc338a39-64d6-549a-acec-da60846dd90d'), 'updated_at': datetime.datetime(2024, 11, 21, 12, 23, 1, 211808, tzinfo=datetime.timezone.utc), 'name': 'natural language processing', 'description': 'An interdisciplinary subfield of computer science and information retrieval.'}, {'relationship_name': 'is_a_subfield_of', 'source_node_id': UUID('bc338a39-64d6-549a-acec-da60846dd90d'), 'target_node_id': UUID('6218dbab-eb6a-5759-a864-b3419755ffe0'), 'updated_at': datetime.datetime(2024, 11, 21, 12, 23, 15, 473137, tzinfo=datetime.timezone.utc)}, {'id': UUID('6218dbab-eb6a-5759-a864-b3419755ffe0'), 'updated_at': datetime.datetime(2024, 11, 21, 12, 23, 1, 211808, tzinfo=datetime.timezone.utc), 'name': 'computer science', 'description': 'The study of computation and information processing.'})\n    # (...)\n    # It represents nodes and relationships in the knowledge graph:\n    # - The first element is the source node (e.g., 'natural language processing').\n    # - The second element is the relationship between nodes (e.g., 'is_a_subfield_of').\n    # - The third element is the target node (e.g., 'computer science').\n\n\nif __name__ == \"__main__\":\n    logger = setup_logging(log_level=ERROR)\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n    try:\n        loop.run_until_complete(main())\n    finally:\n        loop.run_until_complete(loop.shutdown_asyncgens())\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/cognee/examples/python/simple_example.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "search",
            "Description": "search",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/cognee/cognee/api/v1/search/search.py",
            "Implementation": "from uuid import UUID\nfrom typing import Union, Optional, List, Type\n\nfrom cognee.modules.users.models import User\nfrom cognee.modules.search.types import SearchType\nfrom cognee.modules.users.methods import get_default_user\nfrom cognee.modules.search.methods import search as search_function\nfrom cognee.modules.data.methods import get_authorized_existing_datasets\nfrom cognee.modules.data.exceptions import DatasetNotFoundError\n\n\nasync def search(\n    query_text: str,\n    query_type: SearchType = SearchType.GRAPH_COMPLETION,\n    user: User = None,\n    datasets: Optional[Union[list[str], str]] = None,\n    dataset_ids: Optional[Union[list[UUID], UUID]] = None,\n    system_prompt_path: str = \"answer_simple_question.txt\",\n    top_k: int = 10,\n    node_type: Optional[Type] = None,\n    node_name: Optional[List[str]] = None,\n) -> list:\n    # We use lists from now on for datasets\n    if isinstance(datasets, UUID) or isinstance(datasets, str):\n        datasets = [datasets]\n\n    if user is None:\n        user = await get_default_user()\n\n    # Transform string based datasets to UUID - String based datasets can only be found for current user\n    if datasets is not None and [all(isinstance(dataset, str) for dataset in datasets)]:\n        datasets = await get_authorized_existing_datasets(datasets, \"read\", user)\n        datasets = [dataset.id for dataset in datasets]\n        if not datasets:\n            raise DatasetNotFoundError(message=\"No datasets found.\")\n\n    filtered_search_results = await search_function(\n        query_text=query_text,\n        query_type=query_type,\n        dataset_ids=dataset_ids if dataset_ids else datasets,\n        user=user,\n        system_prompt_path=system_prompt_path,\n        top_k=top_k,\n        node_type=node_type,\n        node_name=node_name,\n    )\n\n    return filtered_search_results\n",
            "Examples": [
                "\n"
            ]
        },
        {
            "Name": "add",
            "Description": "add",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/cognee/cognee/api/v1/add/add.py",
            "Implementation": "from uuid import UUID\nfrom typing import Union, BinaryIO, List, Optional\n\nfrom cognee.modules.pipelines import Task\nfrom cognee.modules.users.models import User\nfrom cognee.modules.pipelines import cognee_pipeline\nfrom cognee.tasks.ingestion import ingest_data, resolve_data_directories\n\n\nasync def add(\n    data: Union[BinaryIO, list[BinaryIO], str, list[str]],\n    dataset_name: str = \"main_dataset\",\n    user: User = None,\n    node_set: Optional[List[str]] = None,\n    vector_db_config: dict = None,\n    graph_db_config: dict = None,\n    dataset_id: UUID = None,\n):\n    tasks = [\n        Task(resolve_data_directories),\n        Task(ingest_data, dataset_name, user, node_set, dataset_id),\n    ]\n\n    pipeline_run_info = None\n\n    async for run_info in cognee_pipeline(\n        tasks=tasks,\n        datasets=dataset_id if dataset_id else dataset_name,\n        data=data,\n        user=user,\n        pipeline_name=\"add_pipeline\",\n        vector_db_config=vector_db_config,\n        graph_db_config=graph_db_config,\n    ):\n        pipeline_run_info = run_info\n\n    return pipeline_run_info\n",
            "Examples": [
                "\n"
            ]
        }
    ]
}