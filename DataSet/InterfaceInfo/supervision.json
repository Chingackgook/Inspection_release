{
    "Project_Root": "/mnt/autor_name/haoTingDeWenJianJia/supervision",
    "API_Calls": [
        {
            "Name": "yolo_nas_example",
            "Description": "yolo_nas使用Detection类的示例",
            "Code": "import argparse\nfrom collections import defaultdict, deque\n\nimport cv2\nimport numpy as np\nfrom super_gradients.common.object_names import Models\nfrom super_gradients.training import models\n\nimport supervision as sv\n\nSOURCE = np.array([[1252, 787], [2298, 803], [5039, 2159], [-550, 2159]])\n\nTARGET_WIDTH = 25\nTARGET_HEIGHT = 250\n\nTARGET = np.array(\n    [\n        [0, 0],\n        [TARGET_WIDTH - 1, 0],\n        [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],\n        [0, TARGET_HEIGHT - 1],\n    ]\n)\n\n\nclass ViewTransformer:\n    def __init__(self, source: np.ndarray, target: np.ndarray) -> None:\n        source = source.astype(np.float32)\n        target = target.astype(np.float32)\n        self.m = cv2.getPerspectiveTransform(source, target)\n\n    def transform_points(self, points: np.ndarray) -> np.ndarray:\n        if points.size == 0:\n            return points\n\n        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)\n        return transformed_points.reshape(-1, 2)\n\n\ndef parse_arguments() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description=\"Vehicle Speed Estimation using YOLO-NAS and Supervision\"\n    )\n    parser.add_argument(\n        \"--source_video_path\",\n        required=True,\n        help=\"Path to the source video file\",\n        type=str,\n    )\n    parser.add_argument(\n        \"--target_video_path\",\n        required=True,\n        help=\"Path to the target video file (output)\",\n        type=str,\n    )\n    parser.add_argument(\n        \"--confidence_threshold\",\n        default=0.3,\n        help=\"Confidence threshold for the model\",\n        type=float,\n    )\n    parser.add_argument(\n        \"--iou_threshold\", default=0.7, help=\"IOU threshold for the model\", type=float\n    )\n\n    return parser.parse_args()\n\n\nif __name__ == \"__main__\":\n    args = parse_arguments()\n\n    video_info = sv.VideoInfo.from_video_path(video_path=args.source_video_path)\n    model = models.get(Models.YOLO_NAS_L, pretrained_weights=\"coco\")\n\n    byte_track = sv.ByteTrack(\n        frame_rate=video_info.fps, track_activation_threshold=args.confidence_threshold\n    )\n\n    thickness = sv.calculate_optimal_line_thickness(\n        resolution_wh=video_info.resolution_wh\n    )\n    text_scale = sv.calculate_optimal_text_scale(resolution_wh=video_info.resolution_wh)\n    box_annotator = sv.BoxAnnotator(thickness=thickness)\n    label_annotator = sv.LabelAnnotator(\n        text_scale=text_scale,\n        text_thickness=thickness,\n        text_position=sv.Position.BOTTOM_CENTER,\n    )\n    trace_annotator = sv.TraceAnnotator(\n        thickness=thickness,\n        trace_length=video_info.fps * 2,\n        position=sv.Position.BOTTOM_CENTER,\n    )\n\n    frame_generator = sv.get_video_frames_generator(source_path=args.source_video_path)\n\n    polygon_zone = sv.PolygonZone(polygon=SOURCE)\n    view_transformer = ViewTransformer(source=SOURCE, target=TARGET)\n\n    coordinates = defaultdict(lambda: deque(maxlen=video_info.fps))\n\n    with sv.VideoSink(args.target_video_path, video_info) as sink:\n        for frame in frame_generator:\n            result = model.predict(frame)\n            detections = sv.Detections.from_yolo_nas(result)\n            detections = detections[polygon_zone.trigger(detections)]\n            detections = detections.with_nms(threshold=args.iou_threshold)\n            detections = byte_track.update_with_detections(detections=detections)\n\n            points = detections.get_anchors_coordinates(\n                anchor=sv.Position.BOTTOM_CENTER\n            )\n            points = view_transformer.transform_points(points=points).astype(int)\n\n            for tracker_id, [_, y] in zip(detections.tracker_id, points):\n                coordinates[tracker_id].append(y)\n\n            labels = []\n            for tracker_id in detections.tracker_id:\n                if len(coordinates[tracker_id]) < video_info.fps / 2:\n                    labels.append(f\"#{tracker_id}\")\n                else:\n                    coordinate_start = coordinates[tracker_id][-1]\n                    coordinate_end = coordinates[tracker_id][0]\n                    distance = abs(coordinate_start - coordinate_end)\n                    time = len(coordinates[tracker_id]) / video_info.fps\n                    speed = distance / time * 3.6\n                    labels.append(f\"#{tracker_id} {int(speed)} km/h\")\n\n            annotated_frame = frame.copy()\n            annotated_frame = trace_annotator.annotate(\n                scene=annotated_frame, detections=detections\n            )\n            annotated_frame = box_annotator.annotate(\n                scene=annotated_frame, detections=detections\n            )\n            annotated_frame = label_annotator.annotate(\n                scene=annotated_frame, detections=detections, labels=labels\n            )\n\n            sink.write_frame(annotated_frame)\n            cv2.imshow(\"frame\", annotated_frame)\n            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n                break\n        cv2.destroyAllWindows()\n",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/supervision/examples/speed_estimation/yolo_nas_example.py"
        }
    ],
    "API_Implementations": [
        {
            "Name": "class_Detections",
            "Description": "Detections 类的 __getitem__ 方法用于从 Detections 对象中获取特定的检测结果子集，它支持多种索引方式，允许用户根据不同的条件筛选和获取感兴趣的检测数据。这些索引方式包括整数索引、切片索引、列表索引、布尔数组索引和字符串索引。通过这些索引方式，用户可以方便地筛选出符合特定条件的检测结果，例如根据类别 ID、置信度等条件进行筛选。",
            "Path": "/mnt/autor_name/haoTingDeWenJianJia/supervision/supervision/detection/core.py",
            "Implementation": "from __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, Dict, Iterator, List, Optional, Tuple, Union\n\nimport numpy as np\n\nfrom supervision.config import (\n    CLASS_NAME_DATA_FIELD,\n    ORIENTED_BOX_COORDINATES,\n)\nfrom supervision.detection.overlap_filter import (\n    box_non_max_merge,\n    box_non_max_suppression,\n    mask_non_max_suppression,\n)\nfrom supervision.detection.tools.transformers import (\n    process_transformers_detection_result,\n    process_transformers_v4_segmentation_result,\n    process_transformers_v5_segmentation_result,\n)\nfrom supervision.detection.utils import (\n    box_iou_batch,\n    calculate_masks_centroids,\n    extract_ultralytics_masks,\n    get_data_item,\n    is_data_equal,\n    is_metadata_equal,\n    mask_to_xyxy,\n    merge_data,\n    merge_metadata,\n    process_roboflow_result,\n    xywh_to_xyxy,\n)\nfrom supervision.detection.vlm import (\n    LMM,\n    VLM,\n    from_florence_2,\n    from_paligemma,\n    from_qwen_2_5_vl,\n    validate_vlm_parameters,\n)\nfrom supervision.geometry.core import Position\nfrom supervision.utils.internal import deprecated, get_instance_variables\nfrom supervision.validators import validate_detections_fields\n\n\n@dataclass\nclass Detections:\n    xyxy: np.ndarray\n    mask: Optional[np.ndarray] = None\n    confidence: Optional[np.ndarray] = None\n    class_id: Optional[np.ndarray] = None\n    tracker_id: Optional[np.ndarray] = None\n    data: Dict[str, Union[np.ndarray, List]] = field(default_factory=dict)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def __post_init__(self):\n        validate_detections_fields(\n            xyxy=self.xyxy,\n            mask=self.mask,\n            confidence=self.confidence,\n            class_id=self.class_id,\n            tracker_id=self.tracker_id,\n            data=self.data,\n        )\n\n    def __len__(self):\n        \"\"\"\n        Returns the number of detections in the Detections object.\n        \"\"\"\n        return len(self.xyxy)\n\n    def __iter__(\n        self,\n    ) -> Iterator[\n        Tuple[\n            np.ndarray,\n            Optional[np.ndarray],\n            Optional[float],\n            Optional[int],\n            Optional[int],\n            Dict[str, Union[np.ndarray, List]],\n        ]\n    ]:\n        \"\"\"\n        Iterates over the Detections object and yield a tuple of\n        `(xyxy, mask, confidence, class_id, tracker_id, data)` for each detection.\n        \"\"\"\n        for i in range(len(self.xyxy)):\n            yield (\n                self.xyxy[i],\n                self.mask[i] if self.mask is not None else None,\n                self.confidence[i] if self.confidence is not None else None,\n                self.class_id[i] if self.class_id is not None else None,\n                self.tracker_id[i] if self.tracker_id is not None else None,\n                get_data_item(self.data, i),\n            )\n\n    def __eq__(self, other: Detections):\n        return all(\n            [\n                np.array_equal(self.xyxy, other.xyxy),\n                np.array_equal(self.mask, other.mask),\n                np.array_equal(self.class_id, other.class_id),\n                np.array_equal(self.confidence, other.confidence),\n                np.array_equal(self.tracker_id, other.tracker_id),\n                is_data_equal(self.data, other.data),\n                is_metadata_equal(self.metadata, other.metadata),\n            ]\n        )\n\n    @classmethod\n    def from_yolov5(cls, yolov5_results) -> Detections:\n        \"\"\"\n        Creates a Detections instance from a\n        [YOLOv5](https://github.com/ultralytics/yolov5) inference result.\n\n        Args:\n            yolov5_results (yolov5.models.common.Detections):\n                The output Detections instance from YOLOv5\n\n        Returns:\n            Detections: A new Detections object.\n\n        Example:\n            ```python\n            import cv2\n            import torch\n            import supervision as sv\n\n            image = cv2.imread(<SOURCE_IMAGE_PATH>)\n            model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n            result = model(image)\n            detections = sv.Detections.from_yolov5(result)\n            ```\n        \"\"\"\n        yolov5_detections_predictions = yolov5_results.pred[0].cpu().cpu().numpy()\n\n        return cls(\n            xyxy=yolov5_detections_predictions[:, :4],\n            confidence=yolov5_detections_predictions[:, 4],\n            class_id=yolov5_detections_predictions[:, 5].astype(int),\n        )\n\n    @classmethod\n    def from_ultralytics(cls, ultralytics_results) -> Detections:\n\n        if hasattr(ultralytics_results, \"obb\") and ultralytics_results.obb is not None:\n            class_id = ultralytics_results.obb.cls.cpu().numpy().astype(int)\n            class_names = np.array([ultralytics_results.names[i] for i in class_id])\n            oriented_box_coordinates = ultralytics_results.obb.xyxyxyxy.cpu().numpy()\n            return cls(\n                xyxy=ultralytics_results.obb.xyxy.cpu().numpy(),\n                confidence=ultralytics_results.obb.conf.cpu().numpy(),\n                class_id=class_id,\n                tracker_id=ultralytics_results.obb.id.int().cpu().numpy()\n                if ultralytics_results.obb.id is not None\n                else None,\n                data={\n                    ORIENTED_BOX_COORDINATES: oriented_box_coordinates,\n                    CLASS_NAME_DATA_FIELD: class_names,\n                },\n            )\n\n        if hasattr(ultralytics_results, \"boxes\") and ultralytics_results.boxes is None:\n            masks = extract_ultralytics_masks(ultralytics_results)\n            return cls(\n                xyxy=mask_to_xyxy(masks),\n                mask=masks,\n                class_id=np.arange(len(ultralytics_results)),\n            )\n\n        class_id = ultralytics_results.boxes.cls.cpu().numpy().astype(int)\n        class_names = np.array([ultralytics_results.names[i] for i in class_id])\n        return cls(\n            xyxy=ultralytics_results.boxes.xyxy.cpu().numpy(),\n            confidence=ultralytics_results.boxes.conf.cpu().numpy(),\n            class_id=class_id,\n            mask=extract_ultralytics_masks(ultralytics_results),\n            tracker_id=ultralytics_results.boxes.id.int().cpu().numpy()\n            if ultralytics_results.boxes.id is not None\n            else None,\n            data={CLASS_NAME_DATA_FIELD: class_names},\n        )\n\n    @classmethod\n    def from_yolo_nas(cls, yolo_nas_results) -> Detections:\n       \n        if np.asarray(yolo_nas_results.prediction.bboxes_xyxy).shape[0] == 0:\n            return cls.empty()\n\n        return cls(\n            xyxy=yolo_nas_results.prediction.bboxes_xyxy,\n            confidence=yolo_nas_results.prediction.confidence,\n            class_id=yolo_nas_results.prediction.labels.astype(int),\n        )\n\n    @classmethod\n    def from_tensorflow(\n        cls, tensorflow_results: dict, resolution_wh: tuple\n    ) -> Detections:\n       \n        boxes = tensorflow_results[\"detection_boxes\"][0].numpy()\n        boxes[:, [0, 2]] *= resolution_wh[0]\n        boxes[:, [1, 3]] *= resolution_wh[1]\n        boxes = boxes[:, [1, 0, 3, 2]]\n        return cls(\n            xyxy=boxes,\n            confidence=tensorflow_results[\"detection_scores\"][0].numpy(),\n            class_id=tensorflow_results[\"detection_classes\"][0].numpy().astype(int),\n        )\n\n    @classmethod\n    def from_deepsparse(cls, deepsparse_results) -> Detections:\n       \n\n        if np.asarray(deepsparse_results.boxes[0]).shape[0] == 0:\n            return cls.empty()\n\n        return cls(\n            xyxy=np.array(deepsparse_results.boxes[0]),\n            confidence=np.array(deepsparse_results.scores[0]),\n            class_id=np.array(deepsparse_results.labels[0]).astype(float).astype(int),\n        )\n\n    @classmethod\n    def from_mmdetection(cls, mmdet_results) -> Detections:\n        \n\n        return cls(\n            xyxy=mmdet_results.pred_instances.bboxes.cpu().numpy(),\n            confidence=mmdet_results.pred_instances.scores.cpu().numpy(),\n            class_id=mmdet_results.pred_instances.labels.cpu().numpy().astype(int),\n            mask=mmdet_results.pred_instances.masks.cpu().numpy()\n            if \"masks\" in mmdet_results.pred_instances\n            else None,\n        )\n\n    @classmethod\n    def from_transformers(\n        cls, transformers_results: dict, id2label: Optional[Dict[int, str]] = None\n    ) -> Detections:\n       \n\n        if (\n            transformers_results.__class__.__name__ == \"Tensor\"\n            or \"segmentation\" in transformers_results\n        ):\n            return cls(\n                **process_transformers_v5_segmentation_result(\n                    transformers_results, id2label\n                )\n            )\n\n        if \"masks\" in transformers_results or \"png_string\" in transformers_results:\n            return cls(\n                **process_transformers_v4_segmentation_result(\n                    transformers_results, id2label\n                )\n            )\n\n        if \"boxes\" in transformers_results:\n            return cls(\n                **process_transformers_detection_result(transformers_results, id2label)\n            )\n\n        else:\n            raise ValueError(\n                \"The provided Transformers results do not contain any valid fields.\"\n                \" Expected fields are 'boxes', 'masks', 'segments_info' or\"\n                \" 'segmentation'.\"\n            )\n\n    @classmethod\n    def from_detectron2(cls, detectron2_results: Any) -> Detections:\n        \n\n        return cls(\n            xyxy=detectron2_results[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n            confidence=detectron2_results[\"instances\"].scores.cpu().numpy(),\n            mask=detectron2_results[\"instances\"].pred_masks.cpu().numpy()\n            if hasattr(detectron2_results[\"instances\"], \"pred_masks\")\n            else None,\n            class_id=detectron2_results[\"instances\"]\n            .pred_classes.cpu()\n            .numpy()\n            .astype(int),\n        )\n\n    @classmethod\n    def from_inference(cls, roboflow_result: Union[dict, Any]) -> Detections:\n        \n        if hasattr(roboflow_result, \"dict\"):\n            roboflow_result = roboflow_result.dict(exclude_none=True, by_alias=True)\n        elif hasattr(roboflow_result, \"json\"):\n            roboflow_result = roboflow_result.json()\n        xyxy, confidence, class_id, masks, trackers, data = process_roboflow_result(\n            roboflow_result=roboflow_result\n        )\n\n        if np.asarray(xyxy).shape[0] == 0:\n            empty_detection = cls.empty()\n            empty_detection.data = {CLASS_NAME_DATA_FIELD: np.empty(0)}\n            return empty_detection\n\n        return cls(\n            xyxy=xyxy,\n            confidence=confidence,\n            class_id=class_id,\n            mask=masks,\n            tracker_id=trackers,\n            data=data,\n        )\n\n    @classmethod\n    def from_sam(cls, sam_result: List[dict]) -> Detections:\n       \n\n        sorted_generated_masks = sorted(\n            sam_result, key=lambda x: x[\"area\"], reverse=True\n        )\n\n        xywh = np.array([mask[\"bbox\"] for mask in sorted_generated_masks])\n        mask = np.array([mask[\"segmentation\"] for mask in sorted_generated_masks])\n\n        if np.asarray(xywh).shape[0] == 0:\n            return cls.empty()\n\n        xyxy = xywh_to_xyxy(xywh=xywh)\n        return cls(xyxy=xyxy, mask=mask)\n\n    @classmethod\n    def from_azure_analyze_image(\n        cls, azure_result: dict, class_map: Optional[Dict[int, str]] = None\n    ) -> Detections:\n        \n        if \"error\" in azure_result:\n            raise ValueError(\n                f\"Azure API returned an error {azure_result['error']['message']}\"\n            )\n\n        xyxy, confidences, class_ids = [], [], []\n\n        is_dynamic_mapping = class_map is None\n        if is_dynamic_mapping:\n            class_map = {}\n\n        class_map = {value: key for key, value in class_map.items()}\n\n        for detection in azure_result[\"objectsResult\"][\"values\"]:\n            bbox = detection[\"boundingBox\"]\n\n            tags = detection[\"tags\"]\n\n            x0 = bbox[\"x\"]\n            y0 = bbox[\"y\"]\n            x1 = x0 + bbox[\"w\"]\n            y1 = y0 + bbox[\"h\"]\n\n            for tag in tags:\n                confidence = tag[\"confidence\"]\n                class_name = tag[\"name\"]\n                class_id = class_map.get(class_name, None)\n\n                if is_dynamic_mapping and class_id is None:\n                    class_id = len(class_map)\n                    class_map[class_name] = class_id\n\n                if class_id is not None:\n                    xyxy.append([x0, y0, x1, y1])\n                    confidences.append(confidence)\n                    class_ids.append(class_id)\n\n        if len(xyxy) == 0:\n            return Detections.empty()\n\n        return cls(\n            xyxy=np.array(xyxy),\n            class_id=np.array(class_ids),\n            confidence=np.array(confidences),\n        )\n\n    @classmethod\n    def from_paddledet(cls, paddledet_result) -> Detections:\n       \n\n        if np.asarray(paddledet_result[\"bbox\"][:, 2:6]).shape[0] == 0:\n            return cls.empty()\n\n        return cls(\n            xyxy=paddledet_result[\"bbox\"][:, 2:6],\n            confidence=paddledet_result[\"bbox\"][:, 1],\n            class_id=paddledet_result[\"bbox\"][:, 0].astype(int),\n        )\n\n    @classmethod\n    @deprecated(\n        \"`Detections.from_lmm` property is deprecated and will be removed in \"\n        \"`supervision-0.31.0`. Use Detections.from_vlm instead.\"\n    )\n    def from_lmm(\n        cls, lmm: Union[LMM, str], result: Union[str, dict], **kwargs: Any\n    ) -> Detections:\n        \n        # filler logic mapping old from_lmm to new from_vlm\n        lmm_to_vlm = {\n            LMM.PALIGEMMA: VLM.PALIGEMMA,\n            LMM.FLORENCE_2: VLM.FLORENCE_2,\n            LMM.QWEN_2_5_VL: VLM.QWEN_2_5_VL,\n        }\n\n        # (this works even if the LMM enum is wrapped by @deprecated)\n        if isinstance(lmm, Enum) and lmm.__class__.__name__ == \"LMM\":\n            vlm = lmm_to_vlm[lmm]\n\n        elif isinstance(lmm, str):\n            try:\n                lmm_enum = LMM(lmm.lower())\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid LMM string '{lmm}'. Must be one of \"\n                    f\"{[m.value for m in LMM]}\"\n                )\n            vlm = lmm_to_vlm[lmm_enum]\n\n        else:\n            raise ValueError(\n                f\"Invalid type for 'lmm': {type(lmm)}. Must be LMM or str.\"\n            )\n\n        return cls.from_vlm(vlm=vlm, result=result, **kwargs)\n\n    @classmethod\n    def from_vlm(\n        cls, vlm: Union[VLM, str], result: Union[str, dict], **kwargs: Any\n    ) -> Detections:\n        vlm = validate_vlm_parameters(vlm, result, kwargs)\n\n        if vlm == VLM.PALIGEMMA:\n            xyxy, class_id, class_name = from_paligemma(result, **kwargs)\n            data = {CLASS_NAME_DATA_FIELD: class_name}\n            return cls(xyxy=xyxy, class_id=class_id, data=data)\n\n        if vlm == VLM.QWEN_2_5_VL:\n            xyxy, class_id, class_name = from_qwen_2_5_vl(result, **kwargs)\n            data = {CLASS_NAME_DATA_FIELD: class_name}\n            return cls(xyxy=xyxy, class_id=class_id, data=data)\n\n        if vlm == VLM.FLORENCE_2:\n            xyxy, labels, mask, xyxyxyxy = from_florence_2(result, **kwargs)\n            if len(xyxy) == 0:\n                return cls.empty()\n\n            data = {}\n            if labels is not None:\n                data[CLASS_NAME_DATA_FIELD] = labels\n            if xyxyxyxy is not None:\n                data[ORIENTED_BOX_COORDINATES] = xyxyxyxy\n\n            return cls(xyxy=xyxy, mask=mask, data=data)\n\n    @classmethod\n    def from_easyocr(cls, easyocr_results: list) -> Detections:\n        \n        if len(easyocr_results) == 0:\n            return cls.empty()\n\n        bbox = np.array([result[0] for result in easyocr_results])\n        xyxy = np.hstack((np.min(bbox, axis=1), np.max(bbox, axis=1)))\n        confidence = np.array(\n            [\n                result[2] if len(result) > 2 and result[2] else 0\n                for result in easyocr_results\n            ]\n        )\n        ocr_text = np.array([result[1] for result in easyocr_results])\n\n        return cls(\n            xyxy=xyxy.astype(np.float32),\n            confidence=confidence.astype(np.float32),\n            data={\n                CLASS_NAME_DATA_FIELD: ocr_text,\n            },\n        )\n\n    @classmethod\n    def from_ncnn(cls, ncnn_results) -> Detections:\n       \n\n        xywh, confidences, class_ids = [], [], []\n\n        if len(ncnn_results) == 0:\n            return cls.empty()\n\n        for ncnn_result in ncnn_results:\n            rect = ncnn_result.rect\n            xywh.append(\n                [\n                    rect.x.astype(np.float32),\n                    rect.y.astype(np.float32),\n                    rect.w.astype(np.float32),\n                    rect.h.astype(np.float32),\n                ]\n            )\n\n            confidences.append(ncnn_result.prob)\n            class_ids.append(ncnn_result.label)\n\n        return cls(\n            xyxy=xywh_to_xyxy(np.array(xywh, dtype=np.float32)),\n            confidence=np.array(confidences, dtype=np.float32),\n            class_id=np.array(class_ids, dtype=int),\n        )\n\n    @classmethod\n    def empty(cls) -> Detections:\n       \n        return cls(\n            xyxy=np.empty((0, 4), dtype=np.float32),\n            confidence=np.array([], dtype=np.float32),\n            class_id=np.array([], dtype=int),\n        )\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Returns `True` if the `Detections` object is considered empty.\n        \"\"\"\n        empty_detections = Detections.empty()\n        empty_detections.data = self.data\n        empty_detections.metadata = self.metadata\n        return self == empty_detections\n\n    @classmethod\n    def merge(cls, detections_list: List[Detections]) -> Detections:\n       \n        detections_list = [\n            detections for detections in detections_list if not detections.is_empty()\n        ]\n\n        if len(detections_list) == 0:\n            return Detections.empty()\n\n        for detections in detections_list:\n            validate_detections_fields(\n                xyxy=detections.xyxy,\n                mask=detections.mask,\n                confidence=detections.confidence,\n                class_id=detections.class_id,\n                tracker_id=detections.tracker_id,\n                data=detections.data,\n            )\n\n        xyxy = np.vstack([d.xyxy for d in detections_list])\n\n        def stack_or_none(name: str):\n            if all(d.__getattribute__(name) is None for d in detections_list):\n                return None\n            if any(d.__getattribute__(name) is None for d in detections_list):\n                raise ValueError(f\"All or none of the '{name}' fields must be None\")\n            return (\n                np.vstack([d.__getattribute__(name) for d in detections_list])\n                if name == \"mask\"\n                else np.hstack([d.__getattribute__(name) for d in detections_list])\n            )\n\n        mask = stack_or_none(\"mask\")\n        confidence = stack_or_none(\"confidence\")\n        class_id = stack_or_none(\"class_id\")\n        tracker_id = stack_or_none(\"tracker_id\")\n\n        data = merge_data([d.data for d in detections_list])\n\n        metadata_list = [detections.metadata for detections in detections_list]\n        metadata = merge_metadata(metadata_list)\n\n        return cls(\n            xyxy=xyxy,\n            mask=mask,\n            confidence=confidence,\n            class_id=class_id,\n            tracker_id=tracker_id,\n            data=data,\n            metadata=metadata,\n        )\n\n    def get_anchors_coordinates(self, anchor: Position) -> np.ndarray:\n        \n        if anchor == Position.CENTER:\n            return np.array(\n                [\n                    (self.xyxy[:, 0] + self.xyxy[:, 2]) / 2,\n                    (self.xyxy[:, 1] + self.xyxy[:, 3]) / 2,\n                ]\n            ).transpose()\n        elif anchor == Position.CENTER_OF_MASS:\n            if self.mask is None:\n                raise ValueError(\n                    \"Cannot use `Position.CENTER_OF_MASS` without a detection mask.\"\n                )\n            return calculate_masks_centroids(masks=self.mask)\n        elif anchor == Position.CENTER_LEFT:\n            return np.array(\n                [\n                    self.xyxy[:, 0],\n                    (self.xyxy[:, 1] + self.xyxy[:, 3]) / 2,\n                ]\n            ).transpose()\n        elif anchor == Position.CENTER_RIGHT:\n            return np.array(\n                [\n                    self.xyxy[:, 2],\n                    (self.xyxy[:, 1] + self.xyxy[:, 3]) / 2,\n                ]\n            ).transpose()\n        elif anchor == Position.BOTTOM_CENTER:\n            return np.array(\n                [(self.xyxy[:, 0] + self.xyxy[:, 2]) / 2, self.xyxy[:, 3]]\n            ).transpose()\n        elif anchor == Position.BOTTOM_LEFT:\n            return np.array([self.xyxy[:, 0], self.xyxy[:, 3]]).transpose()\n        elif anchor == Position.BOTTOM_RIGHT:\n            return np.array([self.xyxy[:, 2], self.xyxy[:, 3]]).transpose()\n        elif anchor == Position.TOP_CENTER:\n            return np.array(\n                [(self.xyxy[:, 0] + self.xyxy[:, 2]) / 2, self.xyxy[:, 1]]\n            ).transpose()\n        elif anchor == Position.TOP_LEFT:\n            return np.array([self.xyxy[:, 0], self.xyxy[:, 1]]).transpose()\n        elif anchor == Position.TOP_RIGHT:\n            return np.array([self.xyxy[:, 2], self.xyxy[:, 1]]).transpose()\n\n        raise ValueError(f\"{anchor} is not supported.\")\n\n    def __getitem__(\n        self, index: Union[int, slice, List[int], np.ndarray, str]\n    ) -> Union[Detections, List, np.ndarray, None]:\n        \n        if isinstance(index, str):\n            return self.data.get(index)\n        if self.is_empty():\n            return self\n        if isinstance(index, int):\n            index = [index]\n        return Detections(\n            xyxy=self.xyxy[index],\n            mask=self.mask[index] if self.mask is not None else None,\n            confidence=self.confidence[index] if self.confidence is not None else None,\n            class_id=self.class_id[index] if self.class_id is not None else None,\n            tracker_id=self.tracker_id[index] if self.tracker_id is not None else None,\n            data=get_data_item(self.data, index),\n            metadata=self.metadata,\n        )\n\n    def __setitem__(self, key: str, value: Union[np.ndarray, List]):\n        \n        if not isinstance(value, (np.ndarray, list)):\n            raise TypeError(\"Value must be a np.ndarray or a list\")\n\n        if isinstance(value, list):\n            value = np.array(value)\n\n        self.data[key] = value\n\n    @property\n    def area(self) -> np.ndarray:\n       \n        if self.mask is not None:\n            return np.array([np.sum(mask) for mask in self.mask])\n        else:\n            return self.box_area\n\n    @property\n    def box_area(self) -> np.ndarray:\n       \n        return (self.xyxy[:, 3] - self.xyxy[:, 1]) * (self.xyxy[:, 2] - self.xyxy[:, 0])\n\n    def with_nms(\n        self, threshold: float = 0.5, class_agnostic: bool = False\n    ) -> Detections:\n        \n        if len(self) == 0:\n            return self\n\n        assert self.confidence is not None, (\n            \"Detections confidence must be given for NMS to be executed.\"\n        )\n\n        if class_agnostic:\n            predictions = np.hstack((self.xyxy, self.confidence.reshape(-1, 1)))\n        else:\n            assert self.class_id is not None, (\n                \"Detections class_id must be given for NMS to be executed. If you\"\n                \" intended to perform class agnostic NMS set class_agnostic=True.\"\n            )\n            predictions = np.hstack(\n                (\n                    self.xyxy,\n                    self.confidence.reshape(-1, 1),\n                    self.class_id.reshape(-1, 1),\n                )\n            )\n\n        if self.mask is not None:\n            indices = mask_non_max_suppression(\n                predictions=predictions, masks=self.mask, iou_threshold=threshold\n            )\n        else:\n            indices = box_non_max_suppression(\n                predictions=predictions, iou_threshold=threshold\n            )\n\n        return self[indices]\n\n    def with_nmm(\n        self, threshold: float = 0.5, class_agnostic: bool = False\n    ) -> Detections:\n        \n        if len(self) == 0:\n            return self\n\n        assert self.confidence is not None, (\n            \"Detections confidence must be given for NMM to be executed.\"\n        )\n\n        if class_agnostic:\n            predictions = np.hstack((self.xyxy, self.confidence.reshape(-1, 1)))\n        else:\n            assert self.class_id is not None, (\n                \"Detections class_id must be given for NMM to be executed. If you\"\n                \" intended to perform class agnostic NMM set class_agnostic=True.\"\n            )\n            predictions = np.hstack(\n                (\n                    self.xyxy,\n                    self.confidence.reshape(-1, 1),\n                    self.class_id.reshape(-1, 1),\n                )\n            )\n\n        merge_groups = box_non_max_merge(\n            predictions=predictions, iou_threshold=threshold\n        )\n\n        result = []\n        for merge_group in merge_groups:\n            unmerged_detections = [self[i] for i in merge_group]\n            merged_detections = merge_inner_detections_objects(\n                unmerged_detections, threshold\n            )\n            result.append(merged_detections)\n\n        return Detections.merge(result)",
            "Examples": [
                "import numpy as np\nfrom supervision.detection.core import Detections\n\ndef test_detections_getitem():\n    # 创建一个 Detections 对象\n    xyxy = np.array([[0, 0, 10, 10], [20, 20, 30, 30], [40, 40, 50, 50]], dtype=np.float32)\n    confidence = np.array([0.8, 0.6, 0.7], dtype=np.float32)\n    class_id = np.array([0, 1, 2], dtype=int)\n    detections = Detections(xyxy=xyxy, confidence=confidence, class_id=class_id)\n\n    # 测试整数索引\n    single_detection = detections[0]\n    print(\"Single detection (index 0):\")\n    print(f\"xyxy: {single_detection.xyxy}\")\n    print(f\"confidence: {single_detection.confidence}\")\n    print(f\"class_id: {single_detection.class_id}\")\n\n    # 测试切片索引\n    slice_detections = detections[0:2]\n    print(\"\\nSlice detections (index 0:2):\")\n    print(f\"xyxy: {slice_detections.xyxy}\")\n    print(f\"confidence: {slice_detections.confidence}\")\n    print(f\"class_id: {slice_detections.class_id}\")\n\n    # 测试列表索引\n    list_detections = detections[[0, 2]]\n    print(\"\\nList detections (index [0, 2]):\")\n    print(f\"xyxy: {list_detections.xyxy}\")\n    print(f\"confidence: {list_detections.confidence}\")\n    print(f\"class_id: {list_detections.class_id}\")\n\n    # 测试布尔数组索引\n    bool_detections = detections[detections.confidence > 0.7]\n    print(\"\\nBoolean detections (confidence > 0.7):\")\n    print(f\"xyxy: {bool_detections.xyxy}\")\n    print(f\"confidence: {bool_detections.confidence}\")\n    print(f\"class_id: {bool_detections.class_id}\")\n\n    # 测试字符串索引\n    # 假设 data 字典中有一个键为 'custom_data' 的数据\n    detections.data = {'custom_data': np.array([10, 20, 30])}\n    custom_data = detections['custom_data']\n    print(\"\\nString index ('custom_data'):\")\n    print(f\"custom_data: {custom_data}\")\n\nif __name__ == \"__main__\":\n    test_detections_getitem()\n"
            ]
        }
    ]
}