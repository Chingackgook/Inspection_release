# API Documentation for OptLM Class

## Class: `OptLM`
The `OptLM` class encapsulates the complete inference process of a large language model, providing a simple `generate()` method to receive input text sequences and return generated token sequences. It supports flexible memory allocation strategies and includes built-in quantization and optimization features.

### Attributes:
- `config`: Configuration object or string representing the model configuration.
- `env`: Execution environment for the model.
- `path`: Path to the model weights.
- `policy`: Policy configuration for memory allocation.
- `num_gpu_batches`: Number of GPU batches as defined in the policy.
- `layers`: List of model layers.
- `num_layers`: Total number of layers in the model.
- `act_home`: Home location for activation storage (GPU, CPU, or Disk).
- `load_weight_stream`, `load_cache_stream`, `store_cache_stream`: CUDA streams for asynchronous operations.
- `cache_home`, `cache_read_buf`, `cache_write_buf`: Buffers for caching intermediate values.
- `weight_read_buf`: Buffer for reading weights.
- `attention_mask`: Attention mask for each GPU batch.
- `task`: Current task being processed.
- `output_ids`: Output token IDs generated by the model.
- `stopped`: Array indicating whether generation has stopped for each input.
- `hidden`: Array for storing hidden states during generation.

### Method: `__init__(self, config: Union[str, OptConfig], env: ExecutionEnv, path: str, policy: Policy)`
#### Parameters:
- `config`: A string or `OptConfig` object specifying the model configuration.
- `env`: An `ExecutionEnv` object representing the execution environment.
- `path`: A string representing the path to the model weights.
- `policy`: A `Policy` object defining memory allocation strategies.

#### Return Value:
- None

#### Description:
Initializes the `OptLM` class, setting up the model configuration, execution environment, memory policy, and layers of the model.

---

### Method: `set_task(self, task)`
#### Parameters:
- `task`: A `Task` object representing the current task to be processed.

#### Return Value:
- None

#### Description:
Sets the current task for the model and updates each layer with the task information.

---

### Method: `init_weight(self, j)`
#### Parameters:
- `j`: An integer representing the index of the layer whose weights are to be initialized.

#### Return Value:
- None

#### Description:
Initializes the weights for the specified layer by downloading the model weights if they are not already present.

---

### Method: `load_weight(self, i, j, k, overlap=True)`
#### Parameters:
- `i`: An integer representing the current token index.
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.
- `overlap`: A boolean indicating whether to use overlapping I/O (default is True).

#### Return Value:
- None

#### Description:
Loads the weights from the weight storage to the read buffer for the specified layer and GPU batch.

---

### Method: `delete_weight(self, j, k)`
#### Parameters:
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.

#### Return Value:
- None

#### Description:
Deletes the weights for the specified layer and GPU batch from memory.

---

### Method: `init_cache(self, j, k)`
#### Parameters:
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.

#### Return Value:
- None

#### Description:
Initializes the cache for the specified layer and GPU batch.

---

### Method: `load_cache(self, i, j, k, overlap=True)`
#### Parameters:
- `i`: An integer representing the current token index.
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.
- `overlap`: A boolean indicating whether to use overlapping I/O (default is True).

#### Return Value:
- None

#### Description:
Loads the cache from the cache storage to the read buffer for the specified layer and GPU batch.

---

### Method: `store_cache(self, i, j, k, overlap=True)`
#### Parameters:
- `i`: An integer representing the current token index.
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.
- `overlap`: A boolean indicating whether to use overlapping I/O (default is True).

#### Return Value:
- None

#### Description:
Stores the cache from the write buffer to the cache storage for the specified layer and GPU batch.

---

### Method: `delete_cache(self, j, k)`
#### Parameters:
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.

#### Return Value:
- None

#### Description:
Deletes the cache for the specified layer and GPU batch from memory.

---

### Method: `load_hidden(self, i, j, k)`
#### Parameters:
- `i`: An integer representing the current token index.
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.

#### Return Value:
- None

#### Description:
Loads the hidden states for the specified layer and GPU batch.

---

### Method: `store_hidden(self, i, j, k)`
#### Parameters:
- `i`: An integer representing the current token index.
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.

#### Return Value:
- None

#### Description:
Stores the hidden states from the specified layer and GPU batch to the output.

---

### Method: `compute_layer(self, i, j, k)`
#### Parameters:
- `i`: An integer representing the current token index.
- `j`: An integer representing the layer index.
- `k`: An integer representing the GPU batch index.

#### Return Value:
- None

#### Description:
Performs the forward computation for the specified layer and GPU batch, updating the hidden states.

---

### Method: `sync(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Synchronizes the disk and GPU to ensure all operations are complete.

---

### Method: `init_all_weights(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Initializes all weights for the model layers.

---

### Method: `delete_all_weights(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Deletes all weights from memory for the model layers.

---

### Method: `update_attention_mask(self, i, k)`
#### Parameters:
- `i`: An integer representing the current token index.
- `k`: An integer representing the GPU batch index.

#### Return Value:
- None

#### Description:
Updates the attention mask for the specified GPU batch based on the current token index.

---

### Method: `generate(self, inputs: Union[np.array, List[List[int]]], max_new_tokens: int = 32, do_sample: bool = False, temperature: float = 1.0, stop: Optional[int] = None, debug_mode: Optional[str] = None, cut_gen_len: Optional[int] = None, verbose: int = 0)`
#### Parameters:
- `inputs`: A numpy array or a list of lists containing input token IDs.
- `max_new_tokens`: An integer specifying the maximum number of new tokens to generate (default is 32).
- `do_sample`: A boolean indicating whether to use sampling (default is False).
- `temperature`: A float controlling the randomness of predictions (default is 1.0).
- `stop`: An optional integer specifying a stop token ID (default is None).
- `debug_mode`: An optional string for debugging modes (default is None).
- `cut_gen_len`: An optional integer to limit the generation length (default is None).
- `verbose`: An integer controlling verbosity level (default is 0).

#### Return Value:
- A numpy array of generated token IDs.

#### Description:
Generates new tokens based on the input sequences, using the specified parameters for sampling and generation control.

---

### Method: `generation_loop_normal(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Executes the normal generation loop without overlapping I/O and computation.

---

### Method: `generation_loop_debug_normal(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Executes a debug version of the normal generation loop, allowing for performance analysis and debugging.

---

### Method: `generation_loop_overlap_single_batch(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Executes the generation loop with overlapping I/O and computation for a single GPU batch.

---

### Method: `generation_loop_overlap_multi_batch(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Executes the generation loop with overlapping I/O and computation for multiple GPU batches.

---

### Method: `generation_loop_debug_single_batch(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Executes a debug version of the generation loop for a single GPU batch, allowing for performance analysis.

---

### Method: `generation_loop_debug_multi_batch(self)`
#### Parameters:
- None

#### Return Value:
- None

#### Description:
Executes a debug version of the generation loop for multiple GPU batches, allowing for performance analysis.

