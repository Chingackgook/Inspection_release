"Project Name (Inspection Registered Name)","Repo name","Project address (github website)","Main functions of the project","Intelligent module interface","Interface call location","Call type
(Please enumerate from the following fields: command line entry, UI interface entry, network back-end interface, sample script (demo), test script, others (please note))","This interface is the reason for the smart module","Is the interface used to implement the main functionality of the project","Star number","Task type","Commit hash"
"AnimateDiff","guoyww/animatediff","https://github.com/guoyww/animatediff/","The image is animated","AnimationPipeline.__call__","scripts/animate.py","Command line entry","Model main inference interface","Yes","11.7K","Generate the animation","e92bd5671ba62c0d774a32951453e328018b7c5b"
"asrt_speechrecognition","nl8590687/ASRT_SpeechRecognition","https://github.com/nl8590687/ASRT_SpeechRecognition","Speech recognition","ModelSpeech.recognize_speech_from_file","predict_speech_file.py","Sample script (original project has network backend interface)","Finally, call the predict method of the model.","Yes","8.2K","Recognize speech","c695d4d3f49f08f2b8c92c89d7baae047e8ee6f5"
"audiocraft","facebookresearch/audiocraft","https://github.com/facebookresearch/audiocraft","Audio generation","MusicGen.generate_with_chroma","demos/musicgen_app.py","Sample script (example is UI interface entry)","BaseGenModel, the base class of MusicGen, has the generate method: generate- > self. _ generate _ tokens, self. _ generate _ tokens calls the neural network model to generate tokens.","Yes","22.4K","Generate audio","896ec7c47f5e5d1e5aa1e4b260c4405328bf009d"
"autokeras","keras-team/autokeras","https://github.com/keras-team/autokeras","Deep learning library","TextClassifier.fit","examples/imdb.py","Sample script","The Text Classifier. Fit internally calls its parent class AutoModel. Fit ()-> AutoTuner. Search () calls its parent class keras _ tuner. Engine. Tuner. Tuner. Search (), KerasTuner's search process essentially builds and trains neural network models iteratively to explore different combinations of hyperparameters.
","Yes","9.3K","Deep learning library","db78b445ee3aa3aedb19a71d2d1e330cc87f12b3"
"backgroundremover","nadermx/backgroundremover","https://github.com/nadermx/backgroundremover","Remove backgrounds from images and videos","remove","backgroundremover/cmd/cli.py","Command line entry","Finally, call the predict method of the model.","Yes","7.5K","Process the image","608dc37e53760eaf13f6b80a593875ef774c4edc"
"bark","suno-ai/bark","https://github.com/suno-ai/bark","Text Prompts Generate Audio","generate_audio","bark/cli.py","Command line entry","Take the mantic subtask of text _ to _ se as an example: generate _ autio-> text _ to _ se mantic-> generate _ text _ semantic-> GPT. _ _ call _ _ ()
Where the GPT class inherits from the NN. Module.","Yes","38.4K","Generate audio","f4f32d4cd480dfec1c245d258174bc9bde3c2148"
"BasicSR","XPixelGroup/BasicSR","https://github.com/XPixelGroup/BasicSR","Image and video restoration","BasicVSR.forward","inference/inference_basicvsr.py","Command line entry","Model main inference interface","Yes","7.7K","Process the image","8d56e3a045f9fb3e1d8872f92ee4a4f07f886b0a"
"BOPBTL_fixed","microsoft/Bringing-Old-Photos-Back-to-Life","https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life","Restore old photos","Pix2PixHDModel_Mapping.inference","Global/test.py","Test script","Call the forward method of the model","Yes","15.6K","Process the image","33875eccf4ebcd3665cf38cc56f3a0ce563d3a9c"
"ChatDev","OpenBMB/ChatDev","https://github.com/OpenBMB/ChatDev","Use natural language to create custom software","ChatChain.execute_step","run.py","Command line entry","The execute _ step calls the execute method of the corresponding Phase or ComposedPhase instance based on the phaseType. Within these execute methods, the reasoning interfaces of large language models (such as ChatGPT, GPT-4, etc.) Will be called by means of role dialogue and task decomposition to generate replies, codes or analysis results, so as to realize multi-round intelligent dialogue and collaboration","Yes","27.3K","Intelligent creation software","33612e6391e2e4c358f852456ade8fd886f2e288"
"ChatPaper","kaixindelele/ChatPaper","https://github.com/kaixindelele/ChatPaper","Summarizing arXiv papers using ChatGPT","Reader.summary_with_chat","chat_paper.py","Command line entry","Finally, the openai. ChatCompletion. Create method is called: the interface method calls the chat _ summary method, and the chat _ summary calls the openai. ChatCompletion. Create method","Yes","19K","Generate text","045205730c164ae6192b99538f1ca666de75d19a"
"ChatTTS","2noise/ChatTTS","https://github.com/2noise/ChatTTS","Generate speech","Chat.infer","tests/#511.py","Test script","Finally, call the GPT. Generate method: the interface method calls the _ infer method, the _ infer calls the _ infer _ code method, and the _ infer _ code calls the GPT. Generate method","Yes","37.5K","Generate speech","1092c1ffcaa82f4bdef104c35aa5541227c3e1d7"
"ChuanhuChatGPT","GaiZhenbiao/ChuanhuChatGPT","https://github.com/GaiZhenbiao/ChuanhuChatGPT","Chatbot","BaseLLMModel.predict","modules/models/models.py","Test script","Model main inference interface","Yes","15.4K","Chat with ai","0271b07aa113bd48cbed36328b46985388d0ce79"
"CLIP","openai/CLIP","https://github.com/openai/CLIP","Predicting the most relevant text segments for a given image","tokenize","tests/test_consistency.py","Test script","Model main inference interface","Yes","30.3K","Generate text","dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1"
"CodeFormer","sczhou/CodeFormer","https://github.com/sczhou/CodeFormer","Face image inpainting","FaceRestoreHelper.paste_faces_to_input_image","inference_codeformer.py","Command line entry","Model main inference interface","Yes","17.4K","Process the image","e878192ee253cfcc8f19e29d3307c181501f53ae"
"cognee","topoteretes/cognee","https://github.com/topoteretes/cognee","AI Agent Build Dynamic Memory","search","examples/python/simple_example.py","Sample script","And finally cal that GeminiAdapter. Acreate _ structured _ output method of the model, namely calling the search _ function method by the interface method and cal the specific _ search method by the search _ function, The specific _ search calls the get _ completion, and the get _ completion calls the GeminiAdapter. Acreate _ structured _ output","Yes","6.7K","Agent memory","8b6aaff554f159cff3ca127c60c93cdcfaa87d9b"
"cogvideo","zai-org/CogVideo","https://github.com/zai-org/CogVideo","Text and image to video generation","generate_video","inference/cli_demo.py","Sample script","CogVideoXImageToVideoPipeline
CogVideoXPipeline
CogVideoXVideoToVideoPipeline
They all encapsulate Diffusion Model and related neural network structures (such as transformer, VAE, UNet, etc.), and use deep learning frameworks such as PyTorch/TensorFlow for forward propagation and generation during reasoning (i.e. pipe (..)).","Yes","11.8K","Generate video","aaab2877ec1a99df1df8fce336e0fe8307300b41"
"consistency_models","openai/consistency_models","https://github.com/openai/consistency_models","Official repository for the consistency model","karras_sample","scripts/image_sample.py","Command line entry","Karras _ sample ()-> KarrasDenoiser. Denoise ()-> UNetModel. _ _ call _ _ (), UNetModel inherits from NN. Moudle","Yes","6.4K","Machine learning library","e32b69ee436d518377db86fb2127a3972d0d8716"
"Cosyvoice","FunAudioLLM/CosyVoice","https://github.com/FunAudioLLM/CosyVoice","Multi-language large speech generation","CosyVoice.inference_zero_shot","generate.py","Sample script","Call CosyVoice Model. TTS model interface","Yes","15.7K","Generate speech","86e7c2d7317e6b5e3e993025acf4bda4ce9d44fa"
"csm","SesameAILabs/csm","https://github.com/SesameAILabs/csm","Conversational speech generation","Generator.generate","run_csm.py","Sample script","Model main inference interface","Yes","13.9K","Generate speech","daed31e6d42cf71873999075de204fa37d2acec3"
"ddddocr","sml2h3/ddddocr","https://github.com/sml2h3/ddddocr","Offline Local Identification SDK","OCREngine.predict","ddddocr/compat/legacy.py","Command line entry","Model main inference interface","Yes","12.5K","Identify the SDK","bdb2cb0faec5f0f44234e082ba04295f2cb42e0d"
"deep_live_cam","hacksider/Deep-Live-Cam","https://github.com/hacksider/Deep-Live-Cam","Real-time face swapping and video depth forgery using images","process_image","modules/core.py","Command line entry","The interface method invokes the process _ frame method, the process _ frame invokes the swap _ face, and the swap _ face invokes the face _ swapper. Get method to obtain the exchanged face. Wherein the face _ swapper object is an instance of one class of the insightface project, and machine learning model reasoning is called","Yes","72.4K","Process the video","f9270c5d1cb2b752b89bf1de28ae181f3f4c361d"
"deep_searcher","zilliztech/deep-searcher","https://github.com/zilliztech/deep-searcher","Alternative Reasoning and Searching for Private Data","query","deepsearcher/cli.py","Network back-end interface","Finally, the model interface LLM. Chat is called: the interface method calls the RAGRouter. Query method, the RAGRouter. Query calls the _ route, and the _ route calls the model interface BaseLLM. Chat","Yes","6.8K","Intelligent search","67d2a6b49f3103b37ed50716cb319e32f2f705ea"
"deepface","serengil/deepface","https://github.com/serengil/deepface","Face Recognition and Face Attribute Analysis","analyze","deepface/api/src/modules/core/service.py","Command line entry","Finally, call the predict method of the model.","Yes","20.1K","Identify the image","4cb0a598252f2a885ee963e6122e2b067a522704"
"Deepfacelab (directly using base environment)","iperov/DeepFaceLab","https://github.com/iperov/DeepFaceLab","Deep forgery","FacesetEnhancer.process_folder","main.py","Command line entry","FacesetEnhancer. Process _ folder ()-> construct and promote process result = FacesetEnhancerSubprocessor (image _ paths, output _ dirpath, device_config=device_config).run(), Instantiates FacesetEnhancerSubprocessorrun () creates multiple Cli's based on the list of devices (GPU/CPU) produced by process _ info _ generator () Child processes (FacesetEnhancerSubprocessor. Cli), each of which initializes the model environment once. The model is loaded in the child process, the Cli. On _ initialize (), self.fe = FaceEnhancer( place_model_on_cpu=(device_vram<=2 or cpu_only), run_on_cpu=cpu_only )ï¼Œ Finally FaceEnhancer. Enhance ()-> FaceEnhancer. Run () is called, FaceEnhancer inherits from NN. ModelBase, and the run method finally calls forward","Yes","18.4K","Process the image","e4b7543ffa1d73b26fce1e31852727f658ba490c"
"DeOldify","jantic/DeOldify","https://github.com/jantic/DeOldify","Coloring and restoring old image","ModelImageVisualizer.get_transformed_image","ColorFIDBenchipynbmarkArtistic.ipynb","Command line entry","Call the intelligent interface of get _ watermarked.","Yes","18.4K","Process the image","5f86c28923799036ad4b1bf7af8c629ac65efd75"
"developer","smol-ai/developer","https://github.com/smol-ai/developer","Libraries for Developer Agents","generate_code_sync","smol_dev/main.py","Command line entry","Finally, the model interface of openai. ChatCompletion. Acreate is called: the interface method calls the generate _ code method, and the generate _ code calls the openai. ChatCompletion. Acreate.","Yes","12.1K","Agent Library","a6747d1a6ccd983c54a483c4a4fb1fa4bf740e82"
"DragGAN","XingangPan/DragGAN","https://github.com/XingangPan/DragGAN","Drag points to manipulate the image","generate_images","gen_images.py","Command line entry","Call the _ _ call _ _ method of the model","Yes","35.9K","Process the image","336f120ce126aca6f55dc58537e76c10d19eabd0"
"EasyOCR","JaidedAI/EasyOCR","https://github.com/JaidedAI/EasyOCR","Character in that image are recognized","Reader.readtext","easyocr/cli.py","Command line entry","The readtext function calls the recognize function to recognize the image, and the recognize function calls the get _ paragraph smart module interface","Yes","27.5K","Recognize text","c4f3cd7225efd4f85451bd8b4a7646ae9a092420"
"EverydayWechat","sfyc23/EverydayWechat","https://github.com/sfyc23/EverydayWechat","WeChat assistant: automatically reply to messages, etc.","get_bot_info","everyday_wechat/utils/friend_helper.py","Command line entry","Call the get _ auto _ reply model interface to get the robot's reply.","Yes","10.2K","Software plug-in","6b81d03dde92cfef584428bc1e59d2858e94204e"
"External_Attention_pytorch","xmu-xiaoma666/External-Attention-pytorch","https://github.com/xmu-xiaoma666/External-Attention-pytorch","Help understand the paper","MobileViTv2Attention.forward","main.py","Sample script","Model main inference interface","Yes","12K","Summarize the article","d75848e40233ed56fa503c888472bab8b17c568c"
"F5_TTS","Swivid/F5-TTS","https://github.com/SWivid/F5-TTS","Fake smooth and faithful voice through traffic matching","infer_process","src/f5_tts/infer/infer_cli.py","Command line entry","Call the infer _ batch _ process method, which is a model interface method","Yes","12.9K","Generate video","31bb78f2aba40a8b294bdfc2903a010a6c28a9de"
"face","ageitgey/face_recognition","https://github.com/ageitgey/face_recognition","Facial recognition","face_encodings","face_recognition/face_recognition_cli.py","Command line entry","No intelligent interface","Yes","55.2K","Identify the image","2e2dccea9dd0ce730c8d464d0f67c6eebb40c9d1"
"face_alignment","1adrianb/face-alignment","https://github.com/1adrianb/face-alignment","Face Alignment","FaceAlignment.get_landmarks_from_image","examples/detect_landmarks_in_image.py","Sample script","Model main inference interface","Yes","7.4K","Identify the image","bacd0afb400a46ce4e94bf231624591495d932a2"
"fawkes","Shawn-Shan/fawkes","https://github.com/Shawn-Shan/fawkes","Privacy Protection for Facial Recognition Systems","Fawkes.run_protection","fawkes/protection.py","Command line entry","Finally, the FawkesMaskGeneration. Compute method is called: the interface method calls the generate _ cloak _ images method, and the generate _ cloak _ images calls compute","Yes","5.4K","Identify the image","aedaa82d22504c4e7dbc86de869a6e0d943a5f2a"
"first_order_model","AliaksandrSiarohin/first-order-model","https://github.com/AliaksandrSiarohin/first-order-model","Generate a short animation from an image","OcclusionAwareGenerator.forward","demo.py","Sample script","Model main inference interface","Yes","14.9K","Generate video","c0274845cb2dd8f0f2fe6da580d97b60fef90c91"
"fish_speech","fishaudio/fish-speech","https://github.com/fishaudio/fish-speech","Text-generated speech","generate_long","fish_speech/models/text2semantic/inference.py","Command line entry","Finally, call the forward _ generate method of the model: the interface method calls the generate method, and generate calls the decode _ one _ token _ ar method. Decode _ one _ token _ ar calling decode _ one _ token _ ar. Forward _ generate method","Yes","22.6K","Generate speech","5a89fe56cbfdac516c87e82f361770d5240e3aa6"
"flair","flairNLP/flair","https://github.com/flairNLP/flair","Natural language processing","Classifier.predict","tests/test_biomedical_entity_linking.py","Test script","Model main inference interface","Yes","14.3K","Process the audio","d4ea3777998ba67bfbe6b6b8359e024dcf673c3e"
"FlexLLMGen","FMInference/FlexLLMGen","https://github.com/FMInference/FlexLLMGen","Large language models","OptLM.generate","flexllmgen/apps/completion.py","Sample script","Model main inference interface: Encapsulate all the processes of model inference (input preparation, cache management, weight loading, inference loop, result processing, etc.) In one interface","Yes","9.4K","Generate text","004ffef82b46e8dc8685c55d0cdda650bdaf1269"
"generative_models","Stability-AI/generative-models","https://github.com/Stability-AI/generative-models","High Fidelity New View Video Synthesis","run_img2vid","scripts/sampling/simple_video_sample_4d2.py","Sample script","The interface method calls the do _ sample method, which is the core sampling and decoding interface of the diffusion generation model, and is responsible for the entire process from the condition input to the final generation result","Yes","26.3K","Generate video","0ad7de9a5cb53fd63d6d30a4f385485e72e08597"
"gfp_gan","TencentARC/GFPGAN","https://github.com/TencentARC/GFPGAN","Facial repair","GFPGANer.enhance","inference_gfpgan.py","Sample script","Model main inference interface","Yes","37K","Process the image","7552a7791caad982045a7bbe5634bbf1cd5c8679"
"gpt_engineer","AntonOsika/gpt-engineer","https://github.com/AntonOsika/gpt-engineer","Specifying Software in Natural Language","AI.start","gpt_engineer/core/steps.py","Command line entry","Finally, invoke the invoke interface of the model: the start method calls the next method, the next calls the backoff _ inference method, and the backoff _ inference calls invoke","Yes","54.7K","Intelligent development software","a90fcd543eedcc0ff2c34561bc0785d2ba83c47e"
"gpt_fast","meta-pytorch/gpt-fast","https://github.com/meta-pytorch/gpt-fast","Text generation","generate","generate.py","Command line entry","Model main inference interface","Yes","6K","Generate text","6ecad9b5b6b987d17ac4303965545873d0192086"
"GPT2_Chinese","Morizeyao/GPT2-Chinese","https://github.com/Morizeyao/GPT2-Chinese","Write poetry, news, a novel","generate","generate.py","Command line entry","Finally, call the _ call _ method of the model: call the fast _ sample _ sequence and sample _ sequence interface methods, which call the _ call _ method of the GPT2LMHead Model.","Yes","7.6K","Generate text","9dc45aa24275944bec6ddfd132e0681d24d631ad"
"HivisionIDPhotos_fixed","Zeyi-Lin/HivisionIDPhotos","https://github.com/Zeyi-Lin/HivisionIDPhotos","AI ID photo production","IDCreator.__call__","inference.py","Command line entry","Main reasoning interface of the model (steps such as matting, beautification, detection and alignment are completed in the method)","Yes","18.9K","Generate an image","94d70d6445d01cef92d97002942863b00ebd982c"
"insightface","deepinsight/insightface","https://github.com/deepinsight/insightface","Face analysis","FaceAnalysis.get","python-package/insightface/app/face_analysis.py","Command line entry","Call the detect and get methods of the model","Yes","26.1K","Identify the image","29b6cd65aa0e9ae3b6602de3c52e9d8949c8ee86"
"IOPaint","Sanster/IOPaint","https://github.com/Sanster/IOPaint","Image repair tool","batch_inpaint","iopaint/cli.py","Command line entry","Call the Model Manager. _ _ call _ _ method","Yes","22K","Process the image","61a759fb3f332bacdce8b2813f4837495c9b86e0"
"Kats","facebookresearch/Kats","https://github.com/facebookresearch/Kats","Analyzing Time Series Data","SARIMAModel.predict","tutorials/kats_201_forecasting.ipynb","Command line entry","Model main inference interface","Yes","6.1K","Analyze the data","3a35b8b1147ad263049c18745d248de8d8317b20"
"latent_diffusion","CompVis/latent-diffusion","https://github.com/CompVis/latent-diffusion","High Resolution Image Synthesis","DDIMSampler.sample","scripts/txt2img.py","Command line entry","The ddim _ sampling method is cal, and that ddim _ sampling calls the model interface of the p _ sample _ ddim; the p _ sample _ ddim method realize the DDIM sampling process and is used for generate samples from the diffusion model","Yes","13.2K","Generate an image","a506df5756472e2ebaf9078affdde2c4f1502cd4"
"Latex","lukas-blecher/LaTeX-OCR","https://github.com/lukas-blecher/LaTeX-OCR","Transforming equation images into LaTeX code","LatexOCR.__call__","pix2tex/api/app.py","Command line entry","Model main inference interface","Yes","15.1K","Generate code","5c1ac929bd19a7ecf86d5fb8d94771c8969fcb80"
"lit_llama","Lightning-AI/lit-llama","https://github.com/Lightning-AI/lit-llama","Independent implementation of pre-training, fine-tuning, and inference code","generate","generate.py","Command line entry","Call model LLaMA. _ _ call _ _ method","Yes","6.1K","Generate code","2a464de2a1d2f266614d15091d3d7f30330c3ede"
"magic_animate","magic-research/magic-animate","https://github.com/magic-research/magic-animate","Nerating human body image animation","MagicAnimate.__call__","demo/gradio_animate.py","Sample script (also UI interface entry)","Model main inference interface","Yes","10.8K","Generate the animation","d2bc3bc3c9cc3dadeedef8a02668dd5582d10a01"
"magika","google/magika","https://github.com/google/magika","Detect file content type","Magika.identify_paths","python/src/magika/cli/magika_client.py","Command line entry","The identify _ paths method first collects the file features that need to be inferred and then calls _ get _ results _ from _ paths, which internally calls _ get _ results _ from _ features. Finally, the ONNX model inference is performed using self. _ onnx _ session. Run (..) through _ get _ model _ outputs _ from _ features and _ get _ raw _ predictions. The content-type prediction result of each file is obtained.","Yes","8.8K","Identify the contents of the file","4c8b298e2ff191bd1c4af853b8266d18324c2bb9"
"manga_image_translator","zyddnys/manga-image-translator","https://github.com/zyddnys/manga-image-translator","Translate all kinds of text in images","MangaTranslatorLocal.translate_path","manga_translator/__main__.py","Command line entry","The translate _ path recursively processes the image or text file based on the input path, eventually calling the self. Translate _ file, and the translate _ file calls the _ translate _ file. When the image is processed _ translate _ file, the await self. Translate (IMG, config, image _ name) is called. The self. Translate method will perform the inference of OCR, text detection, translation and other models (such as text recognition model, machine translation model, etc.) To realize the automatic recognition and translation of image content.","Yes","8.3K","Translate image text","a89c38fd6a57fcc12f44ec4209ef9dff05988e51"
"marker","datalab-to/marker","https://github.com/datalab-to/marker","Convert PDF to Markdown + JSON","PdfConverter.__call__","benchmarks/throughput/main.py","Command line entry","Model main inference interface","Yes","27.1K","File format conversion","d86b27e1a1c32c63dafaec81ef7073da6cd3d9d9"
"marvin","PrefectHQ/marvin","https://github.com/PrefectHQ/marvin","Generating Structured Output and Building Agent AI","generate","examples/hello_generate.py","Sample script","The generate invokes the generate _ async, and the generate _ async constructs a Marvin. Task object and invokes its run _ async method. Within the Task. Run _ async, the reasoning interface of the underlying big language model (such as OpenAI, Azure, Wenxin Yiyan, etc.) Will be called through the agent.","Yes","5.9K","Structured output","8dc1e9138558ecebc55537de544c3031295be145"
"MegaParse","QuivrHQ/MegaParse","https://github.com/QuivrHQ/MegaParse","File parser","MegaParse.load","libs/megaparse/examples/parse_file_mp.py","Sample script","The load method will automatically call the layout analysis model (self. Layout _ model) and OCR text recognition model (self. Doctr _ parser. Get _ text _ recognition) according to the file type and parsing strategy. Or unstructured parsing model (self. Unstructured _ parser. Convert), to achieve automatic parsing and structured extraction of document content.","Yes","7.1K","Parse the file","ba9a24aec950d6cf14834b8e2e11f5725778f12e"
"MeloTTS","myshell-ai/MeloTTS","https://github.com/myshell-ai/MeloTTS","Multilingual text-to-speech","TTS.tts_to_file","melo/main.py","Command line entry","Calling Synthe sizer Trn. Infer model reasoning interface","Yes","6.6K","Generate speech","209145371cff8fc3bd60d7be902ea69cbdb7965a"
"mem0","mem0ai/mem0","https://github.com/mem0ai/mem0","Personalized AI interaction","Memory.search","cookbooks/customer-support-chatbot.ipynb","Command line entry","The search method invokes the _ search _ vector _ store, which first obtains the vector representation of the query through the self. Embedding _ model. Embed ( ""search""), and then invokes the underlying text embedding model for inference. Subsequently, similarity retrieval is performed in the self. Vector _ store. Search (..) using the resulting vectors.","Yes","38.1K","Chat with ai","77b4b6a2b94b950aeb203a0e3ddea662dec6b3c8"
"memvid","Olow304/memvid","https://github.com/Olow304/memvid","Convert millions of text blocks into a single, searchable video file","MemvidChat.chat","examples/file_chat.py","Sample script","And finally cal that interface method of the Google Provider. Chat model, wherein the interface method calls the LLMClient. Chat method, and the chat call the Google Provider. Chat method","Yes","8.3K","Intelligent search","a8c0516b6f5d864e08f02542bb34d1e87f8a341e"
"mmdetection","open-mmlab/mmdetection","https://github.com/open-mmlab/mmdetection","Object Detection Toolbox","DetInferencer.__call__","demo/image_demo.py","Sample script","Model main inference interface","Yes","31.5K","Detect the object","cfd5d3a985b0249de009b67d04f37263e11cdf3d"
"mmpose","open-mmlab/mmpose","https://github.com/open-mmlab/mmpose","Pose estimation toolbox","MMPoseInferencer.__call__","demo/inferencer_demo.py","Sample script","Model main inference interface","Yes","6.7K","Recognize gestures","759b39c13fea6ba094afc1fa932f51dc1b11cbf9"
"MonkeyOCR","Yuliang-Liu/MonkeyOCR","https://github.com/Yuliang-Liu/MonkeyOCR","Document parsing","single_task_recognition","parse.py","Command line entry","Cal MonkeyOCR _ model. Chat _ model. Batch _ inference model interface method","Yes","5.4K","Parse the document","2f49a15a838279f62ab5149c5286d5733febb6ab"
"moshi","kyutai-labs/moshi","https://github.com/kyutai-labs/moshi","A speech-text based model for real-time dialogue","LMGen.step","moshi/moshi/run_inference.py","Command line entry","Call the _ step method, which is the core single-step inference and sampling method of streaming generation, and is responsible for token generation and cache management of each step.","Yes","8.8K","Generate speech","e7894fa2a466bf6d82f9f1539f4d1a257ba86283"
"Omost","lllyasviel/Omost","https://github.com/lllyasviel/Omost","Image generation","StableDiffusionXLOmostPipeline.__call__","gradio_app.py","UI interface entry","Model main inference interface","Yes","7.7K","Generate an image","731e74922fc6be91171688574d07624f93d3b658"
"OOTDiffusion","levihsu/OOTDiffusion","https://github.com/levihsu/OOTDiffusion","Generating an image of a virtual try-on garment","OOTDiffusionHD.__call__","run/run_ootd.py","Command line entry","Model main inference interface","Yes","6.4K","Generate an image","13ef0faba266cdde9febc8ad39be2395bbb89d9c"
"OpenChatKit","togethercomputer/OpenChatKit","https://github.com/togethercomputer/OpenChatKit","Create specialized and generic models for various applications","ChatModel.do_inference","inference/bot.py","Command line entry","Call AutoModel ForCausalLM. Generate model interface","Yes","9K","Create a software model","a7094aa583d4ac9ecbe700f0c5b11e6bb28cb454"
"PaddleDetection","PaddlePaddle/PaddleDetection","https://github.com/PaddlePaddle/PaddleDetection","Object detection, instance segmentation, multi-object tracking, and real-time multi-person keypoint detection","Trainer.predict","tools/infer.py","Command line entry","Model main inference interface","Yes","13.7K","Detect the object","dbb9f5b2ccd99a68521527d63dcc3cc4bffc94c9"
"PaddleSpeech","PaddlePaddle/PaddleSpeech","https://github.com/PaddlePaddle/PaddleSpeech","Voice Kit","TextExecutor.__call__","demos/automatic_video_subtitiles/recognize.py","Sample script","Model main inference interface","Yes","12.1K","Processing speech","8247eba840c0b0a154e9eee67400ad48e4d87697"
"point_e","openai/point-e","https://github.com/openai/point-e","Point Cloud Diffusion for 3D Model Synthesis","PointCloudSampler.sample_batch_progressive","examples/text2pointcloud.ipynb","Sample script","When the karras _ sample _ progressive method is called, the karras _ sample _ progressive calls the model interface for inference; the sample _ batch _ progressive itself calls the model interface method","Yes","6.8K","Process the 3D model","fc8a607c08a3ea804cc82bf1ef8628f88a3a5d2f"
"pulse","alex-damian/pulse","https://github.com/alex-damian/pulse","Self-supervised photo upsampling","PULSE.forward","run.py","Command line entry","Model main inference interface","Yes","8K","Intelligent sampling","40cacb97df28081e0edf8440a8c3f7c4e6205732"
"pycorrector","shibing624/pycorrector","https://github.com/shibing624/pycorrector","Text error correction","EnSpellCorrector.correct","examples/kenlm/en_correct_demo.py","Sample script","It doesn't feel like an intelligent interface.","Yes","6.1K","Text error correction","6bb3794896418607051443e2ed102bf966cb2ea0"
"pyvideotrans","jianchang512/pyvideotrans","https://github.com/jianchang512/pyvideotrans","Translate videos from one language to another","speech_to_text","cli.py","Command line entry","Cal WhisperModel. Transcribe model interface method","Yes","13.6K","Translate text in video","c8a3bce52cf3cef1326db45240963e13129eb540"
"Real_Time_Voice_Cloning","CorentinJ/Real-Time-Voice-Cloning","https://github.com/CorentinJ/Real-Time-Voice-Cloning","Clone voice in real time","Synthesizer.synthesize_spectrograms","demo_cli.py","Sample script","Call Tacotron. Generate model interface method","Yes","54.8K","Generate speech","440322b8ff93ed1cca1d954f781bcfbe83429d23"
"realesrgan","xinntao/Real-ESRGAN","https://github.com/xinntao/Real-ESRGAN","Universal Image/Video Restoration","RealESRGANer.enhance","inference_realesrgan.py","Command line entry","Model main inference interface","Yes","1.2K","Restore the image","a4abfb2979a7bbff3f69f58f58ae324608821e27"
"rembg","danielgatis/rembg","https://github.com/danielgatis/rembg","Remove the image background","remove","rembg/commands/i_command.py","Command line entry","Call the predict method of the model","Yes","20.1K","Process the image","ae95c2079c130ccd96cb6a72fd07e3d5b1676f6c"
"RIFE","hzwer/ECCV2022-RIFE","https://github.com/hzwer/ECCV2022-RIFE","Real-time intermediate flow estimation","Model.inference","inference_img.py","Command line entry","The main inference interface of the model is used for forward inference of the frame insertion model to generate an intermediate frame between two frames.","Yes","5K","Estimated flow","cf06c863963e99f2a43f144b3a8ad4f029a4cf7c"
"RobustVideoMatting","PeterL1n/RobustVideoMatting","https://github.com/PeterL1n/RobustVideoMatting","Video matting","MattingNetwork.forward","inference.py","Command line entry","Model main inference interface","Yes","9K","Process the video","53d74c6826735f01f4406b5ca9075eee27bec094"
"roop","s0md3v/roop","https://github.com/s0md3v/roop","Change your face","predict_video","roop/core.py","Command line entry","Invoke the predict _ video _ frames method to reason","Yes","30.1K","Ai change face","f9fe11a8a9a0429f2f1f67095af9c71677002793"
"SadTalker","OpenTalker/SadTalker","https://github.com/OpenTalker/SadTalker","Generating a single-image speaking facial animation","Audio2Coeff.generate","interface.py","Command line entry","Model main inference interface","Yes","13.1K","Generate an image","cd4c0465ae0b54a6f85af57f5c65fec9fe23e7f8"
"semantic_kernel ","microsoft/semantic-kernel","https://github.com/microsoft/semantic-kernel","Build, orchestrate, and deploy AI agents and multi-agent systems","ChatCompletionAgent.get_response","python/samples/concepts/agents/chat_completion_agent/chat_completion_agent_function_termination.py","Sample script","The _ inner _ invoke method is called, the chat _ completion _ service. Get _ chat _ message _ contents is called by the _ inner _ invoke, Chat _ completion _ service is an instance of ChatCompletionClientBase, and the get _ chat _ message _ contents method will actually call the inference interface of the underlying large model (such as OpenAI, Azure, Wenxin Yiyan, etc.). The reply content is generated.","Yes","25.8K","Proxy system","0ec81c8a14cee73e543a4a93f76526fd5ca7ab4a"
"Sonnet","google-deepmind/sonnet","https://github.com/google-deepmind/sonnet","Construct the neural network library","Sequential.__call__","examples/simple_mnist.py","Sample script","Model main inference interface","Yes","9.9K","Agent Library","39176f90db9ba770a6ad8ae518ab594314bb487f"
"Spark_TTS","SparkAudio/Spark-TTS","https://github.com/SparkAudio/Spark-TTS","Text-to-speech","SparkTTS.inference","cli/inference.py","Command line entry","Call model AutoModelForCausalLM. Generate method","Yes","10.2K","Generate speech","2f1ea9082400547242641f5271b6f941c9f439d1"
"spleeter","deezer/spleeter","https://github.com/deezer/spleeter","Train the source separation model","Separator.separate","tests/test_separator.py","Test script","Finally, call the predict method of the model.","Yes","27.2K","Agent model","64daa5a9172aa33ba155f051184528c4e969ad8e"
"Stable_dreamfussion","ashawkey/stable-dreamfusion","https://github.com/ashawkey/stable-dreamfusion","Text to 3D and Image to 3D","DPT.__call__","preprocess_image.py","Command line entry","Model main inference interface","Yes","8.7K","Generate an image","5550b91862a3af7842bb04875b7f1211e5095a63"
"StreamDiffusion","cumulo-autumn/StreamDiffusion","https://github.com/cumulo-autumn/StreamDiffusion","Real-time interactive generation","StreamDiffusionWrapper.__call__","examples/img2img/single.py","Sample script","Model main inference interface","Yes","10.4K","Interactive generation","b623251dc055e1fd858d53509aa43e09dfc5cdc0"
"streaming_llm","mit-han-lab/streaming-llm","https://github.com/mit-han-lab/streaming-llm","Fficient stream language model","greedy_generate","examples/run_streaming_llama.py","Sample script","Call the _ _ call _ _ method of the model","Yes","7K","Language model","2e5042606d69933d88fbf909bd77907456b9b4dd"
"supervision","roboflow/supervision","https://github.com/roboflow/supervision","Computer vision tools","Detections.from_yolo_nas","examples/speed_estimation/yolo_nas_example.py","Sample script","Not like an intelligent interface: just turns the result of the inference into a Detections object.","Yes","33.5K","Computer vision tools","deb1c9c4f4b0cd678416a67c8a13f2ef8ed6878f"
"Surprise","NicolasHug/Surprise","https://github.com/NicolasHug/Surprise","Recommender systems that handle explicit rating data","AlgoBase.predict","examples/predict_ratings.py","Sample script","Model main inference interface","Yes","6.6K","Process the data","2381fb11d0c4bf917cc4b9126f205d0013649966"
"surya","datalab-to/surya","https://github.com/datalab-to/surya","Text detection","RecognitionPredictor.__call__","surya/scripts/ocr_text.py","Command line entry","Model main inference interface","Yes","18.1K","Text detection","dca1f48dd25ba1643feada9b87c417b63cb2798d"
"Synonyms","chatopera/Synonyms","https://github.com/chatopera/Synonyms","Chatbot","compare","Synonyms/demo.py","Sample script","The _ similarity _ distance method is called to obtain the distance, the _ similarity _ distance calls the _ get _ WV method, the _ get _ WV calls the _ vectors. Word _ VEC method, Where _ vectors is the loaded word2vec word vector model. The word _ VEC method returns its word vector based on the input word","Yes","5.1K","Chat with ai","b2e7f753a43a9f1153562c86fda07a83f9ec7579"
"txtai","neuml/txtai","https://github.com/neuml/txtai","Semantic search","Embeddings.search","examples/images.py","Sample script","Call the _ _ call _ _ method of the model","Yes","11.4K","Intelligent search","f082bf2a2789242021fc20dd8e5c3db3963eb1f1"
"tortoise_tts","neonbjb/tortoise-tts","https://github.com/neonbjb/tortoise-tts","Text-to-speech","TextToSpeech.tts_with_preset","tortoise/do_tts.py","Command line entry","By calling the main inference interface method of TTS model, the TTS method can convert the input text into speech and audio, support the specification of reference timbre, generation parameters and multi-model fusion, and output high-quality speech.","Yes","14.5K","Generate speech","8a2563ecabe93c4fb626f876dd0c52c966edef2f"
"U2Net","xuebinqin/U-2-Net","https://github.com/xuebinqin/U-2-Net","Target detection","U2NET.forward","u2net_portrait_demo.py","Sample script","Model main inference interface","Yes","9.3K","Identify the image","ac7e1c817ecab7c7dff5ce6b1abba61cd213ff29"
"Vallex","Plachtaa/VALL-E-X","https://github.com/Plachtaa/VALL-E-X","Multilingual Text-to-Speech Synthesis and Speech Cloning","VALLE.inference","launch_ui.py","Command line entry","Model main inference interface","Yes","7.9K","Generate speech","3faaf8ccadb154d63b38070caf518ce9309ea0f4"
"video_retalking","OpenTalker/video-retalking","https://github.com/OpenTalker/video-retalking","Audio based lip-synch","Laplacian_Pyramid_Blending_with_mask","inference.py","Command line entry","Model main inference interface","Yes","7.1K","Identify the audio","d32e8e58248255e2d243eeaf3cba545dbe505ca8"
"VideoLingo","Huanshere/VideoLingo","https://github.com/Huanshere/VideoLingo","Video translation, localization and dubbing","ask_gpt","core/translate_lines.py","Command line entry","Call OpenAI. Chat. Completions. Create to produce output","Yes","14.8K","Translate text in video","b94d8fcd0897626b6110f43683f6a9fff222e446"
"Wav2Lip","Rudrabha/Wav2Lip","https://github.com/Rudrabha/Wav2Lip","Lips are generated synchronously","Wav2Lip.forward","inference.py","Command line entry","Model main inference interface","Yes","12.3K","Generate video","bac9a81e63ecc153202353372e5724b83d9e6322"
"whisper","openai/whisper","https://github.com/openai/whisper","Robust speech recognition","transcribe","whisper/transcribe.py","Command line entry","The transcribe method internally defines decode _ with _ fallback functions. In the decode _ with _ fallback, the model. Decode (segment, options) is called, where model is the Whisper model instance. The model. Decode is the main inference interface of the Whisper model, which is used to convert the audio features into text tokens. Therefore, the transcribe method directly calls the main inference interface of the model in the process of converting audio to text.","Yes","86.4K","Speech recognition","c0d2f624c09dc18e709e37c2ad90c039a4eb72a2"
"yolov10","THU-MIG/yolov10","https://github.com/THU-MIG/yolov10","Real-time end-to-end object detection","Model.predict","ultralytics/data/converter.py","Command line entry","Model main inference interface","Yes","10.9K","Detect the object","453c6e38a51e9d1d5a2aa5fb7f1014a711913397"
"yolov5","ultralytics/yolov5","https://github.com/ultralytics/yolov5","Object Detection, Image Segmentation and Image Classification","DetectMultiBackend.forward","detect.py","Sample script","Model main inference interface","Yes","55K","Detect the object","459d8bf01bee3733332aaec74434ff354945bb9d"
"yolov7","WongKinYiu/yolov7","https://github.com/WongKinYiu/yolov7","Real-time object detector","TracedModel.forward","detect.py","Command line entry","Model main inference interface","Yes","13.9K","Detect the target","a207844b1ce82d204ab36d87d496728d3d2348e7"
"yolox","Megvii-BaseDetection/YOLOX","https://github.com/Megvii-BaseDetection/YOLOX","Detecting the position of the object in the image","vis","demo/ONNXRuntime/onnx_inference.py","Sample script","Model main inference interface","Yes","10K","The object position is detect","6ddff4824372906469a7fae2dc3206c7aa4bbaee"
